@tangler parsers.flx = share/lib/std/strings/parsers.flx
@tangler parsers.fsyn = share/lib/std/strings/parsers.fsyn

@h1 Parsing
Chips to providing parsing functions.

@tangle parsers.flx

@h1 Capturing wrappers
Given a Buffer->Buffer scanner chip 'scan',
and a state updater 'newstate' which takes the
old state and the end position of the scanned lexeme
and produces a new state, run the scan chip
to match a lexeme and output the updated state.

The design of this chip is a bit weird and requires
explanation!

The captured device is expected to have signature (read+ write)+,
and so must the capturing device. So we cannot just read then
write and loop, because the captured scanner may fail, and this
would block the capturer. Instead, we have to spawn a fibre
that does a write and read on the captured device for every
input, which will fail if the scanner fails.

We have to make sure the handler parameter is bound to the
correct x, because it may be suspended when another input
comes in! So the closure y is formed to ensure capture.

NOTE: the code is is completely generic. There's nothing
specific to parsers here.

@tangle parsers.flx

chip gmonad[B,C,T,U] 
  (
    scan: BaseChips::iochip_t[B,C],
    newstate: (B * T) * C -> U
  )
  connector io
    pin inp: %<(B * T)
    pin out: %>(C * U)
{
while true do
  var x = read io.inp;
  noinline proc handler (var x: B * T) () {
    var b,pd = x;
    var rin,win= mk_ioschannel_pair[B]();
    var rout,wout= mk_ioschannel_pair[C]();
    spawn_fthread (scan (inp=rin,out=wout));
    write(win,b);
    var c : C = read rout; // this can block forever if scan fails
    var s : U = newstate((b,pd),c);
    write (io.out,(c,s));
  }
  var y = handler x;
  spawn_fthread y;
done
}

fun monad[B,C,T] 
  (
    scan: BaseChips::iochip_t[B,C],
    newstate: (B * T) * C -> T
  )
=> 
  gmonad [B,C,T,T] (scan,newstate)
;

@h2 Accumulating monad
This is a special case of a generalised monad. The problem is that
in a shift/reduce parser for a production

    E = A B C

we would normally shift the attributes of A, then B, then C, then
at the end we pop them off the stack and combine them into an E term
and push that on the stack: the reduce step. A plain monad cannot
handle that with type safety using a list as the stack, because the
terms for A,B,C have distinct types.

Instead we use a generalised monad, where the output type changes
on each step. The way to gather the data is to use a lazy function:

    E = A -> B -> C

We start by passing the first wrapper e: A -> B -> C -> E, and
applying it to A, which yields a function B -> C -> E. We pass
that closure to the next nonterminal parser which applies it to
the B value, pass that to the next one which applies it to the C
value and finally we have our E value.

This is type safe. So the trick is to write the E constructor
function in curried form and pass that. Changing notation,
our inital state T is now X -> Y, and the output state is just Y.
We split out the attribute constructor B * C -> X which is no longer
allowed to be dependent on the input state. For a terminal, this
is the terminal's attribute constructor. For a nonterminal, its the
identity function.

@tangle parsers.fsyn
// This function returns a chip which acts as a binder for terminal
// symbols in a grammar, where scan is a chip representing a function
// from B to C, usually B = C = position in string.
//
// The att_ctor is a constructor accepting the two positions in the string,
// which returns a value of the terminal representation type X.
//
// The chip reads a function of type X -> T along with the initial
// buffer position, applies the scanner to get the final buffer
// position, and then applies the constructor it read to the
// terminal attribute, and sends the result along with the final
// position to the next chip.

fun terminal_binder[B,C,X,Y] 
  (
    scan: BaseChips::iochip_t[B,C],
    att_ctor: B * C -> X
  )
=>
  let newstate (data:B * (X -> Y), c: C) : Y =
    let b = data.0 in
    let cls = data.1 in
    cls (att_ctor (b,c)) 
  in
  gmonad[B,C,X->Y,Y] (scan, newstate)
;

fun epsilon_binder[B,C,X,Y]
  (
    scan: BaseChips::iochip_t[B,C]
  )
=>
  let newstate (data:B * (X -> Y), c: C) : X-> Y =
    let cls = data.1 in cls
  in
  gmonad[B,C,X->Y,Y] (scan, newstate)
;


@h1 Syntax
@tangle parsers.fsyn

syntax parsers {
  priority 
    palt_pri <
    pseq_pri <
    ppostfix_pri <
    patom_pri
  ;
 
  //$ Define a non-terminal
  stmt := "parser" sdeclname "=" sparser[palt_pri] ";" =># 
    """
    `(ast_var_decl ,_sr ,(first _2) ,(second _2) none (some ,_4))
    """;

  //$ Define a non-terminal
  stmt := "parser" sdeclname ":" stypeexpr "=" sparser[palt_pri] ";" =># 
    """
    `(ast_var_decl ,_sr ,(first _2) ,(second _2) (some ,_4) (some ,_6))
    """;


  //$ Inline regular expression.
  //$ Can be used anywhere in Felix code.
  //$ Returns a a value of type Regdef::regex.
  x[sapplication_pri] := "parse" "(" sparser[palt_pri] ")" =># "_3";

  //$ Alternatives.
  sparser[palt_pri] := sparser[>palt_pri] ("|" sparser[>palt_pri])+ =># 
    """`(ast_apply ,_sr ( ,(qnoi 'BaseChips 'tryall_list) 
      (ast_apply ,_sr (,(noi 'list) ,(cons _1 (map second _2))))))"""
  ;

  //$ Sequential concatenation.
  sparser[pseq_pri] := sparser[>pseq_pri] (sparser[>pseq_pri])+ =># 
    """`(ast_apply ,_sr ( ,(qnoi 'BaseChips 'pipeline_list)
      (ast_apply ,_sr (,(noi 'list) ,(cons _1 _2)))))"""
  ;

/////////
// THESE COMBINATORS SEEM USELESS BECAUSE THERE IS NO WELL DEFINED
// RESULT. 
//
// That is, when parsing, they're not defined to say, push a list
// onto the parser stack.
//
// They can be used by pushing a mark before and popping to the mark
// to do a reduce. Works fine. But depends on being able to put
// a mark on the stack, which means the type of terms on the stack
// has to include a mark term.

  //$ Postfix star (*).
  //$ Kleene closure: zero or more repetitions.
  sparser[ppostfix_pri] := sparser[ppostfix_pri] "*" =># 
    """`(ast_apply ,_sr ( ,(qnoi 'BaseChips 'zeroormore_matcher) ,_1 ))"""
  ;

  //$ Postfix plus (+).
  //$ One or more repetitions.
  sparser[ppostfix_pri] := sparser[ppostfix_pri] "+" =>#
    """`(ast_apply ,_sr ( ,(qnoi 'BaseChips 'oneormore_matcher) ,_1 ))"""
  ;

  //$ Postfix question mark (?).
  //$ Optional. Zero or one repetitions.
  sparser[ppostfix_pri] := sparser[ppostfix_pri] "?" =>#
    """`(ast_apply ,_sr (,(qnoi 'BaseChips 'optional) ,_1 ))"""
  ;
// end suspect combinators
/////////

  //$ Group psuedo function.
  sparser[patom_pri] := "(" sparser[palt_pri] ")" =># '_2'; 

  sparser[patom_pri] :=  "{" sexpr "}" =># "_2";

  //$ Identifier.
  sparser[patom_pri] := sname=># "`(ast_name ,_sr ,_1 ())";

  //$ Indirection
  //$ For example, the LHS of a regdef binder.
  sparser[patom_pri] := "&" sname=># """
    `(ast_apply ,_sr 
      (
        ,(qnoi 'BaseChips 'deref_first_read)
        (ast_ref ,_sr ,(nos _2))
      )
    )
  """;
 
}


