@head(1,'Dypgen')

@h = tangler('spkgs/dyplib.py')
@select(h)
caml_interfaces = [
  'dypgen/dyplib/sig',
  'dypgen/dyplib/dyp',
]

caml_implementations = [
  'dypgen/dyplib/priority_by_relation',
  'dypgen/dyplib/automaton',
  'dypgen/dyplib/gs',
  'dypgen/dyplib/parser',
]

caml_pack = [
  ("Dyp",'dypgen/dyplib/dyp',[
    'dypgen/dyplib/sig',
    'dypgen/dyplib/gs',
    'dypgen/dyplib/priority_by_relation',
    'dypgen/dyplib/automaton',
    'dypgen/dyplib/parser'
  ])
]

caml_include_paths=['dypgen/dyplib']
caml_provide_lib = 'dypgen/dyplib/dyplib'
iscr_source = ["lpsrc/dyp.pak"]
weaver_directory = 'doc/dypgen/'



@h = tangler('spkgs/pgen.py')
@select(h)
caml_include_paths=['src','dypgen/dyplib','dypgen/generators/pgen']
caml_lexes = ['dypgen/generators/pgen/pgen_lexer']
caml_implementations=[
  'dypgen/generators/pgen/pgen_parser_param',
  'dypgen/generators/pgen/pgen_lexer'
]
caml_provide_lib = 'dypgen/generators/pgen/pgen'
caml_require_libs = ['flx_version','dyplib','pgen']
caml_exes = ['dypgen/generators/pgen/pgen']
iscr_source = ["lpsrc/dyp.pak"]
weaver_directory = 'doc/dypgen/'
pkg_requires = ['flx_version','dyplib']


@h = tangler('spkgs/dypgen.py')
@select(h)
caml_lexes = [
  'dypgen/generators/dypgen/dypgen_lexer',
  'dypgen/generators/dypgen/insert_linenum'
]

caml_pgenparses = ['dypgen/generators/dypgen/dypgen_parser']
caml_interfaces =[
  'dypgen/generators/dypgen/parse_tree',
  'dypgen/generators/dypgen/dypgen_parser',
]
caml_implementations=[
  'dypgen/generators/dypgen/argument',
  'dypgen/generators/dypgen/dypgen_parser',
  'dypgen/generators/dypgen/dypgen_lexer',
  'dypgen/generators/dypgen/insert_linenum',
]
caml_include_paths=['src','dypgen/dyplib','dypgen/generators/dypgen']
caml_provide_lib = 'dypgen/generators/dypgen/dypgen'
caml_require_libs = ['flx_version','dyplib','dypgen']
caml_exes = ['dypgen/generators/dypgen/dypgen']
iscr_source = ["lpsrc/dyp.pak"]
pkg_requires = ['flx_version','dyplib','pgen']
weaver_directory = 'doc/dypgen/'

@h=tangler('dypgen/dyplib/dyp.mli')
@select(h)
module Parser :
sig
  module Make :
    functor (E : Sig.Parser_parameters) ->
sig


  module Dyp_tools :
  sig

    val dypgen_verbose : int ref
    type token_name = int
    type non_ter = int
    type 'a pliteral =
      | Ter of token_name
      | Non_ter of 'a

    type priority
    val default_priority : priority (* = 0 *)
    (** Priority assigned to the rule S' -> S. *)

    type non_terminal_priority =
      | No_priority
      | Eq_priority of priority
      | Less_priority of priority
      | Lesseq_priority of priority
      | Greater_priority of priority
      | Greatereq_priority of priority
    (** This type makes possible to assign precedence to non terminals in
        the rhs of rules.
        If the non_terminal_priority of the non terminal E in the following 
        rule : A -> E  is Less_priority pc1, and that the parser has so far 
        reduced a substring to E yielding the priority class pc2 for this
        substring, then the parser reduces with A -> E to A only if we have
        the relation pc1 -> pc2 in the priority set used to construct the 
        parsing_device (see below create_parsing_device).
          The Toeq constructor behaves the same way except that it also 
        accepts pc1 for priority class of the substring even if we don't
        have pc1 -> pc1 in the priority set. *)

    type priority_data
    val empty_priority_data : priority_data
    val is_relation : priority_data -> priority -> priority -> bool
    val insert_priority : priority_data -> string -> (priority_data * priority)
    val find_priority : priority_data -> string -> priority

(* this set p1<p2 true if b=true and false if b=false *)
    val set_relation : priority_data -> bool -> priority -> priority ->
      priority_data

    val update_priority : priority_data -> (priority * priority * bool) list ->
        priority_data
      (** [update_priority ps [pc1,pc2,true]]
      adds the binary relation [pc1] -> [pc2] to [ps]
      [update_priority ps [pc1,pc2,false]]
      removes the relation [pc1] -> [pc2] from [ps] if it exists. *)

    val add_list_relations : priority_data -> (priority list) -> priority_data
      (** [add_list_relation ps [p1;...;p2]] adds the relations
      [p1:p2],...,[p1:pn],[p2:p3],...,[p2:pn],...,[p(n-1):pn] to ps. *)

    type lit = (int * non_terminal_priority) pliteral
    type rule = non_ter * (lit list) * priority

    exception Giveup
    (** This exception can be raised by an action, then the parser gives
        up the current reduction and the parsing along the current path is
        stopped. *)

    exception Syntax_error
    (** This exception is raised by glrParse if the parser is stuck in a
    situtation where no shift and no reduction is possible. *)
    type 'obj merge_function = 'obj list -> 'obj -> ('obj list)
    type 'obj merge_map
    val keep_all : 'a list -> 'a -> 'a list
    val keep_oldest : 'a list -> 'a -> 'a list
    val keep_newest : 'a list -> 'a -> 'a list

  end


  module Special_types :
  sig
    type automaton_kind = LR0 | LALR | LR1
    type datadyn

    type ('obj,'data,'local_data) action =
      Dypgen_action of ( 'obj list -> (Lexing.position * Lexing.position) ->
        (Lexing.position * Lexing.position) list -> 'data -> datadyn ->
        'local_data -> Dyp_tools.priority_data ->
        ('obj * bool * 'data * datadyn * 'local_data *
        ((Dyp_tools.rule * ('obj,'data,'local_data) action) list)
        * (Dyp_tools.rule list) * Dyp_tools.priority_data) )
    (** Type of the actions bound to rules in the grammar. A classic action
        takes as argument one obj for each symbol in the right hand side
        of its associated rule and returns an obj. This makes possible to
        build an abstract syntax tree, arguments objects being subtrees, or
        to compute values. A dynamic action does the same thing and in
        addition it returns a list of couples (rule,action) to be added to
        the grammar and a list of rules to be removed from the grammar.
        The boolean tells whether the possibility of a shift must be
        regarded or not. data and priority_data are accessible to the 
        actions and local_data for the dynamic ones. *)
  end




module Dypgen_runtime_tools :
sig
  val add_nt : string -> Special_types.datadyn ref -> Dyp_tools.non_ter
  val find_nt : string -> Special_types.datadyn -> Dyp_tools.non_ter
  val init_datadyn : string list -> Special_types.datadyn
  val init_merge_map : ('obj Dyp_tools.merge_function * int) list ->
    'obj Dyp_tools.merge_map
  val empty_datadyn : Special_types.datadyn
  val empty_merge_map : 'obj Dyp_tools.merge_map
  type ('global_data,'local_data) data_equal = {
    global_data_equal : 'global_data -> 'global_data -> bool;
    local_data_equal : 'local_data -> 'local_data -> bool }
  val automaton_kind : Special_types.automaton_kind ref
end


module type Parser_type =
sig
  type ('obj,'b,'c) parsing_device
    (** Abstract type of a structure which contains an parsing_device, the
    grammar associated to it and the actions associated to the grammar and
    other data. *)

  val create_parsing_device :
    (Dyp_tools.rule * ('obj,'data,'local_data) Special_types.action) list ->
    Dyp_tools.priority_data -> Special_types.automaton_kind -> 'data ->
    'local_data -> 'obj Dyp_tools.merge_map -> 'obj Dyp_tools.merge_function ->
    Special_types.datadyn -> ('obj,'data,'local_data) parsing_device
    (** Returns the parsing_device which parses strings written with the input
        grammar and assuming the relations between priority classes which
        are contained in the input priority data. *)

  val update_parsing_device_data : ('obj,'data,'local_data) parsing_device ->
    'data -> 'local_data -> ('obj,'data,'local_data) parsing_device

  val glrParse : ('obj,'data,'local_data) parsing_device ->
        (E.token -> 'obj) -> int ->
        ('data,'local_data) Dypgen_runtime_tools.data_equal -> ('a -> E.token) ->
        'a -> ('a -> (Lexing.position * Lexing.position)) ->
        (('obj * Dyp_tools.priority) list)
    (** Given a parsing_device and a list of tokens (the input string),
        [glrParse] returns the list of the parse objects of the input string.
        If there is no ambiguity there is only one object in the list. The
        list may be a forest of abstract syntax trees or a list of computed
        values.
        [int] is the name of the entry point. *)
end

        module Parser_PIA : Parser_type
        module Parser_PAR : Parser_type
      end
end

@h=tangler('dypgen/dyplib/sig.mli')
@select(h)
module type Parser_parameters =
sig
  type token
    (** Type of the tokens in the input string.
        Typically a sum of type constructors like :
        [Int of int | Bool of bool | Plus | Time | Equal | EOF].
        One of the constant constructors must stand for the end of the input
        string. *)

(*  type int*)
    (** Type of the tokens' names used to construct rules.
        It should "match" the [token] type. The difference between [token]
        and [int] is that [token] is used to construct the input string
        and [int] to construct production rules. Therefore there is no
        "value" bound to [int] but there may be to [token]. *)

  val dummy_token_name : int
    (** A int value different from any int values used. *)
  val token_epsilon : int
    (** A value used to represent epsilon rules during the parsing
        but an epsilon rule should not use it, instead the rhs of an
        epsilon rule should be empty.
        It should be different from any int values used. *)
(*  val compare_token_name : int -> int -> int
    (** A total ordering function over the tokens' names, for data
        structure management. [Pervasives.compare] is suitable. *)*)
  val get_name : token -> int
    (** Associates tokens to their names. *)
  val str_token : token -> string
  val str_token_name : int -> string
    (** Makes possible to display relevant error messages about
        tokens' names and rules *)

  (*type int*)
    (** Type of the non terminals' names used to construct rules. For instance
        it may be a sum like [Start | StartPrime | Expression | Identifier]
        or [int] or [string]. *)

  val entry_points : int list
    (** These are the entry points of the grammar *)
  val non_terminal_startprime : int
    (** This is the S' symbol of LR(1) 'modified' grammar.
        It should not be used in the rules of the grammar. *)
  val compare_ntn : int -> int -> int
    (** A total ordering function over the non terminals' names, for data
        structure management. [Pervasives.compare] is suitable. *)
  val str_non_terminal : int -> string
    (** Makes possible to display relevant error messages about non terminals'
        names and rules *)

  (*val global_data_equal : 'data -> 'data -> bool
    (** Are two data values equal or not ? *)
  val local_data_equal : 'local_data -> 'local_data -> bool*)

  val priority_names : string array

  val merge_warning : bool
    (** If set to true then the parser will emits a warning each time a merge
    happen. *)
  (*type lexbuf_type (** Should be Lexing.lexbuf if ocamllex is used. *)
  val lexbuf_position : lexbuf_type -> Lexing.position*)
end
(** Input signature of the functor [Parser] *)

@h=tangler('dypgen/dyplib/automaton.ml')
@select(h)
let log_channel = ref stdout

module Dyp_tools =
struct
let dypgen_verbose = ref 0


exception Giveup
exception Syntax_error
    (** This exception is raised by glrParse if the parser is stuck in a
    situtation where no shift and no reduction is possible. *)

  type token_name = int

  type 'a pliteral =
  | Ter of token_name
  | Non_ter of 'a

(*module Priority = Priority_by_relation.Make(struct type priority = int end)*)
  include Priority_by_relation

  type ('non_terminal,'nt_lit) prule_bis =
    'non_terminal * ('nt_lit pliteral list) * priority * int


  type lit = (int * non_terminal_priority) pliteral
  type non_ter = int
  type rule = non_ter * (lit list) * priority

  module Ordered_non_ter =
  struct
    type t = non_ter
    let compare = Pervasives.compare
  end
  module Nt_map = Map.Make(Ordered_non_ter)

  type 'obj merge_function = 'obj list -> 'obj -> ('obj list)
  type 'obj merge_map = 'obj merge_function Nt_map.t
  let keep_all ol o = o::ol
  let keep_oldest ol _ =
    let rec aux l = match l with [] -> [] | [c] -> [c] | _::t -> aux t in
    aux ol
  let keep_newest _ o = [o]

end
open Dyp_tools

module Ordered_int =
struct
  type t = int
  let compare = Pervasives.compare
end

module Int_map = Map.Make(Ordered_int)

(*type datadyn = ((int * int) String_map.t) * (int Int_map.t) * int*)
(* 1st map is with key : the string of the non terminal and associated values are 2 int. 1st int is the non_ter value, 2nd int is the non_ter value (an int with dypgen) of the non_terminal of the initial grammar which has the same 'type' as this non terminal.
The 2nd map associates the first int with the second int of the values of the previous map (i.e. a nt name to its 'type').
The rigthmost int is the number of non terminals in the map *)

module Special_types =
struct
  type automaton_kind = LR0 | LALR | LR1
  type datadyn = int String_map.t * int
  (* it is a map from the string of the non terminal to its number. int is the number of non terminals *)

  type ('obj,'data,'local_data) action =
    Dypgen_action of ( 'obj list -> (Lexing.position * Lexing.position) ->
      (Lexing.position * Lexing.position) list -> 'data -> datadyn ->
      'local_data -> priority_data ->
      ('obj * bool * 'data * datadyn * 'local_data *
      ((rule * ('obj,'data,'local_data) action) list)
      * (rule list) * priority_data) )
end
open Special_types

module type Automaton_parameters =
sig
  type non_terminal
  type lit_nt
  (*val str_token_name : int -> string
  val str_non_terminal : non_terminal -> string*)
  val token_epsilon : int
  val str_priority : int -> string
  val select_rule : priority_data -> lit_nt -> priority -> bool
end

module type Non_terminal_type =
sig
  type non_terminal
  type lit_nt
  val nt_of_lit : lit_nt -> non_terminal
  val str_token_name : int -> string
  val str_non_terminal : non_terminal -> string
end

module type Grammar_type =
sig
  type non_terminal
  type lit_nt
  val nt_of_lit : lit_nt -> non_terminal
  type rule_bis = (non_terminal,lit_nt) prule_bis
  module Map_r : Map.S with type key = rule_bis
  type ('a,'b,'c) grammar = (('a,'b,'c) action) list Map_r.t
  type item = rule_bis * int
  module Item_map : Map.S with type key=item
  module TNS : Set.S with type elt=token_name
  module IS :
    sig
      include Map.S with type key=item
      val insert : item -> TNS.t -> (TNS.t t) -> (TNS.t t)
      val union : (TNS.t t) -> (TNS.t t) -> (TNS.t t)
      val cut : item -> TNS.t -> (TNS.t t) -> (TNS.t t)
      val diff : (TNS.t t) -> (TNS.t t) -> (TNS.t t)
      val compare_is : (TNS.t t) -> (TNS.t t) -> int
    end
  type item_set = TNS.t IS.t
  val str_token_name : token_name -> string
  val str_non_terminal : non_terminal -> string
  type literal = lit_nt pliteral
  val str_literal : literal -> string
  val str_handle : literal list -> int -> string
  val str_token_set : TNS.t -> string
  val print_item : item -> TNS.t -> unit
end

module Grammar_struct(Ntt:Non_terminal_type) =
struct
  include Ntt
  type literal = lit_nt pliteral
  type rule_bis = (non_terminal,lit_nt) prule_bis

  module Ordered_rule_bis =
    struct
    type t = rule_bis
    let compare (nt1,l1,p1,_) (nt2,l2,p2,_) =
      Pervasives.compare (nt1,l1,p1) (nt2,l2,p2)
  end

  module Map_r = Map.Make (Ordered_rule_bis)

  type ('a,'b,'c) grammar = (('a,'b,'c) action) list Map_r.t

  (** [int] is the dot position in the item *)
  type item = rule_bis * int

  module Ordered_items =
  struct
    type t = item
    let compare = Pervasives.compare
  end
  module Item_map = Map.Make(Ordered_items)

  module Ordered_token_name =
  struct
    type t = token_name
    let compare = Pervasives.compare
  end
  module TNS = Set.Make (Ordered_token_name)

  module IS =
  struct
    include Map.Make (Ordered_items)

    let insert it tok_n_s is =
      try
        let tns = find it is in add it (TNS.union tok_n_s tns) is
      with Not_found -> add it tok_n_s is

    let union is1 is2 = fold insert is1 is2

    let cut it tok_n_s is =
      try
        let tns = find it is in
        let new_tns = TNS.diff tns tok_n_s in
        if TNS.is_empty new_tns then remove it is
        else add it new_tns is
      with Not_found -> remove it is

    let diff is1 is2 = fold cut is2 is1

    let compare_is is1 is2 = compare TNS.compare is1 is2
  end
  type item_set = TNS.t IS.t

  let str_literal lit = match lit with
    | Ter tk -> str_token_name tk
    | Non_ter nt -> str_non_terminal (nt_of_lit nt)

  let rec str_handle litl dp = match litl with
    | [] when dp = 0 -> "."
    | [] -> ""
    | t::q -> if dp=0 then ("."^(str_literal t)^" "^(str_handle q (dp-1)))
      else ((str_literal t)^" "^(str_handle q (dp-1))) 

  let str_token_set tns =
    let f tn str = str^(str_token_name tn)^"," in
    let str = TNS.fold f tns "" in
    if str = "" then "" else
    let string_length = (String.length str) in
    String.sub str 0 (string_length-1)

  let print_item ((nt,litl,_,length),dp) (tns:TNS.t) =
    Printf.fprintf !log_channel "   %s -> %s, (%s) ; length=%d\n" (str_non_terminal nt)
      (str_handle litl dp) (str_token_set tns) length

end



module Automaton_make(Gr:Grammar_type)
  (Ap:Automaton_parameters with type non_terminal=Gr.non_terminal and type lit_nt=Gr.lit_nt) =
struct
open Ap
open Gr


(** this type is used to construct the automaton. Each state in the automaton
    has a field of type [lit_trans] which is the literal of transition to
    this state. The difference with the type [literal] is that there is no
    priority attached to the non terminals. *)
type lit_trans = non_terminal pliteral
(*  | Ter of token_name
  | Non_ter of non_terminal*)

let lit_trans (lit:lit_nt pliteral) = match lit with
  | Non_ter nt -> Non_ter (nt_of_lit nt)
  | Ter t -> Ter t



(** [int] is the length of the [literal] list *)
(* type rule_bis = non_terminal_name * (literal list) * priority * int *)
(* the marker rule_kind is used by the parser. The parser checks the lookahead token to know if it can reduce only in the case of classic rule because dynamic ones can add new rules which may make the lookahead token condition irrelevant *)

(*module Grammar_module = Grammar_struct(Ntt)
include Grammar_module*)



module Ordered_item_set =
struct
  type t = TNS.t IS.t
  let compare = IS.compare_is
end

module Map_is = Map.Make(Ordered_item_set)


module OrdLi =
struct
  type t = lit_trans
  let compare = Pervasives.compare
end
module Li_map = Map.Make(OrdLi)


  (** [li] is the literal of transition from the previous states *)
module rec State :
sig
  type state = {
    mutable number : int;
    mutable li : lit_trans;
    mutable items : TNS.t IS.t;
    mutable succ_states : state Li_map.t;
    mutable pred_states : State.State_set.t Li_map.t
  }
  module State_set : Set.S with type elt = state
end
=
struct
  type state = {
      mutable number : int;
      mutable li : lit_trans;
      mutable items : TNS.t IS.t;
      mutable succ_states : state Li_map.t;
      mutable pred_states : State.State_set.t Li_map.t
    }
  module State_set =
  struct
    module Ordered_States =
    struct
      type t = state
      let compare s1 s2 = IS.compare_is s1.items s2.items
    end
    module State_set_prime = Set.Make(Ordered_States)
    include (State_set_prime:Set.S with type elt = state)
  end
end

include State

let add_edge n1 n2 =
  n1.succ_states <- Li_map.add n2.li n2 n1.succ_states;
  let state_set = try Li_map.find n1.li n2.pred_states
    with Not_found -> State_set.empty in
  let state_set = State_set.add n1 state_set in
  n2.pred_states <- Li_map.add n1.li state_set n2.pred_states

(*let mem_edge s1 s2 =
  Li_map.mem s2.li s1.succ_states*)


(*module Ordered_literal =
struct
  type t = literal
  let compare = Pervasives.compare
end

module Map_lit = Map.Make(Ordered_literal)*)
(* ATTENTION : on s'en sert dans first_on_literal pour la structure
first_memo, on distingue un non terminal avec deux non_terminal_priority
alors que ça ne sert à rien. Il faut : soit ne pas distinguer les deux,
soit s'en servir pour restreindre les lookahead set en utilisant les
priorités. *)




(** Assign unique numbers to states. *)
let number_aut (s0:state) =
  let f s (n:int) visited_v =
    if State_set.mem s visited_v then (n,visited_v,Li_map.empty) else
      (s.number <- n;
      (n+1,State_set.add s visited_v,s.succ_states))
  in
  let rec map_succ _ state (n,visited_v) =
    let n,visited_v,v_map = f state n visited_v in
    Li_map.fold map_succ v_map (n,visited_v)
  in
  let n,visited_v,vertex_map = f s0 0 State_set.empty in
  let n,visited_v = Li_map.fold map_succ vertex_map (n,visited_v) in
  n


(** STRING functions used to print the states of the automaton *)


let str_literal_trans lit = match lit with
  | Ter tk -> str_token_name tk
  | Non_ter nt -> str_non_terminal nt

let rec str_tok_list ll = match ll with
  | [] -> ""
  | [tok] -> str_literal (Ter tok)
  | tok::tl -> (str_literal (Ter tok))^","^(str_tok_list tl)


let rec str_state_succ sl =
  let f lit state str =
    str^" ["^(string_of_int state.number)^","^(str_literal_trans lit)^"]"
  in
  Li_map.fold f sl ""

let rec str_state_pred sl =
  let f lit state_set str =
    let f2 state str =
      str^" ["^(string_of_int state.number)^","^(str_literal_trans lit)^"]"
    in
    State_set.fold f2 state_set str
  in
  Li_map.fold f sl ""



let print_item_set is = IS.iter print_item is

let print_state s =
  Printf.fprintf !log_channel " State %d\n" s.number;
  Printf.fprintf !log_channel "  li : %s\n" (str_literal_trans s.li);
  Printf.fprintf !log_channel "  items :\n";
  print_item_set s.items;
  Printf.fprintf !log_channel "  next states : %s\n" (str_state_succ s.succ_states);
  Printf.fprintf !log_channel "  previous states : %s\n" (str_state_pred s.pred_states)

let rec str_lit_list litl = match litl with
  | [] -> ""
  | lit::tl -> (str_literal lit)^" "^(str_lit_list tl)

let str_rule (nt,litl,_,_) = (str_non_terminal nt)^" -> "^(str_lit_list litl)

let rec print_rule_list rl = match rl with
  | [] -> ()
  | r::t -> Printf.fprintf !log_channel " %s\n" (str_rule r); print_rule_list t


(** Used to print the content of an automaton. *)
let print_aut v0 =
  output_string !log_channel "\n"; output_string !log_channel "\n";
  output_string !log_channel
"----------------------------------- Automaton ----------------------------------\n";
  output_string !log_channel "\n";
  let f s visited_v =
    if State_set.mem s visited_v then (visited_v,Li_map.empty) else
      (print_state s;
      (State_set.add s visited_v,s.succ_states))
  in
  let rec map_succ _ state visited_v =
    let visited_v,v_map = f state visited_v in
    Li_map.fold map_succ v_map visited_v
  in
  let visited_v,vertex_map = f v0 State_set.empty in
  Li_map.fold map_succ vertex_map visited_v

let print_map m =
  let f is s =
    let () = Printf.fprintf !log_channel "state %d\n" (s.number) in
    print_item_set is
  in
  Map_is.iter f m


(* function over lists used by the closure functions *)

let no_double (comp:'a->'a->bool) l =
  let rec aux1 x l = match l with
    | [] -> []
    | y::t -> if comp x y then aux1 x t else y::(aux1 x t)
  in
  let rec aux2 l = match l with 
    | [] -> []
    | x::t -> x::(aux2 (aux1 x t))
  in aux2 l



(**** CLOSURE functions used to close an items set *****)

(*let first_on_literal (gram:('a,'b,'c) grammar) (liter:literal) =
  let rec aux1 visited_rules lit =
    match (lit_trans lit) with
    | Ter ter -> [ter]
    | Non_ter nt ->
        let aux2 r _ (lil,vr) =
          let (n,rhs,_,l) = r in
          if n = nt then
            match rhs with
              | [] -> ((Ter token_epsilon)::lil),(r::vr)
              | lit::t ->
                  if List.exists (function x -> x=r) vr
                  then (lil,vr)
                  else (lit::lil),(r::vr)
          else (lil,vr)
        in
        (* This returns all the first literals of items which lhs is nt. *)
        let (lil,updated_visited_rules) = Map_r.fold aux2 gram ([],visited_rules) in
        let litl = no_double (=) lil in
        let ll = List.map (aux1 updated_visited_rules) litl in
        no_double (=) (List.concat ll)
  in
  aux1 [] liter


let first litl look_ahead p first_memo grammar =
  let end_of_litl = end_of_list litl p in
  let end_of_litl = end_of_litl@[look_ahead] in
  let rec aux1 literal_list first_memo = match literal_list with
    | [] -> begin match look_ahead with
             | Ter tok ->
                 let _ = Printf.fprintf !log_channel "look_ahead = %s\n" (str_token_name tok) in
                 failwith "FIRST error"
             | _ -> failwith "FIRST error" end
    | lit::tl ->
        let tok_l,first_memo =
          try (Map_lit.find lit first_memo),first_memo
          with Not_found ->
            let tok_l = (first_on_literal grammar lit) in
            tok_l, (Map_lit.add lit tok_l first_memo)
        in
        if List.exists (function t -> t=token_epsilon) tok_l
        then let tok_l_rec, first_memo = aux1 tl first_memo in
          (tok_l@tok_l_rec), first_memo
        else tok_l, first_memo
  in
  let tok_l,first_memo = aux1 end_of_litl first_memo in
  (List.filter (function t -> t<>token_epsilon) (no_double (=) tok_l)),first_memo*)


let end_of_list l x =
  let rec aux l x y = match l with
    | [] -> []
    | a::b -> if x=y then a::(aux b 0 0)
        else aux b x (y+1)
  in
  aux l x 0

module Ordered_rule_bis =
struct
  type t = rule_bis
  let compare = Pervasives.compare
end

module RbS = Set.Make(Ordered_rule_bis)
module OrdNt =
struct
  type t = non_terminal
  let compare = Pervasives.compare
end
module NT_map = Map.Make(OrdNt)

let first_memo_print first_memo =
  output_string !log_channel "first_memo :\n";
  let f nt tns =
    let s = (str_non_terminal nt)^" : ("^(str_token_set tns)^")" in
    output_string !log_channel (s^"\n")
  in
  NT_map.iter f first_memo

let first litl p first_memo grammar =
  let litl = end_of_list litl p in
  
  let rec first_on_nt nt first_memo vrules (*n*) =
    (*output_string !log_channel ("first_on_nt "^(string_of_int n));*)
    let f r _ rbs =
      let (nt0,_,_,_) = r in
      if nt=nt0 && RbS.mem r vrules=false then RbS.add r rbs else rbs
    in
    let nt_rules = Map_r.fold f grammar RbS.empty in
    let aux r (tns,first_memo) =
      (*if RbS.mem r vrules then (tns,first_memo) else*)
      let vrules = RbS.add r vrules in
      let (_,litl,_,_) = r in
      let tns2,first_memo = first_on_litl litl first_memo vrules (*(n+1)*) in
      (TNS.union tns tns2),first_memo
    in
    let tns,first_memo = RbS.fold aux nt_rules (TNS.empty,first_memo) in
    let first_memo = NT_map.add nt tns first_memo in
    tns,first_memo
  
  and first_on_litl litl first_memo vrules (*n*) =
    (*output_string !log_channel ("first_on_litl "^(string_of_int n));*)
    let rec aux litl first_memo = match litl with
      | [] -> (TNS.add token_epsilon TNS.empty),first_memo
      | (Ter ter)::_ -> (TNS.add ter TNS.empty),first_memo
      | (Non_ter nt)::tl ->
          let tns,first_memo =
            try (NT_map.find (nt_of_lit nt) first_memo), first_memo
            with Not_found ->
              (first_on_nt (nt_of_lit nt) first_memo vrules (*(n+1)*))
          in
          if TNS.mem token_epsilon tns then
            let tns2,first_memo = aux tl first_memo in
            (TNS.union tns tns2),first_memo
          else tns,first_memo
    in
    aux litl first_memo
  in
  
  first_on_litl litl first_memo RbS.empty (*0*)


(* utilitarian functions used by other functions *)

(* returns rules which lhs is nt1 *)
let find_rules nt1 (gram:('a,'b,'c) grammar) =
  let aux (r:rule_bis) _ (l:rule_bis list) =
    let (nt2,_,_,_) = r in
    if nt1=nt2 then r::l
    else l
  in
  Map_r.fold aux gram []

(*
exception Find_state_failed
(* this function is used in parser.ml in reduceViaPath *)
let rec find_state vl lit = match vl with
  | [] -> raise Find_state_failed
  | v::t -> let s = Gautomaton.V.label v in
      if s.li = lit then v else find_state t lit
*)

(* AUTOMATON CREATION *)

let countst = ref 0
(** This ref counts the number of state creations. *)
let count_trans = ref 0
(** This ref counts the number of transitions between states. *)

(* ---------------------------- LR(1) automaton ---------------------------- *)

let nonkernel_items (lit:literal) (gram:('a,'b,'c) grammar) (tns:TNS.t) prio_dat = match lit with
  | Non_ter nt ->
      let f items_set r =
        let (_,_,p,_) = r in
        let b = select_rule prio_dat nt p in
        if b then IS.add (r,0) tns items_set else items_set
      in
      List.fold_left f IS.empty (find_rules (nt_of_lit nt) gram)
  | Ter _ -> failwith "Non terminal expected"

let closure (is:TNS.t IS.t) (first_memo:TNS.t NT_map.t) (gram:('a,'b,'c) grammar) prio_dat =
  let aux2 ((nt,litl,_,length),dp) (tns:TNS.t) its first_memo =
    try
      let a1 = List.nth litl dp in
      match lit_trans a1 with
        | Ter _ -> IS.empty,first_memo
        | Non_ter a1nt ->
          let tok_s,first_memo =
            if dp=(List.length litl)-1 then tns,first_memo
            else
              let f1 tok (tok_s,first_memo) =
                let tns,first_memo = (first (litl@[Ter tok]) (dp+1) first_memo gram) in
                (TNS.union tns tok_s),first_memo
              in
              TNS.fold f1 tns (TNS.empty,first_memo)
          in
          let its3 = nonkernel_items a1 gram tok_s prio_dat in
          (IS.diff its3 its),first_memo
    with Failure("nth") -> IS.empty,first_memo
  in
  let rec aux1 its1 its2 first_memo =
    (* its1 = the new items one has just added, its2 = the items one has added
       since closure's call. *)
    let f it tns (its1,its2,first_memo) =
      let its3,first_memo = aux2 it tns its2 first_memo in
      (IS.union its3 its1),(IS.union its3 its2),first_memo
    in
    let its1,its2,first_memo = IS.fold f its1 (IS.empty,its2,first_memo) in
    if its1 = IS.empty then its2,first_memo else (aux1 its1 its2 first_memo)
  in
  aux1 is is first_memo

module Ordered_lit_trans=
struct
  type t = lit_trans
  let compare = Pervasives.compare
end

module Map_lit_trans = Map.Make(Ordered_lit_trans)

let move s is_trace first_memo gram prio_dat =
  let f1 (r,dp) tns lit_map =
    let (_,litl,_,length) = r in
    if dp = length then lit_map
    else
      let lit = lit_trans (List.nth litl dp) in
      let is =
        try Map_lit_trans.find lit lit_map
        with Not_found -> IS.empty
      in
      Map_lit_trans.add lit (IS.add (r,dp+1) tns is) lit_map
  in
  let lit_map = IS.fold f1 s.items Map_lit_trans.empty in
  let f2 (lit:lit_trans) (is:TNS.t IS.t) (is_trace,first_memo,vl) =
    count_trans := !count_trans+1;
    try
      let v1 = Map_is.find is is_trace in
      add_edge s v1;
      is_trace,first_memo,vl
    with Not_found ->
      let () = countst := (!countst+1) in
      let is1,first_memo = closure is first_memo gram prio_dat in
      let v1 = {
        li = lit;
        items = is1;
        number = !countst;
        succ_states = Li_map.empty;
        pred_states = Li_map.empty
      } in
      add_edge s v1;
      (Map_is.add is v1 is_trace),first_memo,
      (Li_map.add v1.li v1 vl)
  in
  Map_lit_trans.fold f2 lit_map (is_trace,first_memo,Li_map.empty)

let build_automaton_LR1 (is0:TNS.t IS.t) (lit0:lit_trans) is_trace first_memo (gram:('a,'b,'c) grammar) prio_dat =
  let rec map_succ _ state (is_trace,first_memo) =
    let is_trace,first_memo,v_map = move state is_trace first_memo gram prio_dat in
    Li_map.fold map_succ v_map (is_trace,first_memo)
  in
  let is1,first_memo = closure is0 first_memo gram prio_dat in
  let v0 = {
    li = lit0;
    items = is1;
    number = !countst;
    succ_states = Li_map.empty;
    pred_states = Li_map.empty
  } in
  let is_trace = Map_is.add is0 v0 is_trace in
  let _,_(*first_memo*) =
    Li_map.fold map_succ
      (Li_map.add v0.li v0 Li_map.empty)
      (is_trace,first_memo)
  in
  (*first_memo_print first_memo;*)
  v0


(* --------------------------- LALR(1) automaton --------------------------- *)

let nonkernel_items_LR0 (lit:literal) (gram:('a,'b,'c) grammar) prio_dat = match lit with
  | Non_ter nt ->
      let f items_set r =
        let (_,_,p,_) = r in
        let b = select_rule prio_dat nt p in
        if b then IS.add (r,0) TNS.empty items_set else items_set
      in
      List.fold_left f IS.empty (find_rules (nt_of_lit nt) gram)
  | Ter _ -> failwith "Non terminal expected"

let closure_LR0 (is:TNS.t IS.t) (gram:('a,'b,'c) grammar) prio_dat =
  let aux2 ((nt,litl,_,length),dp) its =
    try
      let a1 = List.nth litl dp in
      match lit_trans a1 with
        | Ter _ -> IS.empty
        | Non_ter a1nt ->
            let its3 = nonkernel_items_LR0 a1 gram prio_dat in
            (IS.diff its3 its)
    with Failure("nth") -> IS.empty
  in
  let rec aux1 its1 its2 =
    (* its1 = the new items one has just added, its2 = the items one has added
       since closure's call. *)
    let f it _ (its1,its2) =
      let its3 = aux2 it its2 in
      (IS.union its3 its1),(IS.union its3 its2)
    in
    let its1,its2 = IS.fold f its1 (IS.empty,its2) in
    if its1 = IS.empty then its2 else (aux1 its1 its2)
  in
  aux1 is is

let move_LR0 s is_trace gram prio_dat =
  let f1 (r,dp) tns lit_map =
    let (_,litl,_,length) = r in
    if dp = length then lit_map
    else
      let lit = lit_trans (List.nth litl dp) in
      let is =
        try Map_lit_trans.find lit lit_map
        with Not_found -> IS.empty
      in
      Map_lit_trans.add lit (IS.add (r,dp+1) tns is) lit_map
  in
  let lit_map = IS.fold f1 s.items Map_lit_trans.empty in
  let f2 (lit:lit_trans) (is:TNS.t IS.t) (is_trace,vl) =
    count_trans := !count_trans+1;
    try
      let v1 = Map_is.find is is_trace in
      add_edge s v1;
      is_trace,vl
    with Not_found ->
      let () = countst := (!countst+1) in
      let is1 = closure_LR0 is gram prio_dat in
      let v1 = {
        li = lit;
        items = is1;
        number = !countst;
        succ_states = Li_map.empty;
        pred_states = Li_map.empty
      } in
      add_edge s v1;
      (Map_is.add is v1 is_trace),
      (Li_map.add v1.li v1 vl)
  in
  Map_lit_trans.fold f2 lit_map (is_trace,Li_map.empty)

(*module Item_map = Map.Make (Ordered_items)*)

type lookahead_info = {
  mutable la_curr :TNS.t;
  mutable la_new :TNS.t;
  mutable la_added :TNS.t
}

let init_array its_array v0 =
  let f it tns map_it =
    let fresh_lai = {
      la_curr = TNS.empty;
      la_new = tns;
      la_added = TNS.empty }
    in
    Item_map.add it fresh_lai map_it
  in
  let visited_states = Array.make (!countst+1) false in
  let rec map_succ _ v =
    let vl =
      if visited_states.(v.number) then Li_map.empty
      else
        (its_array.(v.number) <- IS.fold f v.items Item_map.empty;
        visited_states.(v.number) <- true;
        v.succ_states)
    in
    Li_map.iter map_succ vl
  in
  Li_map.iter map_succ
    (Li_map.add v0.li v0 Li_map.empty)

let init_channel its_array v0 =
  let aux v (ch_s,ch_p) =
    let f2 _ v map_lit =
      Map_lit_trans.add v.li v.number map_lit
    in
    let succ = v.succ_states in
    let map_lit = Li_map.fold f2 succ Map_lit_trans.empty in
    let f1 it _ (ch_s,ch_p) =
      let r,dp = it in
      let (ntn,litl,_,length) = r in
      if dp = length then (ch_s,ch_p) else
      let lit = List.nth litl dp in
      let lai1 = Item_map.find it its_array.(v.number) in
      let prop_to_next_state (ch_s,ch_p) =
        let next_state = Map_lit_trans.find (lit_trans lit) map_lit in
        let lai2 = Item_map.find (r,dp+1) its_array.(next_state) in
        let new_channel = (it,lai1),((r,dp+1),lai2) in
        (ch_s,(new_channel::ch_p))
      in
      let (ch_s,ch_p) = prop_to_next_state (ch_s,ch_p) in
      match lit with
        | Ter _ -> (ch_s,ch_p)
        | Non_ter nt ->
            let f it2 _ ch_list =
              let (nt2,_,_,_),dp2 = it2 in
              if nt2=(nt_of_lit nt) && dp2=0 then
                let lai2 = Item_map.find it2 its_array.(v.number) in
                let new_channel = (it,lai1),(it2,lai2) in
                new_channel::ch_list
              else ch_list
            in
            let ch_list = IS.fold f v.items [] in
            if dp = length-1 then (ch_s,(ch_list@ch_p))
            else ((ch_list@ch_s),ch_p)
    in
    IS.fold f1 v.items (ch_s,ch_p)
  in
  let visited_states = Array.make (!countst+1) false in
  let rec map_succ _ v (ch_s,ch_p) =
    let vl,ch_s,ch_p =
      if visited_states.(v.number) then Li_map.empty,ch_s,ch_p
      else
        let ch_s,ch_p = aux v (ch_s,ch_p) in
        let _ = visited_states.(v.number) <- true in
        (v.succ_states),ch_s,ch_p
    in
    Li_map.fold map_succ vl (ch_s,ch_p)
  in
  Li_map.fold map_succ
    (Li_map.add v0.li v0 Li_map.empty) ([],[])


(*let first_LALR litl p first_memo grammar =
  let end_of_litl = end_of_list litl p in
  let rec aux1 literal_list first_memo = match literal_list with
    | [] -> [],first_memo
    | lit::tl ->
        let tok_l,first_memo =
          try (Map_lit.find lit first_memo),first_memo
          with Not_found ->
            let tok_l = (first_on_literal grammar lit) in
            tok_l, (Map_lit.add lit tok_l first_memo)
        in
        if List.exists (function t -> t=token_epsilon) tok_l
        then let tok_l_rec, first_memo = aux1 tl first_memo in
          (tok_l@tok_l_rec), first_memo
        else tok_l, first_memo
  in
  let tok_l,first_memo = aux1 end_of_litl first_memo in
  (List.filter (function t -> t<>token_epsilon) (no_double (=) tok_l)),first_memo*)

let update_lookahead ch_s ch_p its_array first_memo gram =
  let add_new_la added_la lai2 b =
    let added_la = TNS.diff added_la lai2.la_added in
    let added_la = TNS.diff added_la lai2.la_new in
    let added_la = TNS.diff added_la lai2.la_curr in
    if TNS.is_empty added_la then b else
    let _ = lai2.la_added <- TNS.union lai2.la_added added_la in true
  in
  let spontaneous (b,first_memo) ((it1,lai1),(it2,lai2)) =
    let (_,litl,_,_),dp = it1 in
    let tns = lai1.la_new in
    let f1 tok (tok_s,first_memo) =
      let tns,first_memo = (first (litl@[Ter tok]) (dp+1) first_memo gram) in
      (TNS.union tns tok_s),first_memo
    in
    let added_la,first_memo =
      if TNS.is_empty tns then first litl (dp+1) first_memo gram
      else TNS.fold f1 tns (TNS.empty,first_memo)
    in
    (add_new_la added_la lai2 b),first_memo
  in
  let propagated b ((it1,lai1),(it2,lai2)) =
    add_new_la lai1.la_new lai2 b
  in
  let update_la_fields () =
    let f _ lai =
      lai.la_curr <- TNS.union lai.la_curr lai.la_new;
      lai.la_new <- lai.la_added;
      lai.la_added <- TNS.empty
    in
    for i = 0 to !countst do
      Item_map.iter f its_array.(i)
    done;
  in
  let rec loop first_memo =
    let b1,first_memo = List.fold_left spontaneous (false,first_memo) ch_s in
    let b2 = List.fold_left propagated false ch_p in
    update_la_fields ();
    if (b1 || b2) then loop first_memo else first_memo
  in
  (*Printf.fprintf !log_channel "ch_s length : %d\nch_p length : %d\n" (List.length ch_s) (List.length ch_p);*)
  let first_memo = loop first_memo in
  update_la_fields ();
  first_memo

let make_lalr_aut its_array v0 =
  let make_item_set map_item =
    let f it lai is =
      IS.add it lai.la_curr is
    in
    Item_map.fold f map_item IS.empty
  in
  let visited_states = Array.make (!countst+1) false in
  let rec map_succ _ v =
    if visited_states.(v.number) then ()
    else
      (v.items <- make_item_set its_array.(v.number);
      visited_states.(v.number) <- true;
      Li_map.iter map_succ v.succ_states)
  in
  Li_map.iter map_succ
    (Li_map.add v0.li v0 Li_map.empty)

let build_automaton_LR0 (is0:TNS.t IS.t) (lit0:lit_trans) is_trace first_memo (gram:('a,'b,'c) grammar) prio_dat =
  let rec map_succ _ v is_trace =
    let is_trace,vl = move_LR0 v is_trace gram prio_dat in
    Li_map.fold map_succ vl is_trace
  in
  let v0 = {
    li = lit0;
    items = closure_LR0 is0 gram prio_dat;
    number = !countst;
    succ_states = Li_map.empty;
    pred_states = Li_map.empty
  } in
  let is_trace = Map_is.add is0 v0 is_trace in
  let is_trace = Li_map.fold map_succ
    (Li_map.add v0.li v0 Li_map.empty) is_trace
  in is_trace,v0

let build_automaton_LALR (is0:TNS.t IS.t) (lit0:lit_trans) is_trace first_memo (gram:('a,'b,'c) grammar) prio_dat =
  let is_trace,v0 =
    build_automaton_LR0 is0 lit0 is_trace first_memo gram prio_dat in
  let its_array = Array.make (!countst+1) Item_map.empty in
  init_array its_array v0;
  let channel_spont,channel_prop = init_channel its_array v0 in
  let _ = update_lookahead channel_spont channel_prop its_array first_memo gram in
  make_lalr_aut its_array v0;
  v0


let build_automaton automaton_kind (is0:TNS.t IS.t) (lit0:lit_trans) is_trace first_memo (gram:('a,'b,'c) grammar) verbose nt_nb prio_dat =
  countst := 0;
  count_trans := 0;
  let time1 = Sys.time () in
  let v0 = match automaton_kind with
    | LR0 -> let _,v0 =
        build_automaton_LR0 is0 lit0 is_trace first_memo gram prio_dat in v0
    | LALR -> build_automaton_LALR is0 lit0 is_trace first_memo gram prio_dat
    | LR1 -> build_automaton_LR1 is0 lit0 is_trace first_memo gram prio_dat
  in
  let time2 = Sys.time () in
  if verbose>0 then
    (let str_aut_kind = match automaton_kind with
      LR0 -> "LR(0)" | LALR -> "LALR(1)" | LR1 -> "LR(1)" in
    Printf.fprintf !log_channel "%s automaton built, %d states, %d transitions, %.3f sec\n"
    str_aut_kind (!countst+1) (!count_trans+1) (time2-.time1);
    flush stdout) else ();
  v0





(** The following functions are used to cover 2 automatons to test whether
    they are equal. *) 

let eq_vertex s1 s2 =
  if s1.li<>s2.li then false else
  if (IS.compare_is s1.items s2.items)=0 then true
  else false

exception Look_for_lit_failed

let eq_next n1 v2 =
  let aux1 _ v l = v.li::l in
  let key_list = Li_map.fold aux1 n1 [] in
  let aux2 key = (Li_map.find key v2.succ_states) in
  try (true,List.map aux2 key_list) with Not_found -> (false,[])
(*
let eq_aut automaton1 automaton2 =
  let n1 = number_aut automaton1 in
  let n2 = number_aut automaton2 in
  if n1<>n2 then false else
  if eq_vertex automaton1.init automaton2.init = false then false else
  let next1 = automaton1.init.succ_states in
  let b,next2 = eq_next next1 automaton2.init in
  if b = false then false else
  let rec aux n1 n2 vv b =
    if b = false then false,vv else
    match (n1,n2) with
      | ([],[]) -> true,vv
      | (_,[]) -> false,vv
      | ([],_) -> false,vv
      | (v1::t1,v2::t2) -> if State_set.mem v1 vv then aux t1 t2 vv true else
          let new_vv = State_set.add v1 vv in
          let bb = eq_vertex v1 v2 in
          if bb = false then false,new_vv else
          let next1 = v1.succ_states in
          let bb,next2 = eq_next next1 v2 in
          if bb = false then false,new_vv else
          let b,new_vv = aux next1 next2 new_vv true in
          if b = false then (false,new_vv) else aux t1 t2 new_vv true
  in
  let b,vv = aux next1 next2 (State_set.add automaton1.init State_set.empty) true in
  b
*)
end

@h=tangler('dypgen/dyplib/parser.ml')
@select(h)
open Sig

(** The way this module handles GLR is documented in the following paper :
Scott McPeak, Elkhound: A fast, practical GLR parser generator, University of 
California Berkeley, Report No. UCB/CSD-2-1214, December 2002 ; figures 7 and 8.
Optimizations which are specific to Elkhound are not implemented.

This implementation adds dynamic changes to the grammar at run-time during 
parsing. These modifications take place in the function reduceViaPath. 

When a reduction is performed the parser checks whether the action is 'classic' 
(no change to the grammar) or 'dynamic' and proceeds with the modifications to 
the grammar and the automaton if needed. If the parsing follows simultaneously 
several paths, as it may be the case with GLR parsing, then there is a distinct 
grammar and a distinct automaton for each path if needed.

Following Scott McPeak's report the stack is implemented as a graph.
*)
module Make(E:Parser_parameters) =
struct
open E

include Automaton
open Special_types
open Dyp_tools

let countred = ref 0
(* counts the number if reductions performed
it is only used for information *)

type counters = {
  countsn : int;
  counted : int;
  count_token : int }

open Gs



module Ordered_urule =
struct
  type t = rule
  let compare = Pervasives.compare
end

module Urule_map = Map.Make(Ordered_urule)
type ('a,'b,'c) user_grammar = (('a,'b,'c) action) list Urule_map.t

module type Other_parameters =
sig
  type non_terminal
  type lit_nt
  (*val str_non_terminal : non_terminal -> string*)
  val select_rule : priority_data -> lit_nt -> priority -> bool
  val non_ter_of_nt : non_terminal -> int
  type ('a,'b,'c) grammar
  val make_real_grammar : ('a,'b,'c) user_grammar -> priority_data ->
    (('a,'b,'c) grammar * int)
  type prio_imprint
  type item_set
  val new_prio_imprint : priority_data -> prio_imprint -> item_set ->
    (non_terminal pliteral) -> priority -> (prio_imprint * bool)
  val print_prio_imp : prio_imprint -> unit
  val default_prio_imp : prio_imprint
  val prio_imp_equal : prio_imprint -> prio_imprint -> bool
  type rule_bis
  val entry_point_prio :
    non_ter -> prio_imprint -> (non_terminal pliteral) -> priority
  val prio_imprint_check : rule_bis -> int -> prio_imprint -> bool
  val str_with_priority : priority -> string
end

module NTS = Set.Make(Ordered_non_ter)


module Dypgen_runtime_tools =
struct
  let automaton_kind = ref LR0

  type ('global_data,'local_data) data_equal = {
    global_data_equal : 'global_data -> 'global_data -> bool;
    local_data_equal : 'local_data -> 'local_data -> bool }

  let add_nt (s:string) (datadyn:(Special_types.datadyn ref)) =
    let nt_map,n = !datadyn in
    try String_map.find s nt_map
    with Not_found ->
      (datadyn :=
        (String_map.add s (n+1) nt_map),(n+1);
      (n+1))

  let find_nt s datadyn = String_map.find s (fst datadyn)

  let init_datadyn sl =
    let aux (dd,n) s = (String_map.add s n dd),(n+1) in
    List.fold_left aux (String_map.empty,1) sl

  let init_merge_map (mnl:('obj merge_function * int) list) =
    let aux mm (mf,nt) = Nt_map.add nt mf mm in
    List.fold_left aux Nt_map.empty mnl

  let empty_datadyn = (String_map.empty,0)

  let empty_merge_map = Nt_map.empty
end

open Dypgen_runtime_tools

module Parser(Gr:Grammar_type)(F:Other_parameters with type non_terminal = Gr.non_terminal and type lit_nt = Gr.lit_nt and type ('a,'b,'c) grammar = ('a,'b,'c) Gr.grammar and type item_set = Gr.item_set and type rule_bis = Gr.rule_bis) =
struct

open F
open Gr


module Aut_param =
struct
  type non_terminal = Gr.non_terminal
  type lit_nt = Gr.lit_nt
  let str_priority p = priority_names.(p)
  let token_epsilon = E.token_epsilon
  let select_rule = F.select_rule
end

module Automat = Automaton_make(Gr)(Aut_param)
open Automat
open Aut_param


type ('a,'b,'c) grammar = ('a,'b,'c) Gr.grammar

(* ******* CE QUI SUIT EST A DEPLACER DANS UN AUTRE FICHIER ****** *)




module Ordered_ntcouple =
struct
  type t = non_ter * non_ter
  let compare = Pervasives.compare
end
module Map_ntc = Map.Make(Ordered_ntcouple)

module OrdPrioNb =
struct
  type t = int * int
  let compare = Pervasives.compare
end
module PrioNb_set = Set.Make(OrdPrioNb)

type ('obj,'data,'local_data) parsing_device = {
  g : ('obj,'data,'local_data) grammar;
  user_g : ('obj,'data,'local_data) user_grammar;
  init : state;
  po : bool Map_ntc.t;
    (** Patial order between non terminal name couples. A couple of non
     terminals is bound to a bool. This may be implemented alternatively
     with a set : the presence of a couple (nt1,nt2) in the set would
     denote that nt1<=nt2 is true. This would save memory space. *)
  data : 'data;
  prio : priority_data;
  local_data : 'local_data;
  datadyn : datadyn;
  merge_map : 'obj merge_map;
  global_merge : 'obj merge_function;
  aut_kind : automaton_kind;
  nt_nb : int (* number of non terminals in the 'new' grammar *)
}

(*type saved_parsing_device = {
  sa_init : state;
  sa_po : bool Map_ntc.t
}*)

module Ordered_rule =
struct
  type t = rule
  let compare = Pervasives.compare
end

module RS = Set.Make (Ordered_rule)

(* This function decides if the non terminal nt1 can derive the non terminal
nt2 and stores the results in po_map. If it needed to decide whether another
non terminal nt can derive nt2 then it stores it too in po_map. nt_epsilon
stores the non terminals which can derive epsilon.*)
let derive nt1 nt2 user_g po_map nt_epsilon =

  let rec derive_epsilon nt nt_epsion vr =
    try (Nt_map.find nt nt_epsilon),nt_epsilon with Not_found ->
    let f r _ (b,nt_epsilon) =
      let (nt,l,_) = r in
      if b then true,nt_epsilon else
      if nt<>nt1 then false,nt_epsilon else
      if RS.mem r vr then false,nt_epsilon else
      match l with
        | [] -> true,nt_epsilon
        | litl -> begin
            let rec f2 litl =
              match litl with
                | (Non_ter (nt,_))::t -> nt::(f2 t)
                | _ -> []
            in
            let ntl = f2 litl in
            if (List.length ntl)<>(List.length ntl) then false,nt_epsilon
            else
            let rec f3 (ntl:non_ter list) nt_epsilon =
              match ntl with
                | [] -> true,nt_epsilon
                | nt::t ->
                    let b,nt_epsilon =
                      let b,nt_epsilon = derive_epsilon nt nt_epsilon (RS.add r vr) in
                        b,(Nt_map.add nt b nt_epsilon)
                    in
                    if b then f3 t nt_epsilon
                    else false,nt_epsilon
            in
            f3 ntl nt_epsilon
        end
    in
    Urule_map.fold f user_g (false,nt_epsilon)
  in

  let rec aux nt1 nt2 vr po_map nt_epsilon =
    try (Map_ntc.find (nt1,nt2) po_map),po_map,nt_epsilon with Not_found ->
    let f r _ (b,po_map,nt_epsilon) =
      let (nt,l,_) = r in
      if b then true,po_map,nt_epsilon else
      if nt<>nt1 then false,po_map,nt_epsilon else
      if RS.mem r vr then false,po_map,nt_epsilon else
      match l with
        | [Non_ter (ntbis,_)] when ntbis=nt2 -> true,po_map,nt_epsilon
        | [Non_ter (ntbis,_)] ->
            let b,po_map,nt_epsilon = aux ntbis nt2 (RS.add r vr) po_map nt_epsilon in
            b,(Map_ntc.add (ntbis,nt2) b po_map),nt_epsilon
        | litl -> begin
            let rec f2 litl =
              match litl with
                | (Non_ter (nt,_))::t -> nt::(f2 t)
                | _ -> []
            in
            let ntl = f2 litl in
            if (List.length ntl)<>(List.length ntl) then false,po_map,nt_epsilon
            else
            let rec f3 n1 n2 ntl po_map nt_epsilon =
              match ntl with
                | [] -> true,po_map,nt_epsilon
                | nt::t ->
                    let b,po_map,nt_epsilon =
                      if n1=n2 then let b,po_map,nt_epsilon = aux nt nt2 (RS.add r vr) po_map nt_epsilon in
                        b,(Map_ntc.add (nt,nt2) b po_map),nt_epsilon
                      else let b,nt_epsilon = derive_epsilon nt nt_epsilon RS.empty in
                        b,po_map,(Nt_map.add nt b nt_epsilon)
                    in
                    if b then f3 (n1+1) n2 t po_map nt_epsilon
                    else false,po_map,nt_epsilon
            in
            let rec f4 n po_map nt_epsilon = match n with
              | 0 -> false,po_map,nt_epsilon
              | _ -> let b,po_map,nt_epsilon = f3 1 n ntl po_map nt_epsilon in
                  if b then true,po_map,nt_epsilon
                  else f4 (n-1) po_map nt_epsilon
            in
            f4 (List.length ntl) po_map nt_epsilon
        end
    in
    Urule_map.fold f user_g (false,po_map,nt_epsilon)
  in
  let b,po_map,nt_epsilon = aux nt1 nt2 RS.empty po_map nt_epsilon in
  b,(Map_ntc.add (nt1,nt2) b po_map),nt_epsilon

let create_aut (gram:('a,'b,'c) grammar) init_is lit nt_nb prio_dat =
  let () = countst := 0 in
  let v = build_automaton !automaton_kind init_is lit Map_is.empty
    NT_map.empty gram !dypgen_verbose nt_nb prio_dat in
  v

(*let create_po user_g =
  let collect_nt (nt,_,_) _ nts = NTS.add nt nts in
  let nt_set = Urule_map.fold collect_nt user_g NTS.empty in
  let cover_nts nt1 (po_map,nt_epsilon) =
  (* nt_epsilon is used to record whether a non terminal can derive epsilon *)
    let aux nt2 (po_map,nt_epsilon) =
      if Map_ntc.mem (nt1,nt2) po_map then po_map,nt_epsilon
      else derive nt1 nt2 user_g po_map nt_epsilon
    in
    NTS.fold aux nt_set (po_map,nt_epsilon)
  in
  let po_map,_ = NTS.fold cover_nts nt_set (Map_ntc.empty,Nt_map.empty) in
  po_map*)

let create_po user_g =
  let collect_nt (nt,_,_) _ nts = NTS.add nt nts in
  let nt_set = Urule_map.fold collect_nt user_g NTS.empty in
  let cover_nts nt1 (po_map,nt_epsilon) =
  (* nt_epsilon is used to record whether a non terminal can derive epsilon *)
    let aux nt2 (po_map,nt_epsilon) =
      (*if Map_ntc.mem (nt1,nt2) po_map then po_map,nt_epsilon
      else let _,pm,nte = derive nt1 nt2 user_g po_map nt_epsilon in pm,nte*)
      let b,po_map,nt_epsilon =
        try (Map_ntc.find (nt1,nt2) po_map),po_map,nt_epsilon
        with Not_found -> derive nt1 nt2 user_g po_map nt_epsilon
      in
      if b && nt1=nt2 then
        let () = Printf.fprintf stderr
          "Error: non terminal %s can derive itself, cyclic grammars are not allowed\n"
          (E.str_non_terminal nt1) in
        failwith "cyclic grammar"
      else po_map,nt_epsilon
    in
    NTS.fold aux nt_set (po_map,nt_epsilon)
  in
  let po_map,_ = NTS.fold cover_nts nt_set (Map_ntc.empty,Nt_map.empty) in
  po_map


let create_parsing_device_with_init (gram:('a,'b,'c) grammar) user_g
    (data:'b) datadyn (local_data:'c) (pcs:priority_data) merge_map
    global_merge init_is lit nt_nb po_map =
  let v = create_aut (gram:('a,'b,'c) grammar) init_is
    lit nt_nb pcs in
  let parsing_device = { g = gram ; user_g = user_g ; init = v ; po = po_map ;
    data = data; local_data = local_data ; datadyn = datadyn ; prio = pcs ;
    merge_map = merge_map; global_merge = global_merge ; aut_kind = !automaton_kind ;
    nt_nb = nt_nb } in
  parsing_device


let init_is g =
  let tns = TNS.add dummy_token_name TNS.empty in
  let aux r _ is =
    let (nt,_,_,_) = r in
    if non_ter_of_nt nt = non_terminal_startprime then
      (IS.add (r,0) tns is)
    else is
  in
  Map_r.fold aux g IS.empty

let init_lit = Ter dummy_token_name

let create_parsing_device_bis (gram:('a,'b,'c) grammar) aut_kind (data:'b)
    (local_data:'c) (pcs:priority_data) merge_map global_merge nt_nb
    po_map user_g datadyn =
    (* gram must already contain the rules S' -> entry_point *)
  automaton_kind := aut_kind;
  create_parsing_device_with_init gram user_g data
    datadyn local_data pcs
    merge_map global_merge (init_is gram) init_lit nt_nb po_map


let update_parsing_device_data automaton dat ldat =
  { automaton with data=dat ; local_data = ldat }

(*let create_saved_parsing_device gram nt_nb prio_dat =
  let v , po_map = create_a_and_po (gram:('a,'b,'c) grammar)
    (init_is gram) init_lit nt_nb prio_dat in
  { sa_init = v ; sa_po = po_map }

let complete_parsing_device sa gram aut_kind data local_data priodata
    merge_map global_merge nt_nb =
  { g = gram ; init = sa.sa_init ; po = sa.sa_po ;
  data = data ; local_data = local_data ; prio = priodata ; merge_map = merge_map;
  global_merge = global_merge ; aut_kind = aut_kind ; nt_nb = nt_nb }*)


(*let empty_grammar = Map_r.empty*)



let update_user_g ral user_g =
  let f user_g (r,a) =
    let al = try Urule_map.find r user_g with Not_found -> [] in
    Urule_map.add r (a::al) user_g
  in
  List.fold_left f user_g ral

let make_grammar ral prio_dat =
  let user_g = update_user_g ral Urule_map.empty in
  let po_map = create_po user_g in
  let g,nt_nb = make_real_grammar user_g prio_dat in
  g,nt_nb,po_map,user_g


let create_parsing_device rapf_list priority_data aut_kind global_data local_data merge_map merge datadyn =
  let current_grammar,nt_nb,map_po,user_g =
    make_grammar rapf_list priority_data
  in
  create_parsing_device_bis current_grammar aut_kind global_data local_data
    priority_data merge_map merge nt_nb map_po user_g datadyn


(** UPDATE AUTOMATON used in reduceViaPath to change the grammar and the automaton
    when new rule_with_lengths are added and old ones are removed. *)

let remove_from_user_g rl user_g =
  let f user_g r = Urule_map.remove r user_g in
  List.fold_left f user_g rl

let update_parsing_device parsing_device ral_add r_remove newdata newdatadyn
    newlocal_data newprio s_rightSib =
  let user_g = remove_from_user_g r_remove parsing_device.user_g in
  let user_g = update_user_g ral_add user_g in
  let po_map = create_po user_g in
  let g,nt_nb = make_real_grammar user_g parsing_device.prio in
  let init_is_updated_parsing_device =
    let f (it:item) tns (is:TNS.t IS.t) =
      let (_,dp) = it in
      if dp=0 then is
      else
        IS.insert it tns is
    in
    IS.fold f s_rightSib.items IS.empty
  in
  (* All the kernel items are selected in the current state after the reduction
   happened. An items set is made with them and used as the starting state of a
   new automaton. *)
  create_parsing_device_with_init g user_g newdata newdatadyn newlocal_data
    parsing_device.prio parsing_device.merge_map parsing_device.global_merge
    init_is_updated_parsing_device s_rightSib.li nt_nb po_map

(* ******* CE QUI PRECEDE EST A DEPLACER DANS UN AUTRE FICHIER ****** *)







type ('obj,'data,'local_data) vertex_lab = {
  aut_vertex : state;
  pdev : ('obj,'data,'local_data) parsing_device;
  sn_nb : int;
  token_shifted : int;
  lexer_pos : (Lexing.position * Lexing.position);
  prio_imprint : F.prio_imprint
}
(* sn_nb is the number of the stack node, which is useful to distinguish
the stack nodes.
token_shifted is the token number (how many token were shifted
when the stack node was created).

prio_imprint : stack node should not be merged if there is an item i and
a non terminal nt in the rhs of i before the 'dot' such that nt was yielded
with two different priorities. This ensures that when two stack nodes are
merged, the "history of priorities" is the same. Thus, for any stack nodes
each items is either 'valid' with respect to the priorities of all paths
from this node or it is not valid for all paths. This validity is stored
in the bool. The priority list is the history of priorities.
Before being merged, two stack nodes must have the same prio_imprint,
see the function find_rightSib
*)

type 'obj edge_lab = 'obj list * int

type ('a,'b) path = ('a,'b) Gs.vertex * (('a,'b) Gs.edge list) * int
(** Gs.vertex is for the start of the path, int is the token number, i.e.
the first token in the part of the input which would be reduced if a reduction
along this path of the graph-structured stack happens. *)

(** [find_paths] returns a list of couples ([path],[token_nb]), where a path is
    a list of edges of the graph structured stack [gs] . The returned paths
    have the following properties : they begin at stack node [sn], their length
    is [len], the nodes along each path contain states which associated
    literals are in [litl], these literals take place along the path in the
    same order as in the list [litl] (actually in reverse). These paths are the
    ones along which a reduction can be performed by a production rule which
    rhs is [litl].
    [token_nb] is the token number of the leftmost stack node of a path, i.e.
    the dest stack node of the edge which is at the end of the list of edges
    which is [path]. It is the number of the token which is the first in the
    part of the input which would be reduced by the rule given as argument.
    [find_paths] is used in [doReductions] and in [insertLimitedReductions]
    and in [insertLimitedReductions2]. *)
let find_paths (sn:('a,'b) Gs.vertex) (r:rule_bis) =
  let (_,litl,_,len) = r in
  let b = prio_imprint_check r len sn.vertex_label.prio_imprint in
  if b = false then [] else
  let rec aux n rev_litl succ path =
    if n = 0 then match path with
      | e::_ -> let s = e.dest in [path,(s.vertex_label).token_shifted]
      | [] -> [[],-1]
    else
    match succ with
      | [] -> []
      | e::t -> let sn1 = e.source in
          let sn2 = e.dest in
          let v = (sn1.vertex_label).aut_vertex in
          match rev_litl with
            | [] -> failwith "error find_paths, bad rule_bis length"
            | li::tl ->
                if (lit_trans li) = v.li then
                  let succ2 = sn2.succ_edges in
                  (aux (n-1) tl succ2 (e::path))@(aux n rev_litl t path)
                else
                  (aux n rev_litl t path)
  in
  aux len (List.rev litl) sn.succ_edges []

let stack_node_equal sn1 sn2 = sn1.vertex_label.sn_nb = sn2.vertex_label.sn_nb

let edge_equal e1 e2 = (snd e1.edge_label) = (snd e2.edge_label)
let edge_list_equal el1 el2 = List.for_all2 edge_equal el1 el2

(** Maintains a partially ordered list of couples (path,rule_bis), where a path is 
    a list of edges of the graph structured stack. This function inserts the couple 
    of the path [p] and the rule_bis [r] in the list [l] at its right place. The 
    partial order is the field [po] of the state which is held by the source 
    stack node of the first edge of the path [p].
    The partial order is implemented as a map with key a couple of non terminals which 
    is bound to true or false. The need for this partial order is explained in 
    Scott McPeak's report. A better data structure than a list should be used. *)
let insert_partially_ordered l (((start_node,p,token_nb):('a,'b) path),r) =
  let (nt,litl,_,len) = r in
  if non_ter_of_nt nt = non_terminal_startprime then l (* Do not reduce with S'->S *)
  else
  let parsing_device = start_node.vertex_label.pdev in
  let rec aux l = match l with
    | [] -> [((start_node,p,token_nb),r)]
    | ((start1,p1,tnb1),r1)::tl ->
        if tnb1<token_nb then ((start_node,p,token_nb),r)::l
        else
        if tnb1>token_nb then ((start1,p1,tnb1),r1)::(aux tl)
        else
        let (nt1,litl1,_,_) = r1 in
        let parsing_device1 = start1.vertex_label.pdev in
        let b = Map_r.equal (==) parsing_device.g parsing_device1.g in
        if b = false then ((start1,p1,tnb1),r1)::(aux tl)
        else
        (*let (unt1,_,_),(unt,_,_) = nt1,nt in*)
        let rel = Map_ntc.find ((non_ter_of_nt nt1),(non_ter_of_nt nt))
          parsing_device.po in
        if rel then  ((start_node,p,token_nb),r)::l
        else if nt=nt1 && litl=litl1 && (stack_node_equal start_node start1)
          && (edge_list_equal p p1) then l
        else ((start1,p1,tnb1),r1)::(aux tl)
  in
  aux l

let print_path sn p =
  let snnb = sn.vertex_label.sn_nb in
  let () = Printf.fprintf !log_channel "sn:%d; " snnb in flush_all ();
  let f e =
    let _,ednb = e.edge_label in
    Printf.fprintf !log_channel "%d " ednb
  in
  let () = List.iter f p in
  Printf.fprintf !log_channel "\n"

let insertLimitedReductions pathList link (*t*) topmost =
  let _,edge_nb = link.edge_label in
  let aux1 (pathList:(('a,'b) path * rule_bis) list) sn =
    let v,aut = sn.vertex_label.aut_vertex,sn.vertex_label.pdev in
    let aux2 (r,dp) tns pathList =
      let (_,_,_,len) = r in
      if dp = len (*&& (!automaton_kind=LR0 || (TNS.mem t tns) ||
         (TNS.mem dummy_token_name tns) || (rule_kind=Dynamic_rule))*) then
        let paths = find_paths sn r in
        let aux3 pathList (p,tnb) =
          if List.exists (function e -> (snd e.edge_label)=edge_nb) p then
            let () = if !dypgen_verbose>2 then print_path sn p else () in
            insert_partially_ordered pathList ((sn,p,tnb),r)
          else pathList
        in
        List.fold_left aux3 pathList paths
      else pathList
    in
    IS.fold aux2 v.items pathList
  in
  List.fold_left aux1 pathList topmost

let insertLimitedReductions2 pathList (*t*) sn =
  let v,aut = sn.vertex_label.aut_vertex,sn.vertex_label.pdev in
  let aux2 (r,dp) tns pathList =
    let (_,_,_,len) = r in
    if dp = len (*&& (!automaton_kind=LR0 || (TNS.mem t tns) ||
         (TNS.mem dummy_token_name tns) || (rule_kind=Dynamic_rule))*) then
      let paths = find_paths sn r in
      let aux3 pathList (p,tnb) =
        let () = if !dypgen_verbose>2 then print_path sn p else () in
        insert_partially_ordered pathList ((sn,p,tnb),r)
      in
      List.fold_left aux3 pathList paths
    else pathList
  in
  IS.fold aux2 v.items pathList

exception Find_rightSib_failed

(** [find_rightSib] is used in [reduceViaPath] and [doShift].
    Its purpose is to find in the stack nodes list [snl] a stack node which
    holds the same grammar as [g_leftSib] and which holds a state which has an
    items set equal to [is_rightSib]. *)
let find_rightSib prio_imp g_leftSib is_rightSib data_rightSib local_data_rightSib snl data_equal =
  let rec aux snl = match snl with
    | [] -> raise Find_rightSib_failed
    | sn::tl ->
        let (v,parsing_device, sn_prio_imp) =
          sn.vertex_label.aut_vertex, sn.vertex_label.pdev,
          sn.vertex_label.prio_imprint
        in
        if ((IS.compare_is v.items is_rightSib) = 0) &&
          (Map_r.equal (==) parsing_device.g g_leftSib) &&
          (data_equal.global_data_equal parsing_device.data data_rightSib) &&
          (data_equal.local_data_equal parsing_device.local_data local_data_rightSib) &&
          (prio_imp_equal prio_imp sn_prio_imp)
        then sn
        else aux tl
  in
  aux snl

(*let rec last_in_list l =  match l with
  | [x] -> x
  | _::tl -> last_in_list tl
  | [] -> failwith "error last_in_list, empty list"*)

(*let replace_in_pathList pathList edge_nb new_link =
  let aux2 e = if snd e.edge_label = edge_nb then new_link else e in
  let aux1 ((sn,edl,tnb),r) = ((sn,List.map aux2 edl,tnb),r) in
  List.map aux1 pathList*)


open Lexing

exception Find_link_failed

let complete_reduction gs pathList topmost leftSib pdev_rightSib
    v_rightSib new_obj (*t*) nt lexer_pos prio counters data_equal =
  countred := !countred + 1;
  let prio_imp,b =
    new_prio_imprint pdev_rightSib.prio leftSib.vertex_label.prio_imprint
      leftSib.vertex_label.aut_vertex.items (Non_ter nt) prio
  in
  if b=false then gs,pathList,topmost,counters else
  try
    let rightSib =
      find_rightSib prio_imp pdev_rightSib.g v_rightSib.items
        pdev_rightSib.data pdev_rightSib.local_data topmost data_equal
    in
    let find_link gs rightSib leftSib =
      let rec aux el = match el with
        | [] -> raise Find_link_failed
        | e::tl -> if (stack_node_equal e.dest leftSib) then e else aux tl
      in
      aux rightSib.succ_edges
    in
    try
      let link = find_link gs rightSib leftSib in
(*       let _ = Printf.fprintf !log_channel "complete_reduction called, merge\n" in *)
      let link_label = link.edge_label in
      let old_obj_list = (fst link_label) in
      let edge_nb = snd link_label in
      if (!dypgen_verbose>2 || E.merge_warning) && old_obj_list<>[] then
        (let (start_pos,end_pos) = lexer_pos in
        let col1 = start_pos.pos_cnum - start_pos.pos_bol in
        let col2 = end_pos.pos_cnum - end_pos.pos_bol in
        Printf.fprintf !log_channel "Warning: parser merges non terminal `%s'%s\nin file \"%s\", from l:%d,c:%d to l:%d,c:%d\n" (* il faudrait afficher aussi la priorité *)
        (str_non_terminal nt) (str_with_priority prio) start_pos.pos_fname start_pos.pos_lnum col1
        end_pos.pos_lnum col2);
      let merge = try Nt_map.find (non_ter_of_nt nt) pdev_rightSib.merge_map
        with Not_found -> pdev_rightSib.global_merge in
      let new_obj_list = merge old_obj_list new_obj in
      let () = link.edge_label <- (new_obj_list,edge_nb) in
      gs,pathList,topmost,counters
    with
      Find_link_failed ->
(*       let _ = Printf.fprintf !log_channel "complete_reduction called, Find_link_failed\n" in *)
      let link = Gs.create_e rightSib ([new_obj],counters.counted) leftSib in
      let counters = {counters with counted = counters.counted+1 } in
      let pathList = insertLimitedReductions pathList link (*t*) topmost in
      gs,pathList,topmost,counters
  with
    Find_rightSib_failed ->
(*     let _ = Printf.fprintf !log_channel "complete_reduction called, Find_rightSib_failed\n" in *)
    let rightSib = Gs.create_v {
      aut_vertex = v_rightSib;
      pdev = pdev_rightSib;
      sn_nb = counters.countsn;
      token_shifted = counters.count_token;
      lexer_pos = lexer_pos;
      prio_imprint = prio_imp }
    in
    let _ = Gs.create_e rightSib ([new_obj],counters.counted) leftSib in
    let counters = { counters with
      countsn = counters.countsn+1;
      counted = counters.counted+1 }
    in
    let gs = rightSib::gs in
    let topmost = rightSib::topmost in
    let pathList = insertLimitedReductions2 pathList (*t*) rightSib in
    gs,pathList,topmost,counters


let reduceViaPath (((start_node:('a,'b) Gs.vertex),(p:('a,'b) Gs.edge list),_),(r:rule_bis)) (t:token_name) (gs:(('a,'b) Gs.vertex) list) (pathList:(('a,'b) path * rule_bis) list) (topmost:('a,'b) Gs.vertex list) counters data_equal =
  
  (if !dypgen_verbose>2 then
    let _ = Printf.fprintf !log_channel "reduceViaPath called, start_node=%d\n"
      (start_node.vertex_label).sn_nb in flush_all () else ());
  
  let (nt,lit_list,prio,rule_length) = r in
  let position_map e = e.source.vertex_label.lexer_pos in
  let position_list = List.map position_map p in
  let end_node_pos = try fst (List.hd position_list)
    with Failure _ -> Lexing.dummy_pos in
  let start_node_pos = snd start_node.vertex_label.lexer_pos in
  let symbol_pos = (end_node_pos,start_node_pos) in
  (* ^ this is the good order actually ^ *)
  let leftSib =
    if List.length p = 0 then start_node
    else (List.hd p).dest
  in
  let v,parsing_device_leftSib =
    leftSib.vertex_label.aut_vertex,leftSib.vertex_label.pdev in
  let prio_dat = parsing_device_leftSib.prio in
  (* collect_objs collects objects along the path p.
     The head of the list corresponds to the leftmost
     object in gs. *)
  let rec collect_objs p = match p with
    | e::tl -> let obj_ll = collect_objs tl in
        let obj_list = fst e.edge_label in
        let f1 new_obj_ll obj_l =
          let f2 new_obj_ll obj =
            (obj::obj_l)::new_obj_ll
          in
          List.fold_left f2 new_obj_ll obj_list
        in
        let obj_ll = List.fold_left f1 [] obj_ll in
        obj_ll
    | [] -> [[]]
  in
  let obj_ll = collect_objs p in

  let ac_l = Map_r.find r parsing_device_leftSib.g in
  let succ = v.succ_states in
  let v_rightSib = Li_map.find (Non_ter nt) succ  in
  let last_parsing_device = start_node.vertex_label.pdev
  in
    let foldfun (gs,pathList,topmost,will_shift,counters) toPass =
     try
      let rec try_actions ac_l = match ac_l with
        | (Dypgen_action f)::tl_ac_l ->
           (try
              f toPass symbol_pos position_list last_parsing_device.data
              parsing_device_leftSib.datadyn parsing_device_leftSib.local_data
              prio_dat
           with Giveup -> try_actions tl_ac_l)
        | [] -> raise Giveup
      in
      let newSemanticValue, will_shift2, newdata, newdatadyn, newlocal_data,
        rapf_add, r_remove, newprio = try_actions ac_l
      in
      let new_obj = newSemanticValue in
      let v_rightSib,parsing_device_rightSib =
        if rapf_add=[] && r_remove=[] && newprio==prio_dat then
          let item_set = start_node.vertex_label.aut_vertex.items in
          let tns = IS.find (r,List.length lit_list) item_set in
          if (TNS.mem t tns = false)&&(TNS.mem dummy_token_name tns = false)
            && !automaton_kind<>LR0 then raise Giveup
          else
            v_rightSib,{ parsing_device_leftSib with data = newdata ;
            local_data = newlocal_data }
        else
          let parsing_device_rightSib =
            (update_parsing_device parsing_device_leftSib rapf_add r_remove
            newdata newdatadyn newlocal_data newprio v_rightSib)
          in
          parsing_device_rightSib.init,parsing_device_rightSib
      in
      let gs,pathList,topmost,counters =
        complete_reduction gs pathList topmost leftSib
        parsing_device_rightSib v_rightSib new_obj (*t*) nt
        symbol_pos prio counters data_equal
      in
      gs,pathList,topmost,(will_shift2 && will_shift),counters
     with Giveup -> (gs,pathList,topmost,will_shift,counters)
    in
    List.fold_left foldfun (gs,pathList,topmost,true,counters) obj_ll


(*exception Giveup_shiftreduce*)

let doReductions (t:token_name) gs (topmost:('a,'b) Gs.vertex list)
    entry_point counters data_equal =
  let aux1 (pathList:(('a,'b) path * rule_bis) list) sn =
    let v,aut = sn.vertex_label.aut_vertex,sn.vertex_label.pdev in
    let item_set = v.items in
    let aux2 (r,dp) tns pathList =
      let (nt_lhs,_,_,len) = r in
      
      let tns = (* on devrait ne calculer ça que si on sait que len=dp *)
        try IS.find (r,dp) item_set
        with Not_found -> failwith "Not_found in doReductions"
      in
      
      if dp = len &&
        ( !automaton_kind=LR0 || t<>dummy_token_name ||
          (non_ter_of_nt nt_lhs)=entry_point ||
          (t=dummy_token_name && TNS.mem t tns) ) then
      
        let paths = List.map (function (p,tnb) -> sn,p,tnb) (find_paths sn r) in
        let aux3 pathList p = insert_partially_ordered pathList (p,r) in
        List.fold_left aux3 pathList paths
      else pathList
    in
    IS.fold aux2 item_set pathList
  in
  let pathList = List.fold_left aux1 [] topmost in
  let rec aux4 (pathList:(('a,'b) path * rule_bis) list) gs
      topmost counters =
    match pathList with
    | [] -> gs,topmost,counters
    | pr::tl ->
        let gs,pathList,topmost,counters =
          let gs,pathList,topmost,will_shift,counters =
            reduceViaPath pr t gs tl topmost counters data_equal
          in
          if will_shift = false then
            let sn,_,_ = fst pr in
            let topmost = List.filter (function x -> x!=sn) topmost in
            gs,pathList,topmost,counters
          else gs,pathList,topmost,counters
        in
        aux4 pathList gs topmost counters
  in
  aux4 pathList gs topmost counters


let doShifts (t:token) get_value gs (prevTops:('a,'b) Gs.vertex list) lexbuf_position lexbuf counters data_equal =
(*   let _ = Printf.fprintf !log_channel "(doShift) longueur prevTops : %d\n" (List.length prevTops) in *)
  let f (gs,topmost,counters) sn =
    let v,parsing_device = sn.vertex_label.aut_vertex,sn.vertex_label.pdev in
    try
      let next_v =
        Li_map.find
          (Ter (E.get_name t)) v.succ_states
      in
      let prio_imp,b =
        new_prio_imprint parsing_device.prio sn.vertex_label.prio_imprint
          sn.vertex_label.aut_vertex.items (Ter (E.get_name t)) 0
      in
      if b=false then gs,topmost,counters else
      try
        let s = next_v in
        let rightSib =
          find_rightSib prio_imp parsing_device.g s.items
            parsing_device.data parsing_device.local_data topmost data_equal
        in
        let _ = Gs.create_e rightSib ([get_value t],counters.counted) sn in
        let counters = {counters with counted = counters.counted+1 } in
        gs,topmost,counters
      with Find_rightSib_failed ->
        let rightSib = Gs.create_v {
          aut_vertex = next_v;
          pdev = parsing_device;
          sn_nb = counters.countsn;
          token_shifted = counters.count_token;
          lexer_pos = lexbuf_position lexbuf;
          prio_imprint = prio_imp }
        in
        let _ = Gs.create_e rightSib ([get_value t],counters.counted) sn in
        let counters = { counters with
          countsn = counters.countsn+1;
          counted = counters.counted+1 }
        in
        let gs = rightSib::gs in
        gs,(rightSib::topmost),counters
    with Not_found ->
      gs,topmost,counters
  in
  List.fold_left f (gs,[],counters) prevTops


(** This function print the content of the (graph) stack [gs], it is meant 
    for debugging purpose. *)
let print_gs gs title =
  output_string !log_channel "\n"; output_string !log_channel "\n";
  output_string !log_channel title;
  output_string !log_channel "\n";
  let f sn =
    let { aut_vertex = v; pdev = parsing_device; sn_nb = snnb;
      token_shifted = token_nb ; prio_imprint = prio_imp } = sn.vertex_label
    in
    output_string !log_channel "____________________________________\n";
    let () = Printf.fprintf !log_channel "STACK NODE <%d>, token number : %d\n" snnb token_nb in
    output_string !log_channel "\n";
    let () = print_state v in
    output_string !log_channel "\n";
    output_string !log_channel " priority imprint :\n";
    print_prio_imp prio_imp;
    let f3 f4 ed =
      let _,ednb = ed.edge_label in
      let { aut_vertex = v; sn_nb = snnb} = f4 ed in
      Printf.fprintf !log_channel "  sn:%d ed:%d st:%d\n" snnb ednb v.number
    in
    output_string !log_channel "\n";
    output_string !log_channel " predecessor stack nodes :\n";
    let () = List.iter (f3 (fun e -> e.source.vertex_label)) sn.pred_edges in
    output_string !log_channel "\n";
    output_string !log_channel " successor stack nodes :\n";
    let () = List.iter (f3 (fun e -> e.dest.vertex_label)) sn.succ_edges in
    output_string !log_channel "\n"
  in
  List.iter f gs

(*let non_ter_of_li li = match li with
  | Non_ter nt -> nt
  | _ -> failwith "non_ter_of_li"*)

(** Despite the use of the [merge] function there may be several final parse
    ojects, because two objects won't be merged if the two currents grammars
    are not the same, and because merge may keep several objects.
    Therefore, [log_parse_forest] is used to put in a list all the final parse
    objects. *)
let log_parse_forest successful entry_point =
  let f l sn =
    let prio_imp = sn.vertex_label.prio_imprint in
    let li = sn.vertex_label.aut_vertex.li in
    (*let prio_l,_ = Item_map.find (r,1) prio_imp in*)
    (*let prio = 0 in*) (*List.hd prio_l in*)
    let prio = entry_point_prio entry_point prio_imp li in
    let edges = sn.succ_edges in
    let f2 l e =
      let snnb = e.dest.vertex_label.sn_nb in
      if snnb = 0 then
        let ol = fst e.edge_label in
        let f3 o = (o,prio) in
        (List.map f3 ol)@l
      else l
    in
    List.fold_left f2 l edges
  in
  List.fold_left f [] successful


(*exception Syntax_error*)
(* The same automaton is used for all entry points, so the parser
tries to match all of them and then it selects the entry point it
is looking for. This may make the parser slower and should be
addressed in the future. *)
let glrParse parsing_device get_value (entry_point:non_ter) data_equal
    (lexfun:('a -> token)) (lexbuf:'a)
    (lexbuf_position:'a -> (Lexing.position * Lexing.position)) =
  let counters = {
    countsn = 0;
    counted = 0;
    count_token = 0 }
  in

  let log_count = ref 0 in
  if !dypgen_verbose>2 then
    (try
      let log_count_chan = open_in "dypgen_log_count" in
      let dlc = input_line log_count_chan in
      let dlc = if dlc = "" then "0" else dlc in
      let () = log_count := int_of_string dlc in
      close_in log_count_chan
    with _ -> log_count := 0);

  if !dypgen_verbose>2 then
    (let log_count_chan = open_out "dypgen_log_count" in
    let () = output_string log_count_chan (string_of_int (!log_count+1)) in
    close_out log_count_chan);

  let () = log_channel :=
    if !dypgen_verbose < 3 then stdout
    else open_out ("dypgen_"^(string_of_int !log_count)^".log")
  in
  let start = Gs.create_v {
    aut_vertex = parsing_device.init;
    pdev = parsing_device;
    sn_nb = counters.countsn;
    token_shifted = counters.count_token;
    lexer_pos = lexbuf_position lexbuf;
    prio_imprint = default_prio_imp }
  in
  let counters = { counters with countsn=counters.countsn+1 } in
  let gs = [start] in
  let topmost = [start] in
  let title_gs = "------------------------- Graph Structured Stack -------------------------\n" in
  (*let title_tm =
    "-------------------------- Topmost Stack Nodes --------------------------\n"
  in*)
  let is_successful sn =
    let s = sn.vertex_label.aut_vertex in
    match s.li with
      | Non_ter nt when (non_ter_of_nt nt)=entry_point -> true
      | _ -> false
  in

  let rec aux_la gs topmost (t:token) counters (*last_successful*) =
    if !dypgen_verbose>2 then
      (Printf.fprintf !log_channel "\nTOKEN : %s, size of topmost = %d\n" (str_token t)
        (List.length topmost); flush_all ());
    let gs,topmost,counters =
      doReductions (get_name t) gs topmost entry_point counters data_equal in
    (*if topmost = [] then gs,last_successful
    else*)
    let counters = { counters with
      count_token = counters.count_token+1 }
    in
    let gs,topmost,counters =
      doShifts t get_value gs topmost lexbuf_position lexbuf counters
        data_equal in
    let gs,topmost,counters =
      doReductions dummy_token_name gs topmost entry_point counters
        data_equal in
      (* tries to reduce to the entry point *)
    if topmost = []
    then (if !dypgen_verbose>2 then print_gs gs title_gs;
      raise Syntax_error)
    else
    let successful = List.filter is_successful topmost in
    if successful<>[] then gs,successful,counters else
    (*if successful = [] then
      aux_la gs topmost (lexfun lexbuf) last_successful
    else*) aux_la gs topmost (lexfun lexbuf) counters (*successful*)
  in

  let rec aux_LR0 gs topmost (t:token) counters =
    if !dypgen_verbose>2 then
      (Printf.fprintf !log_channel "\nTOKEN : %s, size of topmost = %d\n" (str_token t)
        (List.length topmost); flush_all ());
    let counters =
      { counters with count_token = counters.count_token+1 }
    in
    let gs,topmost,counters =
      doShifts t get_value gs topmost lexbuf_position lexbuf counters
        data_equal in
    let gs,topmost,counters =
      doReductions dummy_token_name gs topmost entry_point counters
        data_equal in
    if topmost = []
    then (if !dypgen_verbose>2 then print_gs gs title_gs;
      raise Syntax_error)
    else
    let successful = List.filter is_successful topmost in
    if successful<>[] then gs,successful,counters else
    aux_LR0 gs topmost (lexfun lexbuf) counters
  in

  (*let gs,topmost = if !automaton_kind=LR0
    then doReductions dummy_token_name gs topmost
    else gs,topmost in*)
  let (gs,successful,counters) =
    try (
      if !automaton_kind <> LR0 then aux_la gs topmost (lexfun lexbuf) counters
      else
        let gs,topmost,counters = (* reduces initial epsilon rules *)
          doReductions dummy_token_name gs topmost entry_point counters data_equal
        in
        aux_LR0 gs topmost (lexfun lexbuf) counters)
    with Syntax_error ->
      (flush_all ();
      if !dypgen_verbose>2 then close_out !log_channel;
      raise Syntax_error)
  in
  if !dypgen_verbose>2 then print_gs gs title_gs;
  if !dypgen_verbose>1 then
    (output_string !log_channel ("number of stack nodes = "^(string_of_int counters.countsn)^"\n");
    output_string !log_channel ("number of edges = "^(string_of_int counters.counted)^"\n");
    output_string !log_channel ("number of reductions = "^(string_of_int !countred)^"\n"));
  if !dypgen_verbose>2 then close_out !log_channel;
  log_parse_forest successful entry_point

end






module Ntt_PrioInAutomaton =
struct
  type non_terminal = non_ter * priority * int
  type lit_nt = non_terminal
  let nt_of_lit nt = nt
  let str_token_name = E.str_token_name
  let str_non_terminal (nt,p,_) = "("^(E.str_non_terminal nt)^","^(E.priority_names.(p))^")"
end

module Ntt_PrioAtRuntime =
struct
  type non_terminal = non_ter
  type lit_nt = non_terminal * non_terminal_priority
  let nt_of_lit (nt,p) = nt
  let str_token_name = E.str_token_name
  let str_non_terminal nt = (E.str_non_terminal nt)
end

module Grammar_PrioInAutomaton = Grammar_struct(Ntt_PrioInAutomaton)
module Grammar_PrioAtRuntime = Grammar_struct(Ntt_PrioAtRuntime)




module PrioInAutomaton =
struct

let select_rule _ _ _ = true


module OrdPrioNb =
struct
  type t = int * int
  let compare = Pervasives.compare
end
module PrioNb_set = Set.Make(OrdPrioNb)
module Non_ter_set = Set.Make(Ordered_non_ter)
open Grammar_PrioInAutomaton
type ('a,'b,'c) grammar = ('a,'b,'c) Grammar_PrioInAutomaton.grammar
type non_terminal = Grammar_PrioInAutomaton.non_terminal
type lit_nt = Grammar_PrioInAutomaton.lit_nt
let non_ter_of_nt  (nt,_,_) = nt
type item_set = Grammar_PrioInAutomaton.item_set
type rule_bis = Grammar_PrioInAutomaton.rule_bis
let str_with_priority _ = ""

let nt_prio_to_prio_set p_map (ps:Prio_set.t) p = match p with
  | No_priority -> ps
  | Eq_priority pr -> Prio_set.add pr Prio_set.empty
  | Less_priority pr -> (try fst (Prio_map.find pr p_map.prd_rel)
      with Not_found -> Prio_set.empty)
  | Lesseq_priority pr -> Prio_set.add pr (try (fst (Prio_map.find pr p_map.prd_rel))
      with Not_found -> Prio_set.empty)
  | Greater_priority pr -> (try snd (Prio_map.find pr p_map.prd_rel)
      with Not_found -> Prio_set.empty)
  | Greatereq_priority pr -> Prio_set.add pr (try (snd (Prio_map.find pr p_map.prd_rel))
      with Not_found -> Prio_set.empty)
      (* this may result in pr being 2 times in the list and result in
         2 times the same rule_bis, but it will be only once
         in the new_grammar because a grammar is a map of key
         rule_bis. *)
(*let nt_prio_to_prio_set p_map (ps:Prio_set.t) p = match p with
  | No_priority -> ps
  | Less_priority pr -> (try fst (Prio_map.find pr p_map.prd_rel)
      with Not_found -> Prio_set.empty)
  | Lesseq_priority pr -> Prio_set.add pr (try (fst (Prio_map.find pr p_map.prd_rel))
      with Not_found -> Prio_set.empty)
      (* this may result in pr being 2 times in the list and result in
         2 times the same rule_bis, but it will be only once
         in the new_grammar because a grammar is a map of key
         rule_bis. *)*)

let new_rules p_map nt_prio_map array_nt_prio ps ntn litl len prio nt_nb =
  let aux2 tn lit_l = (Ter tn)::lit_l in
  let aux3 nt p lit_ll =
    let rec aux4 lit_ll new_lit_ll = match lit_ll with
      | lit_l::tl ->
          let prio_set = nt_prio_to_prio_set p_map ps p in
          let prio_set2 = try Nt_map.find nt nt_prio_map
            with Not_found -> Prio_set.empty in
          let prio_set = Prio_set.inter prio_set prio_set2 in
          let f1 pr pn_set =
            let n = try Prio_map.find pr array_nt_prio.(nt)
              with Not_found -> failwith "Not_found in new_rules rhs"
                | Invalid_argument("index out of bounds") ->
                    (Printf.fprintf !log_channel "Error: non terminal `%s' is out of bounds.\n"
                    (E.str_non_terminal nt);failwith "index out of bounds in new_rules rhs")
                    (*(Printf.fprintf !log_channel "Warning: non terminal `%s' is never in a left-hand side.\n"
                    (E.str_non_terminal nt); -1)*)
            in
            PrioNb_set.add (pr,n) pn_set
          in
          let pn_set = Prio_set.fold f1 prio_set PrioNb_set.empty in
          let f (pr,n) l = ((Non_ter (nt,pr,n))::lit_l)::l in
          let lit_ll_2 = PrioNb_set.fold f pn_set [] in
          aux4 tl lit_ll_2@new_lit_ll
      | [] -> new_lit_ll
    in
    aux4 lit_ll []
  in
  let rec aux1 litl lit_ll = match litl with
    | (Ter tn)::tl -> aux1 tl (List.map (aux2 tn) lit_ll)
    | (Non_ter (nt,p))::tl -> aux1 tl (aux3 nt p lit_ll)
    | [] -> lit_ll
  in
  let lit_ll = aux1 litl [[]] in
  let nb = try Prio_map.find prio array_nt_prio.(ntn)
    with Not_found -> failwith "Not_found in new_rules lhs"
  in
  let complete_new_rule lit_l = ((ntn,prio,nb),lit_l,prio,len) in
  List.map complete_new_rule lit_ll

(* ps is the set of all priorities. *)
let make_real_grammar (user_g:('a,'b,'c) user_grammar) (pmap:priority_data) =
  if !dypgen_verbose>1 then
    (let nbr = Urule_map.fold (fun _ _ n -> n+1) user_g 0 in
    Printf.fprintf !log_channel "size of the grammar : %d rules\n" nbr);
  let ps =
    Prio_map.fold (fun p _ pset ->
      (*output_string !log_channel ("add priority :"^(priority_names.(p))^"\n");*)
      Prio_set.add p pset) pmap.prd_rel Prio_set.empty
  in
  let ps = Prio_set.add default_priority ps in
  let foldfun user_g ep =
    Urule_map.add (non_terminal_startprime,[Non_ter (ep,No_priority)],0)
      [(Dypgen_action(fun x _ _ d ld dd prd -> (List.hd x,true,d,ld,dd,[],[],prd)))] user_g
  in
  let user_g = List.fold_left foldfun user_g entry_points in
  (*let foldfun3 (nt,_,_) _ non_ter_set = Non_ter_set.add nt non_ter_set in
  let non_ter_set = Urule_map.fold foldfun3 user_g Non_ter_set.empty in
  let nt_nb = Non_ter_set.cardinal non_ter_set in*)
  let f1 (nt,litl,_) _ n =
    let n = max n nt in
    let f2 n lit = match lit with
      | Non_ter (nt,_) -> max n nt
      | _ -> n
    in
    List.fold_left f2 n litl
  in
  let nt_nb = (Urule_map.fold f1 user_g 0)+1 in
  if !dypgen_verbose>1 then
    Printf.fprintf !log_channel "number of non terminals : %d\n" nt_nb;
  let foldfun2 (nt,_,p) _ mapntp =
    let ps = try Nt_map.find nt mapntp
      with Not_found -> Prio_set.empty in
    let ps = Prio_set.add p ps in
    (*output_string !log_channel ("ajoute "^(str_non_terminal (nt,p))^"\n");*)
    Nt_map.add nt ps mapntp
  in
  let nt_prio_map = Urule_map.fold foldfun2 user_g Nt_map.empty in
  let array_nt_prio = Array.make nt_nb Prio_map.empty in
  let rec f_rec i n = if i=nt_nb then n else
    let prio_set = try Nt_map.find i nt_prio_map
      with Not_found -> Prio_set.empty
    in
    let foldfun prio (prio_map,n) = (Prio_map.add prio n prio_map),(n+1) in
    let prio_map,n = Prio_set.fold foldfun prio_set (Prio_map.empty,n) in
    let () = array_nt_prio.(i) <- prio_map in
    f_rec (i+1) n
  in
  let newnt_nb = f_rec 0 0 in
  (*let fiter nt ps =
    print_string ("nt: "^(E.str_non_terminal nt));
    Prio_set.iter (fun p -> print_string (priority_names.(p)^" ")) ps;
    output_string !log_channel "\n"
  in
  Nt_map.iter fiter nt_prio_map;*)
  let aux (ntn,litl,p) a g =
    let litl = List.rev litl in
    let rl =
      new_rules pmap nt_prio_map array_nt_prio ps ntn litl
        (List.length litl) p nt_nb
    in
    let f g r = Map_r.add r a g in
    List.fold_left f g rl
  in
  let g = Urule_map.fold aux user_g Map_r.empty in
  if !dypgen_verbose>1 then
    (let f r _ n = (*output_string !log_channel ((str_rule r)^"\n"); flush stdout;*) n+1 in
    let nbr = Map_r.fold f g 0 in
    Printf.fprintf !log_channel "size of the new grammar : %d rules\n" nbr;
    Printf.fprintf !log_channel "number of new non terminals : %d\n" newnt_nb;
    flush stdout);
  g,newnt_nb


type prio_imprint = int

let new_prio_imprint _ _ _ _ _ = 0,true
let default_prio_imp = 0
let prio_imprint_check _ _ _ = true
let prio_imp_equal _ _ = true
let print_prio_imp prio_imp = ()
let entry_point_prio _ _ li = match li with
  | Non_ter (_,p,_) -> p
  | Ter _ -> failwith "entry_point_prio, priority in automaton"

end



module PrioAtRuntime =
struct

open Grammar_PrioAtRuntime
type ('a,'b,'c) grammar = ('a,'b,'c) Grammar_PrioAtRuntime.grammar
type non_terminal = Grammar_PrioAtRuntime.non_terminal
type lit_nt = Grammar_PrioAtRuntime.lit_nt
let non_ter_of_nt  nt = nt
type item_set = Grammar_PrioAtRuntime.item_set
type rule_bis = Grammar_PrioAtRuntime.rule_bis
let str_with_priority p = " with priority `"^(priority_names.(p))^"'"

let select_rule prio_dat ntn p =
  let nt,nt_p = ntn in
  match nt_p with
    | No_priority -> true
    | Eq_priority q -> p=q
    | Less_priority q -> is_relation prio_dat p q
    | Lesseq_priority q -> (is_relation prio_dat p q) || (p=q)
    | Greater_priority q -> is_relation prio_dat q p
    | Greatereq_priority q -> (is_relation prio_dat q p) || (p=q)

let compute_nt_nb g =
  let f1 (nt,litl,_,_) _ n =
    let n = max n nt in
    let f2 n lit = match lit with
      | Non_ter (nt,_) -> max n nt
      | _ -> n
    in
    List.fold_left f2 n litl
  in
  (Map_r.fold f1 g 0)+1
(*  let foldfun3 (nt,_,_,_,_) _ non_ter_set = NTS.add nt non_ter_set in
  let non_ter_set = Map_r.fold foldfun3 g NTS.empty in
  NTS.cardinal non_ter_set*)

let rule_bis_of_rule (nt,l,p) = (nt,l,p,(List.length l))

let make_real_grammar user_g _ =
  let foldfun r a g = Map_r.add (rule_bis_of_rule r) a g in
  let g = Urule_map.fold foldfun user_g Map_r.empty in
  let foldfun g ep =
    Map_r.add (non_terminal_startprime,[Non_ter (ep,No_priority)],0,1)
      [(Dypgen_action(fun x _ _ d ld dd prd -> (List.hd x,true,d,ld,dd,[],[],prd)))] g
  in
  (List.fold_left foldfun g entry_points),(compute_nt_nb g)

(*type prio_imprint = int*)
type prio_imprint = ((priority list) * bool) Item_map.t

let symb_of_lit lit = match lit with
  | Ter t -> Ter t
  | Non_ter (n,_) -> Non_ter n

(*let new_prio_imprint _ _ _ _ = 0,true*)

let new_prio_imprint priodat prio_imp is symb prio =
  let f (r,dp) _ (new_pi,b) =
    let (_,litl,_,len) = r in
    if dp=len then (new_pi,b) else
    let lit = (List.nth litl dp) in
    if (symb_of_lit lit)<>symb then (new_pi,b) else
    let b1 = match lit with
      | Ter _ | Non_ter (_,No_priority) -> true
      | Non_ter (_,Eq_priority p) -> prio=p
      | Non_ter (_,Less_priority p) -> is_relation priodat prio p
      | Non_ter (_,Lesseq_priority p) -> (is_relation priodat prio p)||(p=prio)
      | Non_ter (_,Greater_priority p) -> is_relation priodat p prio
      | Non_ter (_,Greatereq_priority p) -> (is_relation priodat p prio)||(p=prio)
    in
    let old_prio_l,old_b =
      if dp=0 then ([],true) else
      try Item_map.find (r,dp) prio_imp
      with Not_found -> failwith "new_prio_imprint"
    in
    (Item_map.add (r,dp+1) ((prio::old_prio_l),(b1 && old_b)) new_pi),
    (b || b1)
  in
  IS.fold f is (Item_map.empty,false)
  (* If the returned bool is true then the parser can complete the reduction.
  In the case of the shift it is false only if the token is not
  expected, not because of priorities. *)

let prio_imprint_check r len prio_imp =
  let _,b = try Item_map.find (r,len) prio_imp
    with Not_found -> [],true in
  b

let default_prio_imp = Item_map.empty
let prio_imp_equal pi1 pi2 = Item_map.equal (=) pi1 pi2

let entry_point_prio entry_point prio_imp _ =
  let r =
    (non_terminal_startprime,[Non_ter(entry_point,No_priority)],
     0,1)
  in
  let prio_l,_ = Item_map.find (r,1) prio_imp in
  try List.hd prio_l with Failure _ -> failwith "entry_point_prio"

let print_prio_imp prio_imp =
  let f it (pl,b) =
    print_item it TNS.empty;
    let f2 s p = s^(E.priority_names.(p))^" " in
    output_string !log_channel ("  "^(string_of_bool b)^" : ["^(List.fold_left f2 " " pl)^"]\n")
  in
  Item_map.iter f prio_imp

end

module Parser_PIA = Parser(Grammar_PrioInAutomaton)(PrioInAutomaton)
module Parser_PAR = Parser(Grammar_PrioAtRuntime)(PrioAtRuntime)

module type Parser_type =
sig
  type ('obj,'b,'c) parsing_device
    (** Abstract type of a structure which contains an parsing_device, the
    grammar associated to it and the actions associated to the grammar and
    other data. *)

  val create_parsing_device : (Dyp_tools.rule * ('obj,'data,'local_data) Special_types.action) list ->
    Dyp_tools.priority_data -> Special_types.automaton_kind -> 'data -> 'local_data ->
    'obj merge_map -> 'obj merge_function -> Special_types.datadyn ->
    ('obj,'data,'local_data) parsing_device
    (** Returns the parsing_device which parses strings written with the input
        grammar and assuming the relations between priority classes which
        are contained in the input priority data. *)

  val update_parsing_device_data : ('obj,'data,'local_data) parsing_device ->
    'data -> 'local_data -> ('obj,'data,'local_data) parsing_device

  val glrParse : ('obj,'data,'local_data) parsing_device ->
        (E.token -> 'obj) -> int ->
        ('data,'local_data) Dypgen_runtime_tools.data_equal -> ('a -> E.token) -> 'a ->
        ('a -> (Lexing.position * Lexing.position)) -> (('obj * Dyp_tools.priority) list)
    (** Given a parsing_device and a list of tokens (the input string),
        [glrParse] returns the list of the parse objects of the input string.
        If there is no ambiguity there is only one object in the list. The
        list may be a forest of abstract syntax trees or a list of computed
        values.
        [int] is the name of the entry point. *)
end


end


@h=tangler('dypgen/dyplib/priority_by_relation.ml')
@select(h)
type priority = int

type non_terminal_priority =
  | No_priority
  | Eq_priority of priority
  | Less_priority of priority
  | Lesseq_priority of priority
  | Greater_priority of priority
  | Greatereq_priority of priority
(** This type makes possible to assign precedence to non terminals in 
          the rhs of rules.
            If the non_terminal_priority of the non terminal E in the following 
          rule : A -> E  is Less_priority pc1, and that the parser has so far 
          reduced a substring to E yielding the priority class pc2 for this
          substring, then the parser reduces with A -> E to A only if we have
          the relation pc1 -> pc2 in the priority set used to construct the 
          automaton (see below create_automaton).
            The Toeq constructor behaves the same way except that it also 
          accepts pc1 for priority class of the substring even if we don't
          have pc1 -> pc1 in the priority set. *)

let str_ntp ntp = match ntp with
  | No_priority -> "No_priority"
  | Eq_priority p -> "="^(string_of_int p)
  | Less_priority p -> "<"^(string_of_int p)
  | Lesseq_priority p -> "<="^(string_of_int p)
  | Greater_priority p -> ">"^(string_of_int p)
  | Greatereq_priority p -> ">="^(string_of_int p)

let start_priority = No_priority

module OrdPrio =
struct
  type t = priority
  let compare = Pervasives.compare
end
module Ordered_string =
struct
  type t = string
  let compare = Pervasives.compare
end

module Prio_set = Set.Make(OrdPrio)
module Prio_map = Map.Make(OrdPrio)
module String_map = Map.Make(Ordered_string)

type priority_data = {
  prd_rel : (Prio_set.t * Prio_set.t) Prio_map.t;
  prd_strmap : (int String_map.t);
  prd_nb : int }
(* This is a map from a priority to a couple of priority set :
p -> (ps1,ps2) where ps1 is the set of all priorities q s.a. q<p
and ps2 is the set of all priorities r s.a. p<r
The string_map maps the string of a priority to its int value.
int is the number of priorities. *)

(* REMARQUE : Puisque les priorités sont des entiers, la structure qu'il nous faut c'est un tableau à 2 entrées :
prio_dat.(p).(q) = true <=> p<q *)



(* this set p1<p2 true if b=true and false if b=false *)
let set_relation priodat b p1 p2 =
  let (ps1,ps2) = try Prio_map.find p1 priodat.prd_rel
    with Not_found -> failwith "set_relation" (*(Prio_set.empty, Prio_set.empty)*)
  in
  let (ps3,ps4) = try Prio_map.find p2 priodat.prd_rel
    with Not_found -> failwith "set_relation" (*(Prio_set.empty, Prio_set.empty)*)
  in
  let (ps2,ps3) =
    if b then (Prio_set.add p2 ps2),(Prio_set.add p1 ps3)
    else (Prio_set.remove p2 ps2),(Prio_set.remove p1 ps3)
  in
  let prd_rel =
    Prio_map.add p2 (ps3,ps4) (Prio_map.add p1 (ps1,ps2) priodat.prd_rel)
  in
  { priodat with prd_rel = prd_rel }

let insert_priority priodat str =
  try
    let p = String_map.find str priodat.prd_strmap in
    (priodat,p)
  with Not_found ->
    let p = priodat.prd_nb in
    let strmap = String_map.add str p priodat.prd_strmap in
    let rel = Prio_map.add p (Prio_set.empty,Prio_set.empty) priodat.prd_rel in
    { prd_rel = rel ; prd_strmap = strmap ; prd_nb = (p+1) },p

let find_priority priodat str =
  String_map.find str priodat.prd_strmap

let default_priority = 0
let empty_priority_data =
{ prd_rel = Prio_map.empty ; prd_strmap = String_map.empty ; prd_nb = 0 }
let empty_priority_data = fst (insert_priority empty_priority_data "default_priority")

let is_relation priodat p1 p2 =
  try
    let (_,ps) = Prio_map.find p1 priodat.prd_rel in
    Prio_set.mem p2 ps
  with Not_found -> false


let update_priority priodat ppbl =
  let aux priodat (p1,p2,b) = set_relation priodat b p1 p2 in
  List.fold_left aux priodat ppbl
(** update_priority ps [pc1,pc2,true]
adds the binary relation pc1 -> pc2 to ps
update_priority ps [pc1,pc2,false]
removes the relation pc1 -> pc2 from ps if it exists. *)

(* used for p1<p2<p3<...<pn *)
let add_list_relations priodat l =
  let foldfun p1 priodat p2 = set_relation priodat true p1 p2 in
  let rec aux p1 l priodat = match l with
    | [p2] -> set_relation priodat true p1 p2
    | p2::tl ->
        let priodat = List.fold_left (foldfun p1) priodat l in
        aux p2 tl priodat
    | [] -> failwith "add_list_relation"
  in
  aux (List.hd l) (List.tl l) priodat

(* does the same as the previous except that there is the reflexivity *)
(*let add_list_relations_order priodat l =
  let foldfun p1 priodat p2 = set_relation priodat true p1 p2 in
  let rec aux p1 l priodat = match l with
    | [p2] -> set_relation priodat true p1 p2
    | p2::tl ->
        let priodat = List.fold_left (foldfun p1) priodat l in
        aux p2 tl priodat
    | [] -> failwith "add_list_relation"
  in
  aux (List.hd l) l priodat*)

@h=tangler('dypgen/dyplib/gs.ml')
@select(h)
type
  ('n,'e) vertex = {
    mutable vertex_label : 'n;
    mutable succ_edges : (('n,'e) edge) list;
    mutable pred_edges : (('n,'e) edge) list
  }
  and ('n,'e) edge = {
    mutable edge_label : 'e;
    mutable dest : ('n,'e) vertex;
    mutable source : ('n,'e) vertex
  }

let create_e v1 label v2 =
  let new_edge = { edge_label = label; source = v1; dest = v2} in
  v1.succ_edges <- new_edge::(v1.succ_edges);
  v2.pred_edges <- new_edge::(v2.pred_edges);
  new_edge

let remove_edge_e edge =
  let v1,v2 = edge.source,edge.dest in
  let f e = e!=edge in
  v1.succ_edges <- List.filter f v1.succ_edges;
  v2.pred_edges <- List.filter f v2.pred_edges

let create_v label =
  { vertex_label = label; succ_edges = []; pred_edges = [] }

(*
module type Node_param =
sig
  type t
  val compare : t -> t -> int
  type node_label
  (*val get_key_from_label : node_label -> t*)
end

module Make_node(Np:Node_param)=
struct

  module Ord =
  struct
    type t = Np.t
    let compare = Np.compare
  end

  module Node_map = Map.Make(Ord)

  type node = {
    node_key : Np.key;
    mutable node_label : Np.node_label;
    mutable succ_nodes : node Node_map;
    mutable pred_nodes : node Node_map
  }

  (*let get_key n = Np.get_key_from_label n.node_label*)

  let add_edge n1 n2 =
    (*let k1,k2 = (get_key n1),(get_key_n2) in*)
    Node_map.add n2.key n2 n1.succ_nodes;
    Node_map.add n1.key n1 n2.pred_nodes;

  let remove_node n0 =
    let f1 n = Node_map.remove n0.key n.succ_nodes
    let f2 n = Node_map.remove n0.key n.pred_nodes
    Node_map.iter f1 n0.pred_nodes;
    Node_map.iter f2 n0.succ_nodes

  let create_node nl k = {
    key = k;
    node_label = nl;
    pred_nodes = Node_map.empty;
    succ_nodes = Node_map.empty
  }

end*)
@h=tangler('dypgen/generators/pgen/pgen_lexer.mll')
@select(h)
{
open Pgen_parser_param
let ocaml_code_buffer = ref ""
let paren_count = ref 0
let in_string = ref false
let comment_count = ref 0
}

let newline = ('\010' | '\013' | "\013\010")
let blank = [' ' '\009' '\012']
let lowercase = ['a'-'z' '\223'-'\246' '\248'-'\255' '_']
let uppercase = ['A'-'Z' '\192'-'\214' '\216'-'\222']
let identchar = 
  ['A'-'Z' 'a'-'z' '_' '\192'-'\214' '\216'-'\246' '\248'-'\255' '\'' '0'-'9']

rule token = parse
  | newline
      { token lexbuf }
  | blank +
      { token lexbuf }
  | "%token" { KWD_TOKEN }
  | "%start" { KWD_START }
  | "%relation" { KWD_RELATION }
  | "%full" { KWD_FULL }
  | lowercase identchar *
      { LIDENT(Lexing.lexeme lexbuf) }
  | uppercase identchar *
      { UIDENT(Lexing.lexeme lexbuf) }
  | "("  { LPAREN }
  | ")"  { RPAREN }
  | ":"  { COLON }
  | "%%"  { PERCENTPERCENT }
  | "<"
      { ocaml_code_buffer := "";
        ocaml_type lexbuf;
        OCAML_TYPE (!ocaml_code_buffer)
      }
  | "{"
      { ocaml_code_buffer := "";
        ocaml_code lexbuf;
        OCAML_CODE (!ocaml_code_buffer)
      }
  | "|"  { BAR }
  | "="  { EQUAL }
  | eof { EOF }

and ocaml_code = parse
  | "}" 
      { 
        if !in_string = false && !comment_count = 0 then
          begin
            if (!paren_count) = 0 then ()
            else
              let _ = ocaml_code_buffer := ((!ocaml_code_buffer) ^ 
                (String.make 1 (Lexing.lexeme_char lexbuf 0))) in
              let _ = paren_count := ((!paren_count)-1) in
              ocaml_code lexbuf
          end
        else
          begin
            ocaml_code_buffer := (!ocaml_code_buffer) ^ "}";
            ocaml_code lexbuf
          end
      }  
  | "$"
      { ocaml_code_buffer := ((!ocaml_code_buffer) ^ 
          "_");
        ocaml_code lexbuf
      }
  | "\\\""
      { ocaml_code_buffer := ((!ocaml_code_buffer) ^ "\\\"");
        ocaml_code lexbuf
      }
  | "\""
      { 
        if !in_string then in_string := false else in_string := true;
        ocaml_code_buffer := (!ocaml_code_buffer) ^ "\"";
        ocaml_code lexbuf
      }
  | "{"
      { ocaml_code_buffer := (!ocaml_code_buffer) ^ "{";
        if !in_string = false && !comment_count = 0 then
          paren_count := (!paren_count)+1;
        ocaml_code lexbuf
      }
  | "(*"
      { 
        if !in_string then () else comment_count := !comment_count + 1;
        ocaml_code_buffer := ((!ocaml_code_buffer) ^ "(*");
        ocaml_code lexbuf
      }
  | "*)"
      { 
        if !in_string then () else comment_count := !comment_count - 1;
        ocaml_code_buffer := ((!ocaml_code_buffer) ^ "*)");
        ocaml_code lexbuf
      }
  | _ 
      { ocaml_code_buffer := ((!ocaml_code_buffer) ^ 
          (String.make 1 (Lexing.lexeme_char lexbuf 0)));
        ocaml_code lexbuf
      }

and ocaml_type = parse
  | ">" { () }
  | _ 
      { ocaml_code_buffer := ((!ocaml_code_buffer) ^ 
          (String.make 1 (Lexing.lexeme_char lexbuf 0)));
        ocaml_type lexbuf
      }

@h=tangler('dypgen/generators/pgen/pgen.ml')
@select(h)
(*
pgen: a simple GLR parser generator for Objective Caml,
priority_by_relation is used.
Special_types.Dypgen_action actions are not possible with pgen and actions cannot use the structures
data and priority_data, priorities of rules are constant only.
Cyclic grammars are not handled.
If no priority are stated for a rule in pgen input file, then Dyp_tools.default_priority
(i.e. 0) is chosen.
merge functions (for two sub parse trees reduced to the same non terminal) cannot be
stated by the user and is always the choice of the first parse tree.

An input file for pgen follows this frame :

{
optional header code for the Parser_parameters module.
}

%token Token1 <type> Token2 (* Constructors for token *)
%start <type> main
%relation (* optional field *)
p1:p2
p1:p3 (* means the relation is true for p1->p2, the field %relation is optional *)

%%

main:
 | sequence of terminals and non terminals { ocaml action code } priority
...

non_terminal:
 | ... {...} priority
...

{
Optional ocaml code, trailer of the main parser code.
}

This is the end of the input file.

In action code $1 is the name of the obj associated to the first literal in the
rhs of the rule, $2 the second, etc.
*)

module P = Dyp.Parser.Make(Pgen_parser_param)

open Pgen_parser_param
open P
open P.Parser_PAR
open Printf

(*let () = Dyp_tools.dypgen_verbose := 2*)
(*let () = number_of_tokens := 19*)

let verbose_ref = ref 0
let process_verbose_mode () = verbose_ref := 1
let string_ref = ref ""
let process_argument s =
  if s = "" then raise (Arg.Bad "missing input file name")
  else string_ref := s
let list_arg = [("-v",Arg.Unit process_verbose_mode,"activate verbose mode: gives details of the parsing of the input file")]
let _ = Arg.parse list_arg process_argument "usage: pgen [-v] file_name.dyp"
let _ = if !string_ref = "" then
  let _ = print_string "usage: pgen [-v] file_name.dyp\n" in exit 0
let verbose = !verbose_ref
let out =
  if verbose = 0 then (open_out "/dev/null")
  else stdout


let out =
  if verbose = 0 then (open_out "/dev/null")
  else stdout

let prio = 0


let ntn_start = 1
let ntn_parser_param_info = 2
let ntn_token_list = 3
let ntn_relation = 4
let ntn_start_def = 5
let ntn_grammar = 6
let ntn_bar_opt = 7
let ntn_literal_list = 8
let ntn_priority = 9
let ntn_optional_code = 10
(*let ntn_startprime = 0*)

type data = Data_void

type obj =
    Obj_void
  | Code of string
  | Obj_type of string
  | Parser_parameters_info of parser_param_info
  | Token_list of (token_desc list) 
  | Obj_start of string * string
  | Relation of relation_desc
  | Grammar of (rule_desc list)
  | Literal_list of (literal_desc list)
  | Obj_uident of string
  | Obj_lident of string
  | Obj_lparen
  | Obj_rparen
  | Obj_equal
  | Pgen_input of (string * parser_param_info * (rule_desc list) * string)
(* Pgen_input : (header code of module Parser_parameters, token list, eof token, relation (optional), trailer code of module Parser_parameters, header code of parser (optional), grammar, trailer code of parser (optional))*)

let r_pgen_input = (ntn_start,[Dyp_tools.Non_ter (ntn_optional_code, Dyp_tools.No_priority); Dyp_tools.Non_ter (ntn_parser_param_info,Dyp_tools.No_priority); Dyp_tools.Ter tn_percentpercent; Dyp_tools.Non_ter (ntn_grammar,Dyp_tools.No_priority); Dyp_tools.Non_ter (ntn_optional_code, Dyp_tools.No_priority); Dyp_tools.Ter tn_EOF],Dyp_tools.default_priority)
(* Start -> optional_code parser_param_inf PercentPercent grammar optional_code Eof *)

let a_pgen_input = Special_types.Dypgen_action(fun l _ _ d dd ld prd ->
  (match l with
    | [Code c1; Parser_parameters_info (tl,rel,start); _; Grammar g; Code c2; _] ->
        let _ = fprintf out "action pgen_input\n" in
        Pgen_input (c1,(tl,rel,start),g,c2)
    | _ -> failwith "a_pgen_input"
),true,Data_void,dd,ld,[],[],prd)

let r_start_def = (ntn_start_def,[Dyp_tools.Ter tn_kwd_start; Dyp_tools.Ter tn_ocaml_type; Dyp_tools.Ter tn_lident],Dyp_tools.default_priority)
(* start_def -> Kwd_start Ocaml_type Lident *)

let a_start_def = Special_types.Dypgen_action(fun l _ _ d dd ld prd ->
  (match l with
    | [Obj_void; Obj_type t; Obj_lident s] -> Obj_start (s,t)
    | _ -> failwith "a_start_def"
),true,Data_void,dd,ld,[],[],prd)

let r_parser_param_info_0 = (ntn_parser_param_info,[Dyp_tools.Non_ter (ntn_start_def,Dyp_tools.No_priority)],Dyp_tools.default_priority)
(* parser_param_info -> start_def *)
let r_parser_param_info_1 = (ntn_parser_param_info,[Dyp_tools.Non_ter (ntn_token_list,Dyp_tools.No_priority)],Dyp_tools.default_priority)
(* parser_param_info -> token_list *)
let r_parser_param_info_3 = (ntn_parser_param_info,[Dyp_tools.Non_ter (ntn_relation,Dyp_tools.No_priority)],Dyp_tools.default_priority)
(* parser_param_info -> relation *)
let r_parser_param_info_4 = (ntn_parser_param_info,[Dyp_tools.Non_ter (ntn_parser_param_info, Dyp_tools.No_priority); Dyp_tools.Non_ter (ntn_parser_param_info, Dyp_tools.No_priority)],Dyp_tools.default_priority)
(* parser_param_info -> parser_param_info parser_param_info *)

let a_parser_param_info = Special_types.Dypgen_action(fun l _ _ d dd ld prd ->
  (match l with
    | [Obj_start (st,t)] -> Parser_parameters_info ([],[],(st,t))
    | [Token_list tl] -> Parser_parameters_info (tl,[],("",""))
    | [Relation rel] -> Parser_parameters_info ([],rel,("",""))
    | [Parser_parameters_info (tl1,rel1,st1); Parser_parameters_info (tl2,rel2,st2)] ->
        let st = if fst st2 = "" then st1 else st2 in
        Parser_parameters_info (tl1@tl2,rel1@rel2,st)
    | _ -> failwith "a_parser_param_info"
),true,Data_void,dd,ld,[],[],prd)

let r_optional_code_0 = (ntn_optional_code,[],Dyp_tools.default_priority)
(* optional_code -> *)
let r_optional_code_1 = (ntn_optional_code,[Dyp_tools.Ter tn_ocaml_code],Dyp_tools.default_priority)
(* optional_code -> Ocaml_code *)

let a_optional_code = Special_types.Dypgen_action(fun l _ _ d dd ld prd ->
  (match l with
    | [] -> let _ = fprintf out "action optional_code_0\n" in Code ""
    | [Code c] -> let _ = fprintf out "action optional_code_1\n" in Code c
    | _ -> failwith "a_optional_code"
),true,Data_void,dd,ld,[],[],prd)

let r_token_list_1 = (ntn_token_list,[Dyp_tools.Ter tn_kwd_token; Dyp_tools.Ter tn_uident],Dyp_tools.default_priority)
(* token_list -> Kwd_token Uident *)
let r_token_list_2 = (ntn_token_list,[Dyp_tools.Ter tn_kwd_token; Dyp_tools.Ter tn_ocaml_type;  Dyp_tools.Ter tn_uident],Dyp_tools.default_priority)
(* token_list -> Kwd_token Ocaml_type Uident *)
let r_token_list_3 = (ntn_token_list,[Dyp_tools.Non_ter (ntn_token_list,Dyp_tools.No_priority); Dyp_tools.Ter tn_uident],Dyp_tools.default_priority)
(* token_list -> token_list Uident *)
let r_token_list_4 = (ntn_token_list,[Dyp_tools.Non_ter (ntn_token_list,Dyp_tools.No_priority); Dyp_tools.Ter tn_ocaml_type;  Dyp_tools.Ter tn_uident],Dyp_tools.default_priority)
(* token_list -> token_list Ocaml_type Uident *)

let a_token_list = Special_types.Dypgen_action(fun l _ _ d dd ld prd ->
  (match l with
    | [Obj_void; Obj_uident tok] -> Token_list [(tok,"No_type")]
    | [Obj_void; Obj_type typ; Obj_uident tok] ->
        Token_list [(tok,typ)]
    | [Token_list tl; Obj_uident tok] -> Token_list ((tok,"No_type")::tl)
    | [Token_list tl; Obj_type typ; Obj_uident tok] ->
        Token_list ((tok,typ)::tl)
    | _ -> failwith "a_token_list"
),true,Data_void,dd,ld,[],[],prd)


let r_relation_1 = (ntn_relation,[Dyp_tools.Ter tn_kwd_relation],Dyp_tools.default_priority) 
(* relation -> Kwd_relation *)
let r_relation_2 = (ntn_relation,[Dyp_tools.Ter tn_kwd_relation; Dyp_tools.Ter tn_lident; Dyp_tools.Ter tn_colon; Dyp_tools.Ter tn_lident],Dyp_tools.default_priority)
(* relation -> Kwd_relation Lident Colon Lident *)
let r_relation_3 = (ntn_relation,[Dyp_tools.Non_ter (ntn_relation,Dyp_tools.No_priority); Dyp_tools.Ter tn_lident; Dyp_tools.Ter tn_colon; Dyp_tools.Ter tn_lident],Dyp_tools.default_priority)
(* relation -> relation Lident Colon Lident *)

let a_relation = Special_types.Dypgen_action(fun l _ _ d dd ld prd ->
  (match l with
    | [Obj_void] -> Relation []
    | [Obj_void; Obj_lident p1; Obj_void; Obj_lident p2] -> Relation [(p1,p2)]
    | [Relation rel; Obj_lident p1; Obj_void; Obj_lident p2] -> Relation ((p1,p2)::rel)
    | _ -> failwith "a_relation"
),true,Data_void,dd,ld,[],[],prd)

let r_grammar_1 = (ntn_grammar,[Dyp_tools.Ter tn_lident; Dyp_tools.Ter tn_colon; Dyp_tools.Non_ter (ntn_bar_opt,Dyp_tools.No_priority); Dyp_tools.Non_ter (ntn_literal_list,Dyp_tools.No_priority); Dyp_tools.Ter tn_ocaml_code; Dyp_tools.Non_ter (ntn_priority,Dyp_tools.No_priority)],Dyp_tools.default_priority)
(* grammar -> Lident Colon opt_bar literal_list Ocaml_code priority *)
let r_grammar_2 = (ntn_grammar,[Dyp_tools.Non_ter (ntn_grammar,Dyp_tools.No_priority); Dyp_tools.Ter tn_lident; Dyp_tools.Ter tn_colon; Dyp_tools.Non_ter (ntn_bar_opt,Dyp_tools.No_priority); Dyp_tools.Non_ter (ntn_literal_list,Dyp_tools.No_priority); Dyp_tools.Ter tn_ocaml_code; Dyp_tools.Non_ter (ntn_priority,Dyp_tools.No_priority)],Dyp_tools.default_priority)
(* grammar -> grammar Lident Colon opt_bar literal_list Ocaml_code priority *)
let r_grammar_3 = (ntn_grammar,[Dyp_tools.Non_ter (ntn_grammar,Dyp_tools.No_priority);Dyp_tools.Ter tn_bar; Dyp_tools.Non_ter (ntn_literal_list,Dyp_tools.No_priority); Dyp_tools.Ter tn_ocaml_code; Dyp_tools.Non_ter (ntn_priority,Dyp_tools.No_priority)],Dyp_tools.default_priority)
(* grammar -> grammar Bar literal_list Ocaml_code priority *)

let r_grammar_4 = (ntn_grammar,[Dyp_tools.Ter tn_lident; Dyp_tools.Ter tn_colon; Dyp_tools.Non_ter (ntn_bar_opt,Dyp_tools.No_priority); Dyp_tools.Non_ter (ntn_literal_list,Dyp_tools.No_priority); Dyp_tools.Ter tn_kwd_full; Dyp_tools.Ter tn_ocaml_code; Dyp_tools.Non_ter (ntn_priority,Dyp_tools.No_priority)],Dyp_tools.default_priority)
(* grammar -> Lident Colon opt_bar literal_list KWD_FULL Ocaml_code priority *)
let r_grammar_5 = (ntn_grammar,[Dyp_tools.Non_ter (ntn_grammar,Dyp_tools.No_priority); Dyp_tools.Ter tn_lident; Dyp_tools.Ter tn_colon; Dyp_tools.Non_ter (ntn_bar_opt,Dyp_tools.No_priority); Dyp_tools.Non_ter (ntn_literal_list,Dyp_tools.No_priority); Dyp_tools.Ter tn_kwd_full; Dyp_tools.Ter tn_ocaml_code; Dyp_tools.Non_ter (ntn_priority,Dyp_tools.No_priority)],Dyp_tools.default_priority)
(* grammar -> grammar Lident Colon opt_bar literal_list KWD_FULL Ocaml_code priority *)
let r_grammar_6 = (ntn_grammar,[Dyp_tools.Non_ter (ntn_grammar,Dyp_tools.No_priority);Dyp_tools.Ter tn_bar; Dyp_tools.Non_ter (ntn_literal_list,Dyp_tools.No_priority); Dyp_tools.Ter tn_kwd_full; Dyp_tools.Ter tn_ocaml_code; Dyp_tools.Non_ter (ntn_priority,Dyp_tools.No_priority)],Dyp_tools.default_priority)
(* grammar -> grammar Bar literal_list KWD_FULL Ocaml_code priority *)

let a_grammar = Special_types.Dypgen_action(fun l _ _ d dd ld prd ->
  (match l with
    | [Obj_lident nt;Obj_void;Obj_void;Literal_list ll;Code c;Obj_lident p] ->
        let _ = fprintf out "action grammar 1\n" in Grammar [(nt,p,List.rev ll,Classic_action c)]
    | [Grammar g;Obj_lident nt;Obj_void;Obj_void;Literal_list ll;Code c;Obj_lident p] ->
        let _ = fprintf out "action grammar 2\n" in Grammar ((nt,p,List.rev ll,Classic_action c)::g)
    | [Grammar g;Obj_void;Literal_list ll;Code c;Obj_lident p] ->
        let _ = fprintf out "action grammar 3\n" in 
        let last_rule = List.hd g in
        let lhs_non_terminal,_,_,_ = last_rule in
        Grammar ((lhs_non_terminal,p,List.rev ll,Classic_action c)::g)
    | [Obj_lident nt;Obj_void;Obj_void;Literal_list ll;Obj_void;Code c;Obj_lident p] ->
        let _ = fprintf out "action grammar 1\n" in Grammar [(nt,p,List.rev ll,Full_action c)]
    | [Grammar g;Obj_lident nt;Obj_void;Obj_void;Literal_list ll;Obj_void;Code c;Obj_lident p] ->
        let _ = fprintf out "action grammar 2\n" in Grammar ((nt,p,List.rev ll,Full_action c)::g)
    | [Grammar g;Obj_void;Literal_list ll;Obj_void;Code c;Obj_lident p] ->
        let _ = fprintf out "action grammar 3\n" in 
        let last_rule = List.hd g in
        let lhs_non_terminal,_,_,_ = last_rule in
        Grammar ((lhs_non_terminal,p,List.rev ll,Full_action c)::g)
    | _ -> failwith "a_grammar"
),true,Data_void,dd,ld,[],[],prd)

let r_bar_opt_0 = (ntn_bar_opt,[],Dyp_tools.default_priority)
(* bar_opt -> *)
let r_bar_opt_1 = (ntn_bar_opt,[Dyp_tools.Ter tn_bar],Dyp_tools.default_priority)
(* bar_opt -> Bar *)

let a_bar_opt = Special_types.Dypgen_action(fun _ _ _ d dd ld prd -> Obj_void,true,Data_void,dd,ld,[],[],prd)

let r_literal_list_0 = (ntn_literal_list,[],Dyp_tools.default_priority)
(* literal_list ->  *)
let r_literal_list_1 = (ntn_literal_list,[Dyp_tools.Ter tn_uident],Dyp_tools.default_priority)
(* literal_list -> Uident *)
let r_literal_list_2 = (ntn_literal_list,[Dyp_tools.Ter tn_lident],Dyp_tools.default_priority)
(* literal_list -> Lident *)
let r_literal_list_3 = (ntn_literal_list,[Dyp_tools.Ter tn_lident; Dyp_tools.Ter tn_lparen; Dyp_tools.Ter tn_equal; Dyp_tools.Ter tn_lident; Dyp_tools.Ter tn_rparen],Dyp_tools.default_priority)
(* literal_list -> Lident Lparen Equal Lident Rparen *)
let r_literal_list_4 = (ntn_literal_list,[Dyp_tools.Ter tn_lident; Dyp_tools.Ter tn_lparen; Dyp_tools.Ter tn_lident; Dyp_tools.Ter tn_rparen],Dyp_tools.default_priority)
(* literal_list -> Lident Lparen Lident Rparen *)
let r_literal_list_5 = (ntn_literal_list,[Dyp_tools.Non_ter (ntn_literal_list,Dyp_tools.No_priority); Dyp_tools.Ter tn_uident],Dyp_tools.default_priority)
(* literal_list -> literal_list Uident *)
let r_literal_list_6 = (ntn_literal_list,[Dyp_tools.Non_ter (ntn_literal_list,Dyp_tools.No_priority); Dyp_tools.Ter tn_lident],Dyp_tools.default_priority)
(* literal_list -> literal_list Lident *)
let r_literal_list_7 = (ntn_literal_list,[Dyp_tools.Non_ter (ntn_literal_list,Dyp_tools.No_priority); Dyp_tools.Ter tn_lident; Dyp_tools.Ter tn_lparen; Dyp_tools.Ter tn_equal; Dyp_tools.Ter tn_lident; Dyp_tools.Ter tn_rparen],Dyp_tools.default_priority)
(* literal_list -> literal_list Lident Lparen Equal Lident Rparen *)
let r_literal_list_8 = (ntn_literal_list,[Dyp_tools.Non_ter (ntn_literal_list,Dyp_tools.No_priority); Dyp_tools.Ter tn_lident; Dyp_tools.Ter tn_lparen; Dyp_tools.Ter tn_lident; Dyp_tools.Ter tn_rparen],Dyp_tools.default_priority)
(* literal_list -> literal_list Lident Lparen Lident Rparen *)

let a_literal_list = Special_types.Dypgen_action(fun l _ _ d dd ld prd ->
  (match l with
    | [] -> let _ = fprintf out "action literal_list 0\n" in Literal_list []
    | [Obj_uident tok] -> let _ = fprintf out "action literal_list 1\n" in 
        Literal_list [Obj_terminal tok]
    | [Obj_lident nt] -> let _ = fprintf out "action literal_list 2\n" in 
        Literal_list [Obj_non_terminal (nt,"Dyp_tools.No_priority",false)]
    | [Obj_lident nt; Obj_lparen; Obj_equal; Obj_lident p; Obj_rparen] -> 
        let _ = fprintf out "action literal_list 3\n" in 
        Literal_list [Obj_non_terminal (nt,p,true)]
    | [Obj_lident nt; Obj_lparen; Obj_lident p; Obj_rparen] -> 
        let _ = fprintf out "action literal_list 4\n" in 
        Literal_list [Obj_non_terminal (nt,p,false)]
    | [Literal_list ll; Obj_uident tok] -> 
        let _ = fprintf out "action literal_list 5\n" in 
        Literal_list ((Obj_terminal tok)::ll)
    | [Literal_list ll; Obj_lident nt] ->
        let _ = fprintf out "action literal_list 6\n" in 
        Literal_list ((Obj_non_terminal (nt,"Dyp_tools.No_priority",false))::ll)
    | [Literal_list ll; Obj_lident nt; Obj_lparen; Obj_equal; Obj_lident p; Obj_rparen] -> 
        let _ = fprintf out "action literal_list 7\n" in 
        Literal_list ((Obj_non_terminal (nt,p,true))::ll)
    | [Literal_list ll; Obj_lident nt; Obj_lparen; Obj_lident p; Obj_rparen] -> 
       let _ = fprintf out "action literal_list 8\n" in 
       Literal_list ((Obj_non_terminal (nt,p,false))::ll)
    | _ -> failwith "a_literal_list"
),true,Data_void,dd,ld,[],[],prd)

let r_priority_0 = (ntn_priority,[],Dyp_tools.default_priority)
let r_priority_1 = (ntn_priority,[Dyp_tools.Ter tn_lident],Dyp_tools.default_priority)

let a_priority = Special_types.Dypgen_action(fun l _ _ d dd ld prd ->
  (match l with
    | [] -> Obj_lident "default priority"
    | [Obj_lident s] -> Obj_lident s
    | _ -> failwith "a_priority"
),true,Data_void,dd,ld,[],[],prd)

let prio_data = Dyp_tools.empty_priority_data
let global_merge obj_l _ = obj_l

let parsing_device = create_parsing_device [
(r_pgen_input,a_pgen_input);
(r_optional_code_0,a_optional_code);
(r_optional_code_1,a_optional_code);
(r_start_def,a_start_def);
(r_parser_param_info_0,a_parser_param_info);
(r_parser_param_info_1,a_parser_param_info);
(r_parser_param_info_3,a_parser_param_info);
(r_parser_param_info_4,a_parser_param_info);
(r_token_list_1,a_token_list);
(r_token_list_2,a_token_list);
(r_token_list_3,a_token_list);
(r_token_list_4,a_token_list);
(r_relation_1,a_relation);
(r_relation_2,a_relation);
(r_relation_3,a_relation);
(r_grammar_1,a_grammar);
(r_grammar_2,a_grammar);
(r_grammar_3,a_grammar);
(r_grammar_4,a_grammar);
(r_grammar_5,a_grammar);
(r_grammar_6,a_grammar);
(r_bar_opt_0,a_bar_opt);
(r_bar_opt_1,a_bar_opt);
(r_literal_list_0,a_literal_list);
(r_literal_list_1,a_literal_list);
(r_literal_list_2,a_literal_list);
(r_literal_list_3,a_literal_list);
(r_literal_list_4,a_literal_list);
(r_literal_list_5,a_literal_list);
(r_literal_list_6,a_literal_list);
(r_literal_list_7,a_literal_list);
(r_literal_list_8,a_literal_list);
(r_priority_0,a_priority);
(r_priority_1,a_priority)
] Dyp_tools.empty_priority_data Special_types.LALR Data_void 0 Dypgen_runtime_tools.empty_merge_map global_merge Dypgen_runtime_tools.empty_datadyn

let input_file = !string_ref
let output_file = (Filename.chop_extension input_file)^".ml"
let output_file_mli = (Filename.chop_extension input_file)^".mli"

let lexbuf = Lexing.from_channel (Pervasives.open_in input_file)

let get_value t = match t with
  | LIDENT s -> Obj_lident s
  | UIDENT s -> Obj_uident s
  | OCAML_CODE s -> Code s
  | OCAML_TYPE t -> Obj_type t
  | LPAREN -> Obj_lparen
  | RPAREN -> Obj_rparen
  | EQUAL -> Obj_equal
  | _ -> Obj_void

let data_equal = {
Dypgen_runtime_tools.global_data_equal = (==);
Dypgen_runtime_tools.local_data_equal = (==) }

let parse_result = glrParse parsing_device get_value ntn_start data_equal Pgen_lexer.token lexbuf (fun _ -> (Lexing.dummy_pos,Lexing.dummy_pos))

let header_main, token_list, relation, non_terminal_start, start_type,
  grammar, trailer_main = match fst (List.hd parse_result) with
  | Pgen_input (c1,(b,d,(st,start_type)),g,c2) -> (c1,b,d,st,start_type,g,c2)
  | _ -> failwith "parse tree"
let header_main = header_main^"\n"
let trailer_main = trailer_main^"\n"

module Ordered_string =
struct
  type t = string
  let compare = Pervasives.compare
end

module String_set = Set.Make(Ordered_string)
module String_map = Map.Make(Ordered_string)


(* string ["a";"b";"c"] returns "[a;b;c]" *)
let string_list sl =
  let aux code s = code^s^";" in
  let code = List.fold_left aux "[" sl in
  let string_length = String.length code in
  (String.sub code 0 (string_length-1))^"]"


let code_token_decl,code_export_module,token_map =
  let code_token_decl = "type token =" in
  let aux (code_token_decl,token_map) (tok,typ) =
    if typ = "No_type"
    then (code_token_decl^" | "^tok),
      (String_map.add tok typ token_map)
    else (code_token_decl^" | "^tok^" of ("^typ^")"),
      (String_map.add tok typ token_map)
  in
  let code_token_decl,token_map =
    List.fold_left aux (code_token_decl,String_map.empty) token_list
  in
  let code_token_decl = code_token_decl^"\n" in
  code_token_decl,
  "module Export_type = \nstruct\n"^
  code_token_decl ^"end\ninclude Export_type\n\n",
  token_map



let code_token_name_decl,token_name_map(*, code_number_of_tokens*) =
  let code_token_name_decl = "" in
  let aux (code,n,token_name_map) (tok,_) =
    (code^"let token_name_"^tok^" = "^(string_of_int n)^"\n",
    (n+1),String_map.add tok n token_name_map)
  in
  let code_token_name_decl,n,token_name_map =
    List.fold_left aux (code_token_name_decl,0,String_map.empty) token_list
  in
  let code_token_name_decl =
    code_token_name_decl^"let dummy_token_name = "^(string_of_int n)^"\n"
    ^"let token_name_epsilon = "^(string_of_int (n+1))^"\n"
    ^"let token_epsilon = token_name_epsilon\n"
  in
  code_token_name_decl,
  String_map.add "dummy" n token_name_map(*,
  "let () = number_of_tokens := "^(string_of_int (n+2))^"\n"*)



let code_token_functions =
  let code_token_functions =
    (*"let compare_token_name t1 t2 = Pervasives.compare t1 t2\n"^*)
    "let get_name t = match t with"
  in
  let aux code (tok,typ) =
    if typ = "No_type" then code^" | "^tok^" -> token_name_"^tok
    else code^" | "^tok^" _ -> token_name_"^tok
  in
  let code_token_functions = List.fold_left aux code_token_functions token_list in
  let code_token_functions =
    code_token_functions^"\n"^
    "let str_token t = match t with\n"
  in
  let aux code (tok,typ) =
    if typ = "No_type" then code^" | "^tok^" -> \""^tok^"\""
    else if typ = "int" then code^" | "^tok^" i -> string_of_int i"
    else if typ = "string" then code^" | "^tok^" s -> s"
    else code^" | "^tok^" _ -> \""^tok^"\""
  in
  let code_token_functions =
    (List.fold_left aux code_token_functions token_list)^"\n"
  in
  let code_str_token_name =
    let tna code (tok,_) = code^"\""^tok^"\";" in
    "let token_name_array = [|"^(List.fold_left tna "" token_list)^
    "\"dummy_token\";\"token_epsilon\"|]\n"^
    "let str_token_name t = token_name_array.(t)\n"
  in
  code_token_functions^code_str_token_name



(*
let code_token_decl = "type token ="
let aux (code_token_decl,token_map) (tok,typ) =
  if typ = "No_type" then (code_token_decl^" | "^tok),(String_map.add tok typ token_map)
  else (code_token_decl^" | "^tok^" of ("^typ^")"),(String_map.add tok typ token_map)
let code_token_decl,token_map = List.fold_left aux (code_token_decl,String_map.empty) token_list
let code_token_decl = code_token_decl^"\n"

let code_token_name_decl = "type token_name ="
let aux code (tok,_) = code^" | token_name_"^tok
let code_token_name_decl = List.fold_left aux code_token_name_decl token_list
let code_token_name_decl = code_token_name_decl^" | token_name_epsilon | token_name_dummy\n"
^"let dummy_token_name = token_name_dummy\n"
^"let token_epsilon = token_name_epsilon\n"

let code_token_functions =
"let compare_token_name t1 t2 = Pervasives.compare t1 t2
let get_name t = match t with"
let aux code (tok,typ) =
  if typ = "No_type" then code^" | "^tok^" -> token_name_"^tok
  else code^" | "^tok^" _ -> token_name_"^tok
let code_token_functions = List.fold_left aux code_token_functions token_list

let code_token_functions = code_token_functions^"\nlet str_token t = match t with\n"
let aux code (tok,typ) =
  if typ = "No_type" then code^" | "^tok^" -> \""^tok^"\""
  else if typ = "int" then code^" | "^tok^" i -> string_of_int i"
  else if typ = "string" then code^" | "^tok^" s -> s"
  else code^" | "^tok^" _ -> \""^tok^"\""
let code_token_functions = List.fold_left aux code_token_functions token_list

let code_token_functions = code_token_functions^"let str_token_name t = match t with\n"
let aux code (tok,_) = code^" | token_name_"^tok^" -> \""^tok^"\""
let code_token_functions = List.fold_left aux code_token_functions token_list
let code_token_functions = code_token_functions^" | token_name_epsilon -> \"epsilon\"\n"
^" | token_name_dummy -> \"dummy\"\n\n"
*)


(*let code_non_terminal_decl = "type non_ter = "
let aux1 st_set ld = match ld with
  | Obj_terminal _ -> st_set
  | Obj_non_terminal (nt,_,_) -> String_set.add nt st_set
let aux2 st_set (lhs_nt,_,ld_list,_) =
  List.fold_left aux1 (String_set.add lhs_nt st_set) ld_list
let non_terminal_set = List.fold_left aux2 String_set.empty grammar
let aux nt_string code = code^" | Non_terminal_name_"^nt_string
let code_non_terminal_decl = String_set.fold aux non_terminal_set code_non_terminal_decl
let code_non_terminal_decl = code_non_terminal_decl^" | Non_terminal_name_startprime\n"*)

let code_non_terminal_decl,non_terminal_set,merge_function_list =
  let aux1 st_set ld = match ld with
    | Obj_terminal _ -> st_set
    | Obj_non_terminal (nt,_,_) -> String_set.add nt st_set
  in
  let aux2 st_set (lhs_nt,_,ld_list,_) =
    List.fold_left aux1 (String_set.add lhs_nt st_set) ld_list
  in
  let non_terminal_set = List.fold_left aux2 String_set.empty grammar in
  let aux nt_string (code1,mfl,n) =
    code1^"let "^nt_string^" = "^(string_of_int n)^"\n",
    (("merge_"^nt_string^","^(string_of_int n))::mfl),
    (n+1)
  in
  let code_non_terminal_decl,merge_function_list,_ =
    String_set.fold aux non_terminal_set
     ("",[],1)
  in
  code_non_terminal_decl^"let non_terminal_startprime = 0\n",
  non_terminal_set,merge_function_list



let code_nt_functions =
  let code = "let entry_points = ["^non_terminal_start^"]\n"^
    "let compare_ntn nt1 nt2 = Pervasives.compare nt1 nt2\n"^
    "let str_non_terminal nt = nt_names.(nt)\n"
  in
  let aux nt_string code = code^";\""^nt_string^"\"" in
  let code_nt_names =
    String_set.fold aux non_terminal_set ""
  in
  let code_nt_names = "let nt_names = [|\"0\""^code_nt_names^"|]\n" in
  code_nt_names^code




let code_main_1 =
"module P = Dyp.Parser.Make(Parser_parameters_module)
open Parser_parameters_module
open P
open P.Parser_PAR
include (P.Dyp_tools:sig exception Syntax_error end)
type priority = P.Dyp_tools.priority
include Export_type\n\n"

(*let code_priority_def = "let Dyp_tools.default_priority = 0\n"*)

let aux (str_set:String_set.t) (p1,p2) =
  String_set.add p2 (String_set.add p1 str_set)
let priority_set = List.fold_left aux String_set.empty relation

let aux1 st_set ld = match ld with
  | Obj_terminal _ -> st_set
  | Obj_non_terminal (_,p,_) -> if p="Dyp_tools.No_priority" then st_set
      else String_set.add p st_set
let aux2 st_set (_,p,ld_list,_) =
  List.fold_left aux1 (String_set.add p st_set) ld_list
let priority_set = List.fold_left aux2 priority_set grammar

let aux p (st_map,n) = (String_map.add p n st_map,n+1)
let priority_map,_ = String_set.fold aux priority_set (String_map.empty,1)

let priority_map = String_map.add "default priority" 0 priority_map

(*let code_var_list n =
  if n = 0 then "" else
  let rec aux p =
    if n = p then "__dypgen_av_"^(string_of_int p)
    else "__dypgen_av_"^(string_of_int p)^";"^(aux (p+1))
  in
  aux 1*)

let aux (lhs_nt,p,ld_list,ocaml_code) =
  let aux2 code ld = match ld with
    | Obj_terminal ter -> code^"Dyp_tools.Ter token_name_"^ter^";"
    | Obj_non_terminal (ntn,p,eq) ->
        let code_p =
          if p = "Dyp_tools.No_priority" then "Dyp_tools.No_priority "
          else
            (if eq then "Lesseq_priority " else "Less_priority ")^
            (string_of_int (String_map.find p priority_map))
        in
        code^"Dyp_tools.Non_ter ("^ntn^","^code_p^");"
  in
  (*let code_priority = (string_of_int (String_map.find p priority_map)) in*)
  let code_literal_list = List.fold_left aux2 "" ld_list in
  let string_length = (String.length code_literal_list) in
  let code_literal_list =
    if string_length = 0 then code_literal_list
    else String.sub code_literal_list 0 (string_length-1)
  in
  let code_rule = "("^ lhs_nt^ ",["^ code_literal_list^ "],Dyp_tools.default_priority)" in
  
  (*let aux_av (code,n) lit =
    let typ = match lit with
      | Obj_terminal ter -> let typ = String_map.find ter token_map in
          if typ = "No_type" then "unit" else typ
      | Obj_non_terminal (nt,_,_) -> "'"^nt
    in code^"let _"^(string_of_int n)^" = (Obj.obj __dypgen_av_"^
      (string_of_int n)^" : "^typ^") in \n",(n+1)
  in
  let action_variable_code,_ = List.fold_left aux_av ("",1) ld_list in*)
  
  (*let rule_type = if lhs_nt = non_terminal_start then start_type else "'"^lhs_nt in*)
  
  let code_var_list =
    let f (code,n) lit = match lit with
      | Obj_terminal ter -> let typ = String_map.find ter token_map in
          if typ = "No_type" then
            code^" _"^(string_of_int n)^";", n+1
          else code^"Obj_"^ter^" _"^(string_of_int n)^";", n+1
      | Obj_non_terminal (nt,_,_) -> code^"Obj_"^nt^" _"^(string_of_int n)^";", n+1
    in
    let c,_ = List.fold_left f ("",1) ld_list in
    let s_length = (String.length c) in
    if s_length = 0 then c
    else String.sub c 0 (s_length-1)
  in
  
  let code_action = match ocaml_code with
    | Classic_action oc_code ->
        "Special_types.Dypgen_action(fun action_variable__l _ _ _d _dd _ld _prd -> (match action_variable__l with ["^
        code_var_list^"] -> Obj_"^lhs_nt^" ("^oc_code^
        ") | _ -> failwith \"Invalid number of arguments in action\"),true,Data_void,_dd,_ld,[],[],_prd)"
    | Full_action oc_code ->
        "Special_types.Dypgen_action(fun action_variable__l _ _ _data _dd _ld _prd -> (match action_variable__l with ["^
        code_var_list^"] -> "^
        "let ob,b,d = "^oc_code^
        " in ((Obj_"^lhs_nt^" ob),b,d,_dd,_ld,[],[],_prd)\n"^
        " | _ -> failwith \"Invalid number or kind of arguments in action\"))"
  in
  "("^code_rule^","^code_action^")"

let list_code_rapf = List.map aux grammar
let code_grammar =
  let rec aux sl = match sl with
    | [] -> ""
    | [s] -> s
    | s::t -> s^"\n;\n"^(aux t)
  in "let rapf_list = [\n"^(aux list_code_rapf)^"]\n"

(*let code_grammar = code_grammar^"let current_grammar,nt_nb,map_po,user_g = make_grammar \n"*)

let code_prio_data = "let current_priority_data = Dyp_tools.empty_priority_data\n"
let aux code (p1,p2) =
  let i1 = string_of_int (String_map.find p1 priority_map) in
  let i2 = string_of_int (String_map.find p2 priority_map) in
  code^"let current_priority_data = update_priority current_priority_data [("^
   i1^","^i2^",true)]\n"
let code_prio_data = (List.fold_left aux code_prio_data relation)^"\n"

let code_main_2 = "let parsing_device = create_parsing_device rapf_list Dyp_tools.empty_priority_data Special_types.LR1 Data_void 0 merge_map merge Dypgen_runtime_tools.empty_datadyn\n"

let code_main_2 = code_main_2^
"let "^non_terminal_start^" f lexbuf =
  let data_equal = {
    Dypgen_runtime_tools.global_data_equal = (==);
    Dypgen_runtime_tools.local_data_equal = (==) }
  in
  let lexbuf_position lexbuf = (lexbuf.Lexing.lex_curr_p,lexbuf.Lexing.lex_start_p) in
  let pf = glrParse parsing_device __dypgen_get_value "^non_terminal_start^
  " data_equal f lexbuf lexbuf_position in
  let aux1 (o,p) = match o with
    | Obj_"^non_terminal_start^" r -> (r,p) | _ -> failwith \"Wrong type for entry result\" in
  List.map aux1 pf\n\n"

let parser_param_header = "
module Parser_parameters_module =
struct\n\n"

let code_export_module = "module Export_type = \nstruct\n"^ code_token_decl^"end\ninclude Export_type\n\n"

let code_type_obj =
  let code_obj =
    let aux nt code =
      if nt = non_terminal_start then code
      else code^" '"^nt^","
    in
    let type_param =(String_set.fold aux non_terminal_set "") in
    let string_length = String.length type_param in
    let type_param = String.sub type_param 0 (string_length-1) in
    "("^type_param^") obj"
  in
  let aux1 tok typ code = if typ = "No_type" then code^"  | Obj_"^tok^"\n"
    else code^"  | Obj_"^tok^" of ("^typ^")\n"
  in
  let aux2 nt code =
    if nt = non_terminal_start then
      code^"  | Obj_"^nt^" of "^start_type^"\n"
    else code^"  | Obj_"^nt^" of '"^nt^"\n"
  in
  "type "^code_obj^" =\n"^
  (String_map.fold aux1 token_map "")^
  (String_set.fold aux2 non_terminal_set "")^
  "type data = Data_void\n"



let code_merge_functions =
  let aux nt_string code = code^"let merge_"^nt_string^" ol _ = ol\n" in
  String_set.fold aux non_terminal_set ""

let code_merge_map =
  let code_merge_function_list = string_list merge_function_list in
  "let merge_map = Dypgen_runtime_tools.init_merge_map "^
  code_merge_function_list
  (*let aux nt_string code = code^"let merge_map = Nt_map.add "^
    nt_string^" merge_"^nt_string^" merge_map\n" in
  "let merge_map = Nt_map.empty\n"^
  (String_set.fold aux non_terminal_set "")*)

(*let code_merge_map =
  let aux2 nt_string nt_int mfl = ("(fun ol o -> (
  let f1 o = match o with "^obj_pref^"Obj_"^nt_string^" ob -> ob
    | _ -> failwith \"type error, bad obj in dyp_merge_"^nt_string^"\"
  in
  let o = f1 o in
  let ol = List.map f1 ol in
  let ol = dyp_merge_"^nt_string^" ol o in
  let f2 o = "^obj_pref^"Obj_"^nt_string^" o in
  List.map f2 ol)),"^(string_of_int nt_int))::mfl
  in
  let merge_function_list = String_map.fold aux2 non_terminal_map [] in
  let code_merge_function_list = string_list merge_function_list in
  (String_set.fold aux1 non_terminal_set "")^
  "let merge_map = Dypgen_runtime_tools.init_merge_map "^code_merge_function_list^"\n"
*)


let code_get_value =
  let aux code (tok,typ) =
    let s = if typ = "No_type" then " -> Obj_"^tok^"\n"
      else " x -> Obj_"^tok^" x\n"
    in
    code^"  | "^tok^s
  in
  "let __dypgen_get_value t = match t with\n"^
  (List.fold_left aux "" token_list)^"\n"

let parser_code = parser_param_header^
  code_export_module^

  code_token_name_decl^
  code_token_functions^

  code_non_terminal_decl^
  code_nt_functions^

  (*code_parser_param_info^*)
  "let priority_names = [|\"0\"|]"^
  "let merge_warning = false\n"^
  "end\n\n"^

  code_main_1^
  (*code_number_of_tokens^*)
  code_type_obj^
  code_get_value^
  "let merge ol _ = ol\n"^
  header_main^
  code_grammar^
  code_prio_data^
  code_merge_functions^
  trailer_main^
  code_merge_map^
  code_main_2

let parser_code_mli =
  "exception Syntax_error\n"^
  "type priority\n"^
  code_token_decl^"val "^non_terminal_start^
  " : (Lexing.lexbuf -> token) -> Lexing.lexbuf -> ("^start_type^" * priority) list\n"

let dest_file = open_out output_file
let dest_file_mli = open_out output_file_mli

let () = output_string dest_file parser_code
let () = output_string dest_file_mli parser_code_mli

@h=tangler('dypgen/generators/pgen/pgen_parser_param.ml')
@select(h)
(*module Prio =
struct
  type priority = int
  let compare_priority p1 p2 = Pervasives.compare p1 p2
end

include Prio
include Dyp.Priority_by_relation.Make (Prio)

let init_priority = 0
let str_prio p = (string_of_int p) *)

(*type data = Data_void
let global_data_equal = (==)
let local_data_equal = (==)*)

type token = LPAREN | RPAREN | COLON | PERCENTPERCENT | LBRACE | RBRACE | BAR | EQUAL | EOF | KWD_TOKEN | KWD_START | KWD_RELATION | KWD_FULL | OCAML_CODE of string | OCAML_TYPE of string | UIDENT of string | LIDENT of string



let tn_lparen = 0
let tn_rparen = 1
let tn_colon = 2
let tn_percentpercent = 3
let tn_lbrace = 4
let tn_rbrace = 5
let tn_bar = 6
let tn_equal = 7
let tn_EOF = 8
let tn_kwd_token = 9
let tn_kwd_start = 10
let tn_kwd_relation = 11
let tn_kwd_full = 12
let tn_ocaml_code = 13
let tn_ocaml_type = 14
let tn_uident = 15
let tn_lident = 16

let dummy_token_name = 17
let token_epsilon = 18
(*let compare_token_name t1 t2 = Pervasives.compare t1 t2*)
let str_token t = match t with
  | LPAREN -> "("
  | RPAREN -> ")"
  | COLON -> ":"
  | PERCENTPERCENT -> "%%"
  | LBRACE -> "}"
  | RBRACE -> "}"
  | BAR -> "|"
  | EQUAL -> "="
  | EOF -> "EOF"
  | KWD_TOKEN -> "%token"
  | KWD_START -> "%start"
  | KWD_RELATION -> "%relation"
  | KWD_FULL -> "%full"
  | OCAML_CODE c -> c
  | OCAML_TYPE t -> t
  | UIDENT i -> i
  | LIDENT i -> i
let token_names = [|"(";")";":";"%%";"{";"}";"|";"=";"EOF";"%token";"%start";"%relation";"%full";"ocaml_code";"ocaml_type";"Uident";"Lident";"dummy";"epsilon"|]
let str_token_name t = token_names.(t)

let get_name t = match t with
  | LPAREN -> tn_lparen
  | RPAREN -> tn_rparen
  | COLON -> tn_colon
  | PERCENTPERCENT -> tn_percentpercent
  | LBRACE -> tn_lbrace
  | RBRACE -> tn_rbrace
  | BAR -> tn_bar
  | EQUAL -> tn_equal
  | EOF -> tn_EOF
  | KWD_TOKEN -> tn_kwd_token
  | KWD_START -> tn_kwd_start
  | KWD_RELATION -> tn_kwd_relation
  | KWD_FULL -> tn_kwd_full
  | OCAML_CODE _ -> tn_ocaml_code
  | OCAML_TYPE _ -> tn_ocaml_type
  | UIDENT _ -> tn_uident
  | LIDENT _ -> tn_lident

(*type token_assoc = Token_assoc_left | Token_assoc_right | Token_nonassoc | Token_assoc
module Ordered_token_name =
struct
  type t = token_name
  let compare = Pervasives.compare
end
module TN_map = Map.Make(Ordered_token_name)
let token_assoc_map = TN_map.empty*)


let entry_points = [1]
let non_terminal_startprime = 0
let compare_ntn nt1 nt2 = Pervasives.compare nt1 nt2

let nt_names = [|"S'";"start";"parser_param_info";"token_list";"relation";"start_def";"grammar";"bar_opt";"literal_list";"priority";"optional_code"|]

let str_non_terminal nt = nt_names.(nt)

type token_desc = string * string (* 2nd string is for type, if no type is mentioned then the string No_type is chosen *)
type literal_desc = Obj_terminal of string | Obj_non_terminal of (string * string * bool) (* 2nd string for the priority identifier, bool is true=Toeq, bool is false=To *)
type action_desc = Classic_action of string | Full_action of string
type rule_desc = (string * string * (literal_desc list) * action_desc)
type relation_desc = ((string * string) list)
type parser_param_info = (token_desc list) * relation_desc * (string * string)
(*last string is for start statement *)
let priority_names = [|"0"|]

let merge_warning = false

@h=tangler('dypgen/generators/dypgen/dypgen_parser.dyp')
@select(h)
{
open Printf
open Parse_tree
open Dyp_tools
let () = dypgen_verbose := 0

let empty_ppi = {
  token_list = [];
  relation = [];
  start = [];
  generic_merge = []}
}

%token LPAREN RPAREN COMMA COLON PERCENTPERCENT LBRACE RBRACE BAR LESS GREATER EQUAL KWD_TOKEN KWD_START KWD_RELATION KWD_MLI KWD_MERGE <string * int> OCAML_CODE <string> OCAML_TYPE <string * int> PATTERN <string * (int * int * int)> UIDENT <string * (int * int * int)> LIDENT EOF

%start <Parse_tree.obj> main

%%

main: | optional_code parser_param_info PERCENTPERCENT grammar optional_code optional_mli EOF
  { ($1,$2,$4,$5,$6) }

parser_param_info:
  | KWD_START OCAML_TYPE LIDENT  { {empty_ppi with start = [((fst $3),$2)]} }
  | token_list                   { {empty_ppi with token_list = $1} }
  | relation                     { {empty_ppi with relation = $1} }
  | KWD_MERGE LIDENT lident_list { {empty_ppi with generic_merge = [((fst $2),$3)]} }
  | parser_param_info parser_param_info
    %full {
      { token_list = ($1.token_list@$2.token_list);
        relation = $1.relation@$2.relation;
        start = $1.start@$2.start;
        generic_merge = $1.generic_merge@$2.generic_merge},
        false,$data }

lident_list:
  | LIDENT             { [(fst $1)] }
  | LIDENT lident_list { (fst $1)::$2 }

optional_code:
  |            { ("",0) }
  | OCAML_CODE { $1 }

optional_mli:
  |                    { ("",0) }
  | KWD_MLI OCAML_CODE { $2 }

token_list:
  | KWD_TOKEN UIDENT             { [((fst $2),"No_type")] }
  | KWD_TOKEN OCAML_TYPE UIDENT  { [((fst $3),$2)] }
  | token_list UIDENT            { ((fst $2),"No_type")::$1 }
  | token_list OCAML_TYPE UIDENT { ((fst $3),$2)::$1 }

relation:
  | KWD_RELATION { [] }
  | relation relation_list { (Rel_list $2)::$1 }
  | relation LIDENT { (Rel_single (fst $2))::$1 }

relation_list:
  | LIDENT LESS LIDENT { [(fst $1);(fst $3)] }
  | LIDENT LESS relation_list { (fst $1)::$3 }

grammar:
  | LIDENT COLON opt_bar literal_list OCAML_CODE priority
      { let litl,_,part_act_l = $4 in
        [((fst $1),$6,List.rev litl, part_act_l, $5)] }
  | grammar LIDENT COLON opt_bar literal_list OCAML_CODE priority
      { let litl,_,part_act_l = $5 in
        ((fst $2),$7,List.rev litl, part_act_l, $6)::$1 }
  | grammar BAR literal_list OCAML_CODE priority
      { let last_rule = List.hd $1 in
        let lhs_nt,_,_,_,_ = last_rule in
        let litl,_,part_act_l = $3 in
        (lhs_nt,$5,List.rev litl, List.rev part_act_l, $4)::$1 }

opt_bar:
  |     { () }
  | BAR { () }

literal_list:
  |        { ([],0,[]) }
  | literal_list opt_par_act literal opt_pattern
      { let l,len,part_act_l = $1 in
        if len=0 && $2<>(("",0),[("_",0)])
        then raise Giveup else
        let part_act_l =
          let pa,patl = $2 in
          if pa=("",0) then part_act_l
          else ((pa,len),patl)::part_act_l
        in
        ( (($3,($4:((string*int) list)))::l), (len+1), part_act_l ) }

literal:
  | UIDENT { (Obj_terminal $1) }
  | LIDENT { (Obj_non_terminal ((fst $1),("No_priority",(-1,-1,-1)),Pr_eq,1)) }
  | LIDENT LPAREN EQUAL LIDENT RPAREN       { (Obj_non_terminal ((fst $1),$4,Pr_eq,1)) }
  | LIDENT LPAREN LESS EQUAL LIDENT RPAREN { (Obj_non_terminal ((fst $1),$5,Pr_lesseq,1)) }
  | LIDENT LPAREN LESS LIDENT RPAREN       { (Obj_non_terminal ((fst $1),$4,Pr_less,1)) }
  | LIDENT LPAREN GREATER EQUAL LIDENT RPAREN { (Obj_non_terminal ((fst $1),$5,Pr_greatereq,1)) }
  | LIDENT LPAREN GREATER LIDENT RPAREN       { (Obj_non_terminal ((fst $1),$4,Pr_greater,1)) }


priority:
  |        { ("default_priority",(-1,-1,-1)) }
  | LIDENT { $1 }


opt_par_act:
  |                        { (("",0),[("_",0)]) }
  | OCAML_CODE opt_pattern { ($1,$2) }

opt_pattern:
  |         { [("_",0)] }
  | PATTERN { [("("^(fst $1)^")",(snd $1))] }
@h=tangler('dypgen/generators/dypgen/parse_tree.mli')
@select(h)
type token_desc = string * string
(* 2nd string is for type, if no type is mentioned then the string No_type is chosen *)
type nt_priority_desc = Pr_eq | Pr_less | Pr_lesseq | Pr_greater | Pr_greatereq
type literal_desc = Obj_terminal of (string * (int * int * int)) (* (line,col1,col2) *)
  | Obj_non_terminal of (string * (string * (int * int * int)) * nt_priority_desc * int)
(* 2nd string for the priority identifier, bool is true=Toeq, bool is false=To *)
(* the last int is the number of arguments, the parser always returns 1 for it. It is used for partial actions, a rule with partial actions is split and new non terminals are created by dypgen. The result of partial action is a (n+1)-tuple if there are n arguments for this action, thus the following partial actions or the action, can access these arguments. The n arguments are the n first values of the (n+1)-tuple and the last value is the value computed by the partial action.*)
type priority_desc = (string * (int * int * int)) (*| Prio_fun of (string * int)*)
type action_desc = string * int
type pattern_desc = (string * int) list
type rule_desc = string * priority_desc * ((literal_desc * pattern_desc) list) * (((action_desc * int) * pattern_desc) list) * action_desc
(*
(((action_desc * int) * (string list)) list) is the list of the partial actions, the int is the place of the partial action in the right-hand side.
The string lists after literal_desc and action_desc are patterns. the parser only retuns list of one element, but the processing of patterns of partial actions makes use of the list.
*)
type relation_desc = Rel_list of (string list) | Rel_single of string
type set_desc = string * (string list)
type parser_param_info = {
  token_list : token_desc list;
  relation : relation_desc list;
  start : (string * string) list;
  generic_merge :(string * (string list)) list }
type obj =((string * int) * parser_param_info * (rule_desc list) * (string * int) * (string * int))

@h=tangler('dypgen/generators/dypgen/argument.ml')
@select(h)
let verbose = ref 1
let merge_warning = ref false
let lexer = ref "ocamllex"
let aut_kind = ref "LR0"
let priority_enforcement = ref "PAR"
let process_verbose_mode () = verbose := 2
let process_merge_warning () = merge_warning := true
let process_lexer s = if s="ocamllex" || s="ulex" || s="other" then lexer := s else failwith "illegal --lexer option"
let process_aut_kind s = if s="LR0" || s="LALR" || s="LR1" then aut_kind := s else failwith "illegal --automaton option"
let process_prio_aut () = priority_enforcement:="PIA"
let string_ref = ref ""
let process_argument s =
  if s = "" then raise (Arg.Bad "missing input file name")
  else string_ref := s
let pv_obj = ref false
let process_pv_obj () = pv_obj := true
let pv_token = ref false
let process_pv_token () = pv_token := true

let list_arg = [
("-v",Arg.Unit process_verbose_mode,"activates verbose mode: gives details of the parsing of the input file");
("--merge-warning",Arg.Unit process_merge_warning,"activates merge warning: the generated parser will emit a warning on the standard output each time a merge happens");
("--lexer",Arg.String process_lexer,"by default the lexer is ocamllex, use --lexer ulex to specify ulex as the lexer and --lexer other for another lexer, this has an effect on the interface of the parser.");
("--automaton",Arg.String process_aut_kind,"by default the automaton is LALR(1), use -automaton LR0 or -automaton LR1 if you prefer one of them");
("--prio-aut",Arg.Unit process_prio_aut,"use --prio-aut to make the priority enforcement embedded into the automaton, by default they are enforced while parsing.");
("--pv-obj",Arg.Unit process_pv_obj,"the type constructor obj is made as a sum of polymorphic variants instead of a sum of constructors. This is useful when the maximum number of constructors allowed is reached.");
("--pv-token",Arg.Unit process_pv_token,"the type token is made as a sum of polymorphic variants instead of a sum of constructors. This is useful when the maximum number of constructors allowed is reached.")
]

let _ = Arg.parse list_arg process_argument "usage: dypgen [-v] [--merge-warning] [--lexer (ocamllex|ulex|other)] [--automaton (LR0|LALR|LR1)] [--prio-aut] [--pv-obj] file_name.dyp"

let _ = if !string_ref = "" then
  let _ = print_string "usage: dypgen [-v] [--merge-warning] [--lexer (ocamllex|ulex|other)] [--automaton (LR0|LALR|LR1)] [--prio-aut] [--pv-obj] file_name.dyp\n" in exit 0

@h=tangler('dypgen/generators/dypgen/dypgen.ml')
@select(h)
open Parse_tree
open Lexing
open Printf
open Dypgen_lexer


let input_file = !(Argument.string_ref)
let input_file_short = Filename.chop_extension input_file
let output_file = input_file_short^".ml"
let output_file_mli = input_file_short^".mli"


let lexbuf = Lexing.from_channel (Pervasives.open_in input_file)

let parse_result =
  try Dypgen_parser.main Dypgen_lexer.token lexbuf
  with Failure _ -> (
    let b = ref true in
    let () = match !start_dypgen_comment with
      | [] -> ()
      | pos::_ ->
          let line = pos.pos_lnum in
          let col = pos.pos_cnum - pos.pos_bol in
          let () = b:= false in
      fprintf stderr "File \"%s\", line %d, character %d:\nDypgen comment not terminated\n"
        input_file line col
    in
    if !start_ocaml_type<>dummy_pos then (
      let line = !start_ocaml_type.pos_lnum in
      let col = !start_ocaml_type.pos_cnum - !start_ocaml_type.pos_bol in
      let () = b:= false in
      fprintf stderr "File \"%s\", line %d, character %d:\nOcaml type statement not terminated\n"
        input_file line col);
    if !start_pattern<>dummy_pos then (
      let line = !start_pattern.pos_lnum in
      let col = !start_pattern.pos_cnum - !start_pattern.pos_bol in
      let () = b:= false in
      fprintf stderr "File \"%s\", line %d, character %d:\nOcaml pattern not terminated\n"
        input_file line col);
    if !start_ocaml_code<>dummy_pos then (
      let line = !start_ocaml_code.pos_lnum in
      let col = !start_ocaml_code.pos_cnum - !start_ocaml_code.pos_bol in
      let () = b:= false in
      fprintf stderr "File \"%s\", line %d, character %d:\nOcaml code not terminated\n"
        input_file line col);
    if !start_string<>dummy_pos then (
      let line = !start_string.pos_lnum in
      let col = !start_string.pos_cnum - !start_string.pos_bol in
      let () = b:= false in
      fprintf stderr "File \"%s\", line %d, character %d:\nString not terminated\n"
        input_file line col);
    let () = match !start_bracket with
      | [] -> ()
      | pos::_ ->
          let line = pos.pos_lnum in
          let col = pos.pos_cnum - pos.pos_bol in
          let () = b:= false in
      fprintf stderr "File \"%s\", line %d, character %d:\nBracket not closed\n"
        input_file line col
    in
    let () = match !start_curlyb with
      | [] -> ()
      | pos::_ ->
          let line = pos.pos_lnum in
          let col = pos.pos_cnum - pos.pos_bol in
          let () = b:= false in
      fprintf stderr "File \"%s\", line %d, character %d:\nCurly brace not closed\n"
        input_file line col
    in
    let () = match !start_ocaml_comment with
      | [] -> ()
      | pos::_ ->
          let line = pos.pos_lnum in
          let col = pos.pos_cnum - pos.pos_bol in
          let () = b:= false in
      fprintf stderr "File \"%s\", line %d, character %d:\nDypgen comment not terminated\n"
        input_file line col
    in
    if !b then (
      let line2 = lexbuf.lex_curr_p.pos_lnum in
      let col2 = lexbuf.lex_curr_p.pos_cnum - lexbuf.lex_curr_p.pos_bol in
      let pos1 = lexeme_start_p lexbuf in
      let line1 = pos1.pos_lnum in
      let col1 = pos1.pos_cnum - pos1.pos_bol in
      if line1=line2 then
        fprintf stderr "File \"%s\", line %d, characters %d-%d:\nLexing failed\n"
          input_file line2 col1 col2
      else
        fprintf stderr "File \"%s\", from l:%d, c:%d to l:%d, c:%d :\nLexing failed\n"
          input_file line1 col1 line2 col2);
    exit 2)
  | Dypgen_parser.Syntax_error -> (
      let line2 = lexbuf.lex_curr_p.pos_lnum in
      let col2 = lexbuf.lex_curr_p.pos_cnum - lexbuf.lex_curr_p.pos_bol in
      let pos1 = lexeme_start_p lexbuf in
      let line1 = pos1.pos_lnum in
      let col1 = pos1.pos_cnum - pos1.pos_bol in
      if line1=line2 then
        fprintf stderr "File \"%s\", line %d, characters %d-%d\nSyntax error\n"
          input_file line2 col1 col2
      else
        fprintf stderr "File \"%s\", from l:%d, c:%d to l:%d,c:%d\nSyntax error\n"
          input_file line1 col1 line2 col2;
    exit 2)


let (header_main,header_main_pos), token_list, relation,
  non_terminal_start_list, generic_merge,
  grammar, (trailer_main,trailer_main_pos), (mli_code,mli_code_pos) =
    let c1,ppi,g,c2,c3 = fst (List.hd parse_result) in
    (c1,ppi.token_list,ppi.relation,ppi.start,
    ppi.generic_merge,g,c2,c3)


let obj_pref = if !Argument.pv_obj then "`" else ""
let token_pref = if !Argument.pv_token then "`" else ""



(* string ["a";"b";"c"] returns "[a;b;c]" *)
let string_list sl =
  let aux code s = code^s^";" in
  let code = List.fold_left aux "[" sl in
  let string_length = String.length code in
  (String.sub code 0 (string_length-1))^"]"



let grammar =
  
  let rec n_first l n =
    if n=0 then [],l else match l with
      | h::t ->
          let l1,l2 = n_first t (n-1) in h::l1,l2
      | [] -> failwith "grammar n_first"
  in
  let rec return_n n =
    if n=0 then ""
    else (return_n (n-1))^"_"^(string_of_int n)^","
  in
  
  let aux (new_gr,newnt_nb) ra =
    
    let (lhs_nt,prio,ld_list,(par_act_l:((action_desc*int)*pattern_desc) list),
      (ocaml_code,ocaml_code_pos)) = ra in
    if par_act_l = [] then
    ((lhs_nt,prio,ld_list,(par_act_l:((action_desc*int)*pattern_desc) list),
      ((ocaml_code,("","")),ocaml_code_pos))::new_gr,newnt_nb)
    else
    
    let rec f new_gr newnt_nb litl last_pos res_nb
              (par_act_l:((action_desc*int)*pattern_desc) list) patternl =
      match par_act_l with
      | [] -> (new_gr,newnt_nb,litl,res_nb,patternl)
      | (((ac_code,i),pos),patl)::tl ->
          let arg_nb = pos-last_pos in
          let new_nt = if last_pos = 0 then [] else
            [(Obj_non_terminal ("dypgen__nt_"^(string_of_int (newnt_nb-1)),
            ("No_priority",(-1,-1,-1)),Pr_eq,res_nb)),patternl]
          in
          let litl1,litl2 = n_first litl arg_nb in
          let new_litl = new_nt@litl1 in
          let patternl = List.map (fun (_,x) -> x) new_litl in
          let patternl = List.flatten patternl in
          let patternl = patternl@patl in
          let ac_code = ac_code,("("^(return_n (res_nb+arg_nb))^"(","))") in
          let new_gr =
            ("dypgen__nt_"^(string_of_int newnt_nb),("default_priority",(-1,-1,-1)),
            new_litl,[],(ac_code,i))::new_gr
          in
          f new_gr (newnt_nb+1) litl2 pos (res_nb+arg_nb+1) tl patternl
    in
    
    let new_gr,newnt_nb,litl,res_nb,patternl =
      f new_gr newnt_nb ld_list 0 0 par_act_l []
    in
    let new_nt =
      ((Obj_non_terminal ("dypgen__nt_"^(string_of_int (newnt_nb-1)),
      ("No_priority",(-1,-1,-1)),Pr_eq,res_nb)),patternl)
    in
    let new_litl = new_nt::litl in
    let new_gr =
      (lhs_nt,prio,new_litl,[],((ocaml_code,("","")),ocaml_code_pos))::new_gr
    in
    (new_gr,newnt_nb)
  in
  let g,_ = List.fold_left aux ([],0) grammar in g


let insert_line_number = "\n# insert-line-number \""^output_file^"\"\n"
let sharp_line_number lnum = "\n# "^(string_of_int lnum)^" \""^input_file^"\"\n"


let header_main = (sharp_line_number header_main_pos)^header_main^insert_line_number
let trailer_main = (sharp_line_number trailer_main_pos)^trailer_main^insert_line_number
let mli_code = if mli_code = "" then "" else
  (sharp_line_number mli_code_pos)^mli_code^insert_line_number



module Ordered_string =
struct
  type t = string
  let compare = Pervasives.compare
end

module String_set = Set.Make(Ordered_string)
module String_map = Map.Make(Ordered_string)



let code_token_decl, code_export_module, token_map =
  let lbra,rbra = if !Argument.pv_token then "[","]" else "","" in
  let code_token_decl = "type token = "^lbra^"\n" in
  let aux (code_token_decl,token_map) (tok,typ) =
    if typ = "No_type" then
      (code_token_decl^"  | "^token_pref^tok^"\n"),
      (String_map.add tok typ token_map)
    else
      (code_token_decl^"  | "^token_pref^tok^" of ("^typ^")\n"),
      (String_map.add tok typ token_map)
  in
  let code_token_decl, token_map =
    List.fold_left aux (code_token_decl,String_map.empty) token_list
  in
  let code_token_decl = code_token_decl^rbra^"\n"
  in
  code_token_decl,
  "module Export_type =\nstruct\n"^
  code_token_decl ^"end\ninclude Export_type\n\n",
  token_map



let code_token_name_decl,token_name_map,token_dummy_to_marshal,
    token_epsilon_to_marshal(*,code_number_of_tokens*) =
  let code_token_name_decl = "type token_name = int\n" in
  let aux (code,n,token_name_map) (tok,_) =
    (code^"let token_"^tok^" = "^(string_of_int n)^"\n",
    (n+1),String_map.add tok n token_name_map)
  in
  let code_token_name_decl,n,token_name_map =
    List.fold_left aux (code_token_name_decl,0,String_map.empty) token_list
  in
  let code_token_name_decl =
    code_token_name_decl^"let dummy_token_name = "^(string_of_int n)^"\n"
    ^"let token_name_epsilon = "^(string_of_int (n+1))^"\n"
    ^"let token_epsilon = token_name_epsilon\n"
  in
  code_token_name_decl,
  String_map.add "dummy" n token_name_map,
  n,n+1(*,"let () = number_of_tokens := "^(string_of_int (n+2))^"\n"*)



let code_token_functions =
  let code_token_functions =
    "let get_name t = match t with"
  in
  let aux code (tok,typ) =
    if typ = "No_type" then code^" | "^token_pref^tok^" -> token_"^tok
    else code^" | "^token_pref^tok^" _ -> token_"^tok
  in
  let code_token_functions =
    List.fold_left aux code_token_functions token_list
  in
  let code_token_functions =
    code_token_functions^"\n"^
    "let str_token t = match t with\n"
  in
  let aux code (tok,typ) =
    if typ = "No_type" then code^" | "^token_pref^tok^" -> \""^tok^"\""
    else if typ = "int" then code^" | "^token_pref^tok^" i -> string_of_int i"
    else if typ = "string" then code^" | "^token_pref^tok^" s -> s"
    else code^" | "^token_pref^tok^" _ -> \""^tok^"\""
  in
  let code_token_functions =
    (List.fold_left aux code_token_functions token_list)^"\n"
  in
  let code_str_token_name =
    let tna code (tok,_) = code^"\""^tok^"\";" in
    "let token_name_array = [|"^(List.fold_left tna "" token_list)^
    "\"dummy_token\";\"token_epsilon\"|]\n"^
    "let str_token_name t = token_name_array.(t)\n"
  in
  code_token_functions^code_str_token_name



let code_non_terminal_decl,code_datadyn,non_terminal_map,non_terminal_set =
  let code_non_terminal_decl = "" in (*"type Dyp_tools.non_ter = int\n" in*)
  let code_datadyn =
"let __dypgen_datadyn = Dypgen_runtime_tools.init_datadyn "
  (*"let def_datadyn1 = Dypgen_parser_runtime.String_map.empty in\n"*)
  in
  let aux1 st_set ld = match ld with
    | (Obj_terminal _),_ -> st_set
    | (Obj_non_terminal (nt,_,_,_)),_ -> String_set.add nt st_set
  in
  let aux2 (st_set1,st_set2) (lhs_nt,_,ld_list,_,_) =
    (String_set.add lhs_nt st_set1),(List.fold_left aux1 st_set2 ld_list)
  in
  let non_terminal_set =
    let nt_set_lhs,nt_set_rhs =
      List.fold_left aux2 (String_set.empty,String_set.empty) grammar
    in
    let foldfun entryp_set (ep,_) = String_set.add ep entryp_set in
    let entryp_set =
      List.fold_left foldfun String_set.empty non_terminal_start_list
    in
    let nt_not_in_lhs = String_set.diff nt_set_rhs nt_set_lhs in
    let nt_not_in_rhs = String_set.diff nt_set_lhs nt_set_rhs in
    let nt_not_in_rhs = String_set.diff nt_not_in_rhs entryp_set in
    let f hs nt =
      print_endline ("File \""^input_file^"\":");
      print_endline ("Warning: non terminal `"^nt^"' is never in a "^hs)
    in
    String_set.iter (f "left-hand side.") nt_not_in_lhs;
    String_set.iter (f "right-hand side.") nt_not_in_rhs;
    String_set.union nt_set_lhs nt_set_rhs
  in
  let aux nt_string (code1,code2,n,nt_map) = (
    code1^"let "^nt_string^" = "^(string_of_int n)^"\n",
    (*code2^"  let def_datadyn1 = Dypgen_parser_runtime.String_map.add \""^nt_string^"\" "^
    (string_of_int n)^" def_datadyn1 in\n",*)
    code2^"\""^nt_string^"\";",
    (n+1),String_map.add nt_string n nt_map)
  in
  let code_non_terminal_decl, code_nt_name_list, non_terminal_number,
    non_terminal_map =
      String_set.fold aux non_terminal_set
      (code_non_terminal_decl,"[",1,String_map.empty)
  in
  let string_length = String.length code_nt_name_list in
  let code_nt_name_list = String.sub code_nt_name_list 0 (string_length-1) in
  let code_nt_name_list = code_nt_name_list^"]\n" in
  let code_datadyn = code_datadyn^code_nt_name_list in
  code_non_terminal_decl,code_datadyn,non_terminal_map,non_terminal_set



let code_merge_warning =
  if !Argument.merge_warning
  then "let merge_warning = true\n"
  else "let merge_warning = false\n"



let code_lexbuf_position = if !Argument.lexer = "ocamllex" then
  "let lexbuf_position lexbuf = (lexbuf.Lexing.lex_start_p,lexbuf.Lexing.lex_curr_p)\n"
  else "let lexbuf_position _ = (Lexing.dummy_pos,Lexing.dummy_pos)\n"



let code_nt_functions =
  let aux str (nts,_) = str^nts^";" in
  let nts_list = List.fold_left aux "" non_terminal_start_list in
  let string_length = String.length nts_list in
  let nts_list = String.sub nts_list 0 (string_length-1) in
  let ntna s code = code^"\""^s^"\";" in
  "let entry_points = ["^nts_list^"]\n"^
  "let non_terminal_startprime = 0\n"^
  "let compare_ntn nt1 nt2 = Pervasives.compare nt1 nt2\n"^
  "let non_ter_array = [|\"S'\";"^
  (String_set.fold ntna non_terminal_set "")^"\"\"|]\n"^
  "let str_non_terminal nt = try non_ter_array.(nt) with Invalid_argument _ -> (\"new_nt_\"^(string_of_int nt))\n"



let code_data_equal =
  "let global_data_equal = (==)\n"^
  "let local_data_equal = (==)\n"



let parser_parameters_module_signature =
  let aux_tok code (tok,_) = code^"val token_"^tok^" : int\n" in
  let token_id_type = List.fold_left aux_tok "" token_list in
  let aux_nt nt code = code^"val "^nt^" : int\n" in
  let non_ter_id_type = String_set.fold aux_nt non_terminal_set "" in
  "sig\n(*type token_name = int*)\n"^
  token_id_type^
  non_ter_id_type^
  "end"



let code_main_1 =
"module Dypgen_parser_runtime = Dyp.Parser.Make(Parser_parameters_module)
include (Parser_parameters_module:"^parser_parameters_module_signature^")
open Dypgen_parser_runtime
module Dypgen_parser_engine = Dypgen_parser_runtime.Parser_"^(!Argument.priority_enforcement)^"
include (Dypgen_parser_runtime.Dyp_tools:sig exception Syntax_error end)
type priority = Dypgen_parser_runtime.Dyp_tools.priority
include Parser_parameters_module.Export_type
open Dyp_tools\n\n" (* supprimer cette ligne peut-être *)



let code_priority_def,priority_set,code_priority_names =
  let code_priority_names = "let priority_names = [|\"default_priority\"" in
  let aux1 (str_set:String_set.t) rel = match rel with
    | Rel_list l -> List.fold_left (fun set p -> String_set.add p set) str_set l
    | Rel_single p1 -> String_set.add p1 str_set
  in
  let priority_set1 = List.fold_left aux1 String_set.empty relation in
  let aux1 st_set ld = match ld with
    | (Obj_terminal _),_ -> st_set
    | (Obj_non_terminal (_,(p,(line,col1,col2)),_,_)),_ -> if p="No_priority" then st_set
        else (if String_set.mem p priority_set1=false && p<>"default_priority" then (
          printf "File \"%s\", line %d, characters %d-%d:\n" input_file line col1 col2;
          printf "Warning: the priority `%s' is not declared\n" p);
        String_set.add p st_set)
  in
  let aux2 st_set (_,(p,(line,col1,col2)),ld_list,_,_) =
    let st_set = String_set.add p st_set in
    if String_set.mem p priority_set1=false && p<>"default_priority" then (
          printf "File \"%s\", line %d, characters %d-%d:\n" input_file line col1 col2;
          printf "Warning: the priority `%s' is not declared\n" p);
    List.fold_left aux1 st_set ld_list
  in
  let priority_set = List.fold_left aux2 priority_set1 grammar in
  let aux p (code,code_pn,n) =
      ((code^"let __dypgen_priority_data,"^p^
      " = Dyp_tools.insert_priority __dypgen_priority_data \""^p^"\"\n"),
      code_pn^";\""^p^"\"",
      (n+1))
  in
  let code_priority_def,code_priority_names,_ =
    String_set.fold aux priority_set
      ("let __dypgen_priority_data = Dyp_tools.empty_priority_data\n",
      code_priority_names,1)
  in
  code_priority_def,priority_set,code_priority_names^"|]\n"



let code_action_ref_decl =
"let global_data = ref 0
let local_data = ref 0\n"



let code_dypgen_toolbox_type =
"type ('obj,'data,'local_data) dypgen_toolbox = {
  mutable global_data : 'data;
  mutable local_data : 'local_data;
  mutable priority_data : Dyp_tools.priority_data;
  mutable add_rules : (Dyp_tools.rule * (
    ('obj,'data,'local_data) dypgen_toolbox -> 'obj list -> 'obj)) list;
  mutable remove_rules : Dyp_tools.rule list;
  mutable will_shift : bool;
  symbol_start : unit -> int;
  symbol_start_pos : unit -> Lexing.position;
  symbol_end : unit -> int;
  symbol_end_pos : unit -> Lexing.position;
  rhs_start : int -> int;
  rhs_start_pos : int -> Lexing.position;
  rhs_end : int -> int;
  rhs_end_pos : int -> Lexing.position;
  add_nt : string -> Dyp_tools.non_ter;
  find_nt : string -> Dyp_tools.non_ter
}\n"



let code_transform_action =
"let rec __dypgen_transform_action a =
  Special_types.Dypgen_action(fun av_list symbol_pos position_list data_arg datadyn
  local_data_arg prio_data ->
    let __dypgen_datadyn = ref datadyn in

    let dyp = {
      global_data = data_arg;
      local_data = local_data_arg;
      priority_data = prio_data;
      add_rules = [];
      remove_rules = [];
      will_shift = true;
      symbol_start = (fun () -> (fst symbol_pos).Lexing.pos_cnum);
      symbol_start_pos = (fun () -> fst symbol_pos);
      symbol_end = (fun () -> (snd symbol_pos).Lexing.pos_cnum);
      symbol_end_pos = (fun () -> snd symbol_pos);
      rhs_start = (fun i -> (fst (List.nth position_list (i-1))).Lexing.pos_cnum);
      rhs_start_pos = (fun i -> fst (List.nth position_list (i-1)));
      rhs_end = (fun i -> (snd (List.nth position_list (i-1))).Lexing.pos_cnum);
      rhs_end_pos = (fun i -> snd (List.nth position_list (i-1)));
      add_nt = (fun (s:string) -> Dypgen_runtime_tools.add_nt s __dypgen_datadyn);
      find_nt = (fun (s:string) -> Dypgen_runtime_tools.find_nt s !__dypgen_datadyn) }
    in

    let new_obj = a dyp av_list in

    let mapfun (r,ac) =
      (r,(__dypgen_transform_action ac))
    in
    let add_rules_transformed = List.map mapfun dyp.add_rules in
    (new_obj,dyp.will_shift,dyp.global_data,!__dypgen_datadyn,
    dyp.local_data,add_rules_transformed,dyp.remove_rules,
    dyp.priority_data)) in\n"




let code_grammar =
  
  let aux (lhs_nt,(prio,_),ld_list,par_act_l,ocaml_code) =
    let aux2 code ld = match ld with
      | (Obj_terminal (ter,(line,col1,col2))),_ ->
          let _ = (try String_map.find ter token_map
            with Not_found -> (
              fprintf stderr "File \"%s\", line %d, characters %d-%d:\n" input_file line col1 col2;
              fprintf stderr "Token `%s' not declared\n" ter; exit 2))
          in
          code^"Dyp_tools.Ter token_"^ter^";"
      | (Obj_non_terminal (ntn,(p,_),eq,_)),_ ->
          let code_p =
            if p = "No_priority" then "Dyp_tools.No_priority "
            else (match eq with
              | Pr_eq -> "Dyp_tools.Eq_priority "
              | Pr_lesseq -> "Dyp_tools.Lesseq_priority "
              | Pr_less -> "Dyp_tools.Less_priority "
              | Pr_greater -> "Dyp_tools.Greater_priority "
              | Pr_greatereq -> "Dyp_tools.Greatereq_priority ")^p
          in
          code^"Dyp_tools.Non_ter ("^ntn^","^code_p^");"
    in
    
    let code_literal_list = List.fold_left aux2 "" ld_list in
    
    let string_length = (String.length code_literal_list) in
    let code_literal_list =
      if string_length = 0 then code_literal_list
      else String.sub code_literal_list 0 (string_length-1)
    in
    let code_rule = "("^lhs_nt^",["^ code_literal_list^ "],"^prio^")" in
    
    let code_var_list =
      let f (code,n) lit = match lit with
        | (Obj_terminal (ter,_)),patternl ->
            let typ = String_map.find ter token_map in
            if typ = "No_type" then
              code^" _"^(string_of_int n)^";", n+1
            else
              let pat,lnum = List.hd patternl in
              code^"`Real_obj ("^obj_pref^"Obj_"^ter^" "^
              " ("^(sharp_line_number lnum)^
              pat^insert_line_number^" as _"^(string_of_int n)^"))"^";",
              n+1
        | (Obj_non_terminal (nt,_,_,res_nb)),patternl ->
            let rec aux n patl = match patl with
              | [pat,lnum] ->
                  " ("^(sharp_line_number lnum)^pat^insert_line_number^
                  " as _"^(string_of_int n)^")"
                  
              | (pat,lnum)::tl ->
                  " ("^(sharp_line_number lnum)^pat^insert_line_number^
                  " as _"^(string_of_int n)^")"^
                  ","^(aux (n+1) tl)
              | _ -> failwith "code_var_list"
            in
            let str = aux n patternl in
            code^"`Real_obj ("^obj_pref^"Obj_"^nt^" ("^str^"));",
            n+(List.length patternl)
      in
      let c,_ = List.fold_left f ("",1) ld_list in
      let s_length = (String.length c) in
      if s_length = 0 then c
      else String.sub c 0 (s_length-1)
    in

    let code_action =
      let (action,(header_act,trailer_act)),lnum = ocaml_code in
        "__dypgen_transform_action "^
        " (fun dyp __dypgen_av_list -> (match (__dypgen_transform_av_list "^
        "__dypgen_av_list) with ["^
        code_var_list^"] -> "^obj_pref^"Obj_"^lhs_nt^" ("^header_act^
        (sharp_line_number lnum)^"("^action^")"^
        insert_line_number^trailer_act^
        ") | _ -> raise Dyp_tools.Giveup))"
    in
    
    "("^code_rule^","^code_action^")"
  in
  let list_code_rapf = List.map aux grammar in

  (*let code_grammar =*)
    let rec aux sl = match sl with
      | [] -> ""
      | [s] -> s
      | s::t -> s^"\n;\n"^(aux t)
    in "let rapf_list =\n"^
    code_transform_action^
    "[\n"^
    (aux list_code_rapf)^"]\n"
  (*in
  code_grammar^
  "let current_grammar,nt_nb,map_po,user_g = make_grammar rapf_list __dypgen_priority_data\n"*)



let code_transform_av_list =
  let aux t typ code =
    if typ="No_type" then
      code^"  | "^obj_pref^"Obj_"^t^" -> `Dummy_obj\n"
    else code
  in
  let code_match_dummy = String_map.fold aux token_map "" in
"let __dypgen_transform_av_list l =
  let f o = match o with\n"^code_match_dummy^
  "  | x -> `Real_obj x
  in
  List.map f l\n"



let code_prio_data =
  (*let code_relation_data = "let __dypgen_priority_data = Dyp_tools.empty_priority_data\n" in*)
  let aux code rel = match rel with
    | Rel_list l ->
        let code_rel_list = List.fold_left (fun c s -> c^s^";") "" l in
        let string_length = String.length code_rel_list in
        let code_rel_list = "["^(String.sub code_rel_list 0 (string_length-1))^"]" in
        code^"let __dypgen_priority_data = Dyp_tools.add_list_relations __dypgen_priority_data "
        ^code_rel_list^"\n"
    | Rel_single p -> code(*^"let __dypgen_priority_data = Dyp_tools.insert_priority __dypgen_priority_data "^p^"\n"*)
  in
  (List.fold_left aux "" relation)^"\n"



(*
module Pparam =
struct
  let default_priority = 0
  type token = Token_void
  type obj = Obj_void
  type token_name = int
  let dummy_token_name = token_dummy_to_marshal
  let token_epsilon = token_epsilon_to_marshal
  let compare_token_name t1 t2 = Pervasives.compare t1 t2
  let get_name t = 0
  let str_token t = ""
  let str_token_name t = ""
  type Dyp_tools.non_ter = int
  let entry_points =
    let map_fun (nts,_) = String_map.find nts non_terminal_map in
    List.map map_fun non_terminal_start_list
  let non_terminal_startprime = 0
  let compare_ntn nt1 nt2 = Pervasives.compare nt1 nt2
  let str_non_terminal nt = string_of_int nt
  type data = Data_void
  let compare_data = (=)
  let default_data = Data_void
  type datadyn = Datadyn_void
  let default_datadyn = Datadyn_void
  let default_obj = Obj_void
  let get_value t = Obj_void
  type automaton_kind = LR1 | LALR
  let automaton_kind = if automaton_is_lr1 then LR1 else LALR
  let merge_warning = false
end

module Prio =
struct
  type priority = int
end

module Pparam_relation =
struct
  include Prio
  include Dyp.Priority_by_relation.Make(Prio)
  include Pparam
end

module Pparam_set =
struct
  include Prio
  include Dyp.Priority_by_set.Make(Prio)
  include Pparam
end

module P_relation = Dyp.Parser.Make(Pparam_relation)
module P_set = Dyp.Parser.Make(Pparam_set)

let cst c = (function i -> c)

module Calc_aut_relation =
struct
  open Pparam_relation
  open P_relation
  let rhs_lit obj_lit = match obj_lit with
    | Obj_terminal ter -> Dyp_tools.Ter (String_map.find ter token_name_map)
    | Obj_non_terminal (ntn,p,eq) ->
        let prio_nt =
          if p = "No_priority" then No_priority
          else
            let prio = String_map.find p priority_map in
            if eq then Lesseq_priority prio else Less_priority prio
        in
        Dyp_tools.Non_ter (String_map.find ntn non_terminal_map,prio_nt)
  let aux (nt,_,l,ac_desc) =
    let ac = match ac_desc with
      | Dynamic_action _ -> Special_types.Dypgen_action(fun _ _ _ _ _ _ -> Obj_void,true,default_data,
          default_datadyn, [], [], Dyp_tools.empty_priority_data)
      | _ -> Classic(fun _ _ _ _ _ -> Obj_void,true,default_data)
    in
    (((String_map.find nt non_terminal_map),List.map rhs_lit l),ac,cst 0)
  let rapf_list = if set = [] then List.map aux grammar else []

  let grammar_for_sa = if set = [] then add_grammar empty_grammar rapf_list else empty_grammar
  let marshaled_automaton = if set = [] then
    Marshal.to_string (create_saved_automaton grammar_for_sa) []
    else ""
end

module Calc_aut_set =
struct
  open Pparam_set
  open P_set
  let aux priority_set_map (x,pl) =
    if pl=["priority declaration"] then priority_set_map else
    let f s = String_map.find s priority_map in
    let ntn_p = change_ntp_list empty_ntp (List.map f pl) in
    String_map.add x ntn_p priority_set_map
  let priority_set_map = if set=[] then String_map.empty else
    List.fold_left aux String_map.empty set

  let rhs_lit obj_lit = match obj_lit with
    | Obj_terminal ter -> Dyp_tools.Ter (String_map.find ter token_name_map)
    | Obj_non_terminal (ntn,p,eq) ->
        let prio_nt =
          if p = "No_priority" then No_priority
          else
            let prio = String_map.find p priority_set_map in
            if eq then failwith("equal with priority_by_set")
            else prio
        in
        Dyp_tools.Non_ter (String_map.find ntn non_terminal_map,prio_nt)
  let aux (nt,_,l,ac_desc) =
    let ac = match ac_desc with
      | Dynamic_action _ -> Special_types.Dypgen_action(fun _ _ _ _ _ _ -> Obj_void,true,default_data,
          default_datadyn, [], [], Dyp_tools.empty_priority_data)
      | _ -> Classic(fun _ _ _ _ _ -> Obj_void,true,default_data)
    in
    (((String_map.find nt non_terminal_map),List.map rhs_lit l),ac,cst 0)
  let rapf_list = if set=[] then [] else List.map aux grammar

  let grammar_for_sa = if set = [] then empty_grammar else add_grammar empty_grammar rapf_list
  let marshaled_automaton = if set = [] then "" else
    Marshal.to_string (create_saved_automaton grammar_for_sa) []
end




let code_marshaled_automaton =
  let marshaled_automaton =
    if set = [] then Calc_aut_relation.marshaled_automaton
    else Calc_aut_set.marshaled_automaton
  in
  let marshaled_automaton = String.escaped marshaled_automaton in
  "let marshaled_automaton = \""^marshaled_automaton^"\"\n"
*)


let code_main_2 =
  let aux str (nts,_) =
  str^"let "^nts^" f lexbuf =
  let automaton = Dypgen_parser_engine.update_parsing_device_data automaton !global_data
    !local_data in
  let pf = Dypgen_parser_engine.glrParse automaton __dypgen_get_value "^nts^" __dypgen_data_equal f lexbuf
    lexbuf_position in
  let aux1 (o,p) = match o with
    | "^obj_pref^"Obj_"^nts^" r -> (r,p) | _ -> failwith \"Wrong type for entry result\" in
  List.map aux1 pf\n"
  in
(*"let saved_automaton = Marshal.from_string marshaled_automaton 0
let automaton = complete_automaton saved_automaton current_grammar default_data default_datadyn __dypgen_priority_data merge_map merge\n"^*)
"let automaton = Dypgen_parser_engine.create_parsing_device rapf_list __dypgen_priority_data Special_types."^
!Argument.aut_kind^" !global_data !local_data merge_map dyp_merge __dypgen_datadyn\n"^
  "let __dypgen_data_equal = {\n"^
  "  Dypgen_runtime_tools.global_data_equal = global_data_equal;\n"^
  "  Dypgen_runtime_tools.local_data_equal = local_data_equal }\n"^
  (List.fold_left aux "" non_terminal_start_list)



let first_header = "
module Parser_parameters_module =
struct\n\n"



let code_type_obj =
  if !Argument.pv_obj then "" else
  let code_obj =
    let aux nt code =
      if List.exists (fun (nts,_) -> nts=nt) non_terminal_start_list
      then code else code^" '"^nt^","
    in
    let type_param =(String_set.fold aux non_terminal_set "") in
    let string_length = String.length type_param in
    let type_param = String.sub type_param 0 (string_length-1) in
    "("^type_param^") obj"
  in
  let aux1 tok typ code = if typ = "No_type" then code^"  | Obj_"^tok^"\n"
    else code^"  | Obj_"^tok^" of ("^typ^")\n"
  in
  let aux2 nt code =
    try
      let (_,start_type) =
        List.find (fun (nts,_) -> nts=nt) non_terminal_start_list
      in code^"  | Obj_"^nt^" of "^start_type^"\n"
    with Not_found -> code^"  | Obj_"^nt^" of '"^nt^"\n"
  in
  "type "^code_obj^" =\n"^
  (String_map.fold aux1 token_map "")^
  (String_set.fold aux2 non_terminal_set "")

let code_merge_functions =
  let aux nt_string code = code^"let dyp_merge_"^nt_string^" _ _ = []\n" in
  (String_set.fold aux non_terminal_set "")^
  (*"let keep_all ol o = o::ol\n"^
  "let Dyp_tools.keep_oldest ol _ =
  let rec aux l = match l with [] -> [] | [c] -> [c] | _::t -> aux t in
  aux ol\n"^
  "let keep_newest _ o = [o]\n"^*)
  "let dyp_merge = Dyp_tools.keep_oldest\n"

let code_merge_map =
  let aux4 gmf gmm nt = String_map.add nt gmf gmm in
  let aux3 gmm (gmf,nt_l) = List.fold_left (aux4 gmf) gmm nt_l in
  let gen_merge_map = List.fold_left aux3 String_map.empty generic_merge in
  let aux1 nt_string code = code^"let dyp_merge_"^nt_string^" ol o =\n"^
    try let gen_merge = String_map.find nt_string gen_merge_map in
      "  "^gen_merge^" ol o\n"
    with Not_found -> (
      "  let ol2 = dyp_merge_"^nt_string^" ol o in\n"^
      "  if ol2 = [] then dyp_merge ol o else ol2\n")
  in
  let aux2 nt_string nt_int mfl = ("(fun ol o -> (
  let f1 o = match o with "^obj_pref^"Obj_"^nt_string^" ob -> ob
    | _ -> failwith \"type error, bad obj in dyp_merge_"^nt_string^"\"
  in
  let o = f1 o in
  let ol = List.map f1 ol in
  let ol = dyp_merge_"^nt_string^" ol o in
  let f2 o = "^obj_pref^"Obj_"^nt_string^" o in
  List.map f2 ol)),"^(string_of_int nt_int))::mfl
  in
  let merge_function_list = String_map.fold aux2 non_terminal_map [] in
  let code_merge_function_list = string_list merge_function_list in
  (String_set.fold aux1 non_terminal_set "")^
  "let merge_map = Dypgen_runtime_tools.init_merge_map "^code_merge_function_list^"\n"
  (*"let merge_map = Nt_map.empty\n"^
  (String_set.fold aux2 non_terminal_set "")*)

let code_get_value =
  let aux code (tok,typ) =
    let s = if typ = "No_type" then " -> "^obj_pref^"Obj_"^tok^"\n"
      else " x -> "^obj_pref^"Obj_"^tok^" x\n"
    in
    code^"  | "^token_pref^tok^s
  in
  "let __dypgen_get_value t = match t with\n"^
  (List.fold_left aux "" token_list)^"\n"




let parser_code = first_header^
  code_export_module^

  code_token_name_decl^
  code_token_functions^

  code_non_terminal_decl^
  code_nt_functions^

  (*code_parser_param_info^*)
  (*code_data^*)
  (*code_datadyn_user^*)
  code_priority_names^
  (*code_automaton_kind^*)
  code_merge_warning^
  "end\n\n"^

  (*"open Lexing\n"^*)
  code_main_1^
  code_type_obj^
  code_datadyn^
  code_action_ref_decl^
  (*code_number_of_tokens^*)
  code_priority_def^
  code_get_value^
  code_lexbuf_position^
  (*code_type_dynamic_arg^*)
  code_merge_functions^
  code_dypgen_toolbox_type^
  code_data_equal^
  header_main^
  code_prio_data^
  (*code_transform_action^*)
  code_transform_av_list^
  code_grammar^
  code_merge_map^
  trailer_main




let parser_code_mli =
  let entry_code =
    if !Argument.lexer = "ocamllex" then " : (Lexing.lexbuf -> token) -> Lexing.lexbuf -> "
    else if !Argument.lexer = "ulex" then " : (Ulexing.lexbuf -> token) -> Ulexing.lexbuf -> "
    else " : ('a -> token) -> 'a -> "
  in
  let aux str (nts,start_type) =
    str^"val "^nts^entry_code^"(("^start_type^") * priority) list\n"
  in
  let aux2 p code = code^"val "^p^" : priority\n" in
  "exception Syntax_error\n"^code_token_decl^
  "type priority\n"^
  (String_set.fold aux2 priority_set "")^
  (List.fold_left aux "" non_terminal_start_list)^
  mli_code



let lexbuf = Lexing.from_string parser_code
let parser_code = Insert_linenum.insert_linenum lexbuf
(*let parser_code = parser_code^code_marshaled_automaton^code_main_2*)
let parser_code = parser_code^code_main_2

let lexbuf = Lexing.from_string parser_code_mli
let parser_code_mli = Insert_linenum.insert_linenum lexbuf

let dest_file = open_out output_file
let dest_file_mli = open_out output_file_mli

let () = output_string dest_file parser_code
let () = output_string dest_file_mli parser_code_mli
let () = close_out dest_file
let () = close_out dest_file_mli

@h=tangler('dypgen/generators/dypgen/dypgen_lexer.mll')
@select(h)
{
open Dypgen_parser
open Lexing

let ocaml_code_buffer = ref ""
(*let paren_count = ref 0*)
let in_string = ref false
let comment_count = ref 0
(*let dypgen_comment = ref 0*)
let look_for_type = ref false

let start_ocaml_type = ref dummy_pos
let start_ocaml_code = ref dummy_pos
let start_curlyb = ref []
let start_bracket = ref []
let start_pattern = ref dummy_pos
let start_dypgen_comment = ref []
let start_ocaml_comment = ref []
let start_string = ref dummy_pos

let update_loc lexbuf file line absolute chars =
  let pos = lexbuf.lex_curr_p in
  let new_file = match file with
                 | None -> pos.pos_fname
                 | Some s -> s
  in
  lexbuf.lex_curr_p <- { pos with
    pos_fname = new_file;
    pos_lnum = if absolute then line else pos.pos_lnum + line;
    pos_bol = pos.pos_cnum - chars;
  }
}

let newline = ('\010' | '\013' | "\013\010")
let blank = [' ' '\009' '\012']
let lowercase = ['a'-'z' '\223'-'\246' '\248'-'\255' '_']
let uppercase = ['A'-'Z' '\192'-'\214' '\216'-'\222']
let identchar = 
  ['A'-'Z' 'a'-'z' '_' '\192'-'\214' '\216'-'\246' '\248'-'\255' '\'' '0'-'9']

rule token = parse
  | newline
      { update_loc lexbuf None 1 false 0;
        token lexbuf
      }
  | blank +
      { token lexbuf }
  | "%token" { look_for_type:=true; KWD_TOKEN }
  | "%start" { look_for_type:=true; KWD_START }
  | "%relation" { look_for_type:=false; KWD_RELATION }
  | "%mli" { KWD_MLI }
  | "%merge" blank { KWD_MERGE }
  | lowercase identchar *
      { let pos = lexeme_start_p lexbuf in
        let line = pos.pos_lnum in
        let col1 = pos.pos_cnum - pos.pos_bol in
        let col2 = lexbuf.lex_curr_p.pos_cnum - lexbuf.lex_curr_p.pos_bol in
        LIDENT((Lexing.lexeme lexbuf),(line,col1,col2)) }
  | uppercase identchar *
      { let pos = lexeme_start_p lexbuf in
        let line = pos.pos_lnum in
        let col1 = pos.pos_cnum - pos.pos_bol in
        let col2 = lexbuf.lex_curr_p.pos_cnum - lexbuf.lex_curr_p.pos_bol in
        UIDENT((Lexing.lexeme lexbuf),(line,col1,col2)) }
  | "("  { LPAREN }
  | ")"  { RPAREN }
  | "["
      { ocaml_code_buffer := "";
        let pos = lexeme_start_p lexbuf in
        start_pattern := pos;
        (*paren_count:=1;*)
        ocaml_code lexbuf;
        PATTERN (!ocaml_code_buffer,pos.pos_lnum)
      }
  | ","  { COMMA }
  | ":"  { COLON }
  | ">"  { GREATER }
  | "%%" { look_for_type:=false; PERCENTPERCENT }
  | "<"
      { if !look_for_type=false then LESS
        else
          (ocaml_code_buffer := "";
          start_ocaml_type := lexeme_start_p lexbuf;
          ocaml_type lexbuf;
          OCAML_TYPE (!ocaml_code_buffer))
      }
  | "{"
      { ocaml_code_buffer := "";
        let pos = lexeme_start_p lexbuf in
        start_ocaml_code := pos;
        ocaml_code lexbuf;
        OCAML_CODE (!ocaml_code_buffer,pos.pos_lnum)
      }
  | "/*"
       { (*dypgen_comment := !dypgen_comment+1;*)
         start_dypgen_comment := (lexeme_start_p lexbuf)::(!start_dypgen_comment);
         comment lexbuf; token lexbuf }
  | "|"  { BAR }
  | "="  { EQUAL }
  | eof { EOF }

and comment = parse
  | "/*" { (*dypgen_comment := !dypgen_comment+1;*)
           start_dypgen_comment := (lexeme_start_p lexbuf)::(!start_dypgen_comment);
           comment lexbuf }
  | "*/"
      { (*dypgen_comment := !dypgen_comment-1;*)
         start_dypgen_comment := List.tl (!start_dypgen_comment);
         if !start_dypgen_comment=[] then () else comment lexbuf }
  | newline
      { update_loc lexbuf None 1 false 0; comment lexbuf }
  | _ { comment lexbuf }

and ocaml_code = parse
  | "}" 
      { 
        if !in_string = false && !comment_count = 0 then
          begin
            match !start_curlyb with
              | [] ->
                if !start_ocaml_code=dummy_pos then (
                  ocaml_code_buffer := (!ocaml_code_buffer) ^ "}";
                  ocaml_code lexbuf)
                else start_ocaml_code:=dummy_pos
              | _::tl ->
                  start_curlyb:=tl;
                  ocaml_code_buffer := (!ocaml_code_buffer) ^ "}";
                  ocaml_code lexbuf

            (*if (!paren_count) = 0 then start_ocaml_code := dummy_pos
            else
              let _ = ocaml_code_buffer := ((!ocaml_code_buffer) ^ 
                (String.make 1 (Lexing.lexeme_char lexbuf 0))) in
              let _ = paren_count := ((!paren_count)-1) in
              ocaml_code lexbuf*)
          end
        else
          begin
            ocaml_code_buffer := (!ocaml_code_buffer) ^ "}";
            ocaml_code lexbuf
          end
      }
  | "]" { if !in_string=false && !comment_count=0 then (
          match !start_bracket with
            | _::tl -> start_bracket := tl;
                ocaml_code_buffer := ((!ocaml_code_buffer)^"]");
                ocaml_code lexbuf
            | [] ->
                if !start_pattern=dummy_pos then (
                  ocaml_code_buffer := ((!ocaml_code_buffer)^"]");
                  ocaml_code lexbuf)
                else
                  start_pattern:=dummy_pos)
          else (
            ocaml_code_buffer := ((!ocaml_code_buffer)^"]");
            ocaml_code lexbuf) }
  | "[" { if !in_string=false && !comment_count=0 then
            start_bracket := (lexeme_start_p lexbuf)::(!start_bracket);
          ocaml_code_buffer := ((!ocaml_code_buffer)^"[");
          ocaml_code lexbuf }
  | "$"
      { ocaml_code_buffer := ((!ocaml_code_buffer) ^ 
          "_");
        ocaml_code lexbuf
      }
  | "\\\""
      { ocaml_code_buffer := ((!ocaml_code_buffer) ^ "\\\"");
        ocaml_code lexbuf
      }
  | "\""
      { 
        if !in_string then (in_string := false; start_string := dummy_pos)
        else (in_string := true; start_string := lexeme_start_p lexbuf);
        ocaml_code_buffer := (!ocaml_code_buffer) ^ "\"";
        ocaml_code lexbuf
      }
  | "{"
      { ocaml_code_buffer := (!ocaml_code_buffer) ^ "{";
        if !in_string = false && !comment_count = 0 then
          start_curlyb := (lexeme_start_p lexbuf)::!start_curlyb;
          (*paren_count := (!paren_count)+1;*)
        ocaml_code lexbuf
      }
  | "(*"
      { 
        if !in_string then () else (comment_count := !comment_count + 1;
          start_ocaml_comment := (lexeme_start_p lexbuf)::(!start_ocaml_comment));
        ocaml_code_buffer := ((!ocaml_code_buffer) ^ "(*");
        ocaml_code lexbuf
      }
  | "*)"
      { 
        if !in_string then () else (comment_count := !comment_count - 1;
          start_ocaml_comment := List.tl (!start_ocaml_comment));
        ocaml_code_buffer := ((!ocaml_code_buffer) ^ "*)");
        ocaml_code lexbuf
      }
  | newline
      { update_loc lexbuf None 1 false 0;
        ocaml_code_buffer := ((!ocaml_code_buffer)^
          (String.make 1 (Lexing.lexeme_char lexbuf 0)));
        ocaml_code lexbuf
      }
  | _
      { ocaml_code_buffer := ((!ocaml_code_buffer)^
          (String.make 1 (Lexing.lexeme_char lexbuf 0)));
        ocaml_code lexbuf
      }

and ocaml_type = parse
  | "->"
      { ocaml_code_buffer := (!ocaml_code_buffer) ^ "->";
        ocaml_type lexbuf
      }
  | ">" { start_ocaml_type := dummy_pos; () }
  | newline
      { update_loc lexbuf None 1 false 0;
        ocaml_code_buffer := ((!ocaml_code_buffer)^
          (String.make 1 (Lexing.lexeme_char lexbuf 0)));
        ocaml_type lexbuf
      }
  | _
      { ocaml_code_buffer := ((!ocaml_code_buffer) ^
          (String.make 1 (Lexing.lexeme_char lexbuf 0)));
        ocaml_type lexbuf
      }

@h=tangler('dypgen/generators/dypgen/insert_linenum.mll')
@select(h)
{
open Lexing

let buffer = ref ""

let update_loc lexbuf file line absolute chars =
  let pos = lexbuf.lex_curr_p in
  let new_file = match file with
                 | None -> pos.pos_fname
                 | Some s -> s
  in
  lexbuf.lex_curr_p <- { pos with
    pos_fname = new_file;
    pos_lnum = if absolute then line else pos.pos_lnum + line;
    pos_bol = pos.pos_cnum - chars;
  }
}

let newline = ('\010' | '\013' | "\013\010")

rule insert_linenum = parse
  | newline
      { update_loc lexbuf None 1 false 0;
        buffer := ((!buffer)^(Lexing.lexeme lexbuf));
        insert_linenum lexbuf
      }
  | "# insert-line-number"
      {
        let pos = Lexing.lexeme_start_p lexbuf in
        buffer := ((!buffer)^"# "^(string_of_int (pos.pos_lnum+1)));
        insert_linenum lexbuf
      }

  | eof
      { let result = !buffer in
        buffer := "";
        result }
  | [^'#''\010''\013']+
      {
        buffer := ((!buffer)^(Lexing.lexeme lexbuf));
        insert_linenum lexbuf
      }
  | _
      {
        buffer := ((!buffer)^(Lexing.lexeme lexbuf));
        insert_linenum lexbuf
      }

