@set_title('Theory of operation')
@head(1,'Introduction')
This document describes the theory of operation
of the Felix compiler, the data structures
produced by the code generator, and the principle
of control inversion which leads to the particular
design of the execution model. Felix is a multi-staged
compiler, this document describes each stage
in turn. 

@head(1,'Establishment')
The first stage of operation is initial housekeeping
including gathering command line options and will
not be described further.

@head(1,'STAGE 1. Lexemical Analysis')
The first proper stage of operation has two functions:
to partition the proper program text of a source file
into lexemes, and to recursively invoke the lexemical
analysis of include files. The result of the
total process is a single string of pre-tokens.
@p()
A pretoken consists of a symbol for the class of
lexeme, a reference to where the lexeme originated,
and any attributes associated with the lexeme.
Attributes may include a string value for identifiers
and string literals, a value for integers, for example.
@p()
Lexing is accomplished using code generated by 
the tool ocamllex, the rules all accept a lexer
state argument and return a list of pretokens.
@p()
Some peculiarities of the lexing process are listed
below.

@head(2,'UCN normalisation')
Felix mandates an ISO10646/Unicode character set,
however the current version only supports 8 bit clean
byte strings sourced from binary files.
@p()
To facilitate i18n considerations, two encoding
mechanisms are supported. First, the input stream
is specified as UTF-8 encoded 31 bit ISO10646,
which may be used universally,
and secondly, sequences of bytes of the form
@begin_displayed_code()
  \uXXXX
  \UXXXXXXXX
@end_displayed_code()
called Universal Character Names may be used
in certain contexts to denote character ISO10646
code points.
@p()
UCNs may be used in identifiers and in strings.
@p()
In order to ensure a unique representation,
ISO-10646 code points in identifiers 
less than 127 are replaced by bytes 
with the corresponding literal value,
whilst those greater than
value 127 are replaced by UCNs generated by
the lexer. The form \uXXXX is used for code
points in the range 128-65535, and \UXXXXXXXX
for anything larger. Lower case hex digits are used.
@p()
For strings, ISO10646 code points less than 128
are replaced by bytes with the corresponding value,
whilst those points greater
than 127 are replaced by UTF-8 encoded byte
strings. Note that this processing does not
apply to bytes specified by \x escapes: it only
applies to UTF-8 byte strings and UCN escapes.
This supports use of strings as both human script
and binary data.

@head(2,'Include Files')
The #include directive triggers a search
for an include file. If the form
@begin_displayed_code()
  #include "filename"
@end_displayed_code()
is used, the file is accessed from the directory
containing the current file, that is, the file
name is relative.
@p()
If the form
@begin_displayed_code()
  #include <filename>
@end_displayed_code()
then the file is searched for on a path determined
by the first stage.

@head(2,'Sub lexicologies')
The lexer is factored some some special sublanguages
are handled separately. Notably, strings are lexed
by special purpose sublexers.

@head(2,'Keywords')
Keywords are special identifiers whose status is
detected by hashtable lookup.

@head(2,'Literals')
Both string and integer literals are have special
support for encoding and decoding. On the other
hand floating literals are processed as strings,
to ensure that no information is lost in the
transformation from Felix source to C/C++ output.
[Thus, float constant folding is not possible]

@head(2,'User defined Literals')
There is no provision at present for user
defined literals, however there is some
appeal to allowing compiled shared libraries
to be dynamically loaded to process user defined
literals. [Under investigation]

@head(2,'User defined operators')
There is currently no support for user defined
operators. Worth investigating.

@head(1,'STAGE 2. Tokenisation')
The pretoken stream is processed to obtain tokens.
White space is removed, and other minor rewriting
occurs.

@head(1,'STAGE 3. Parsing')
The parser is invoked to build an High Level Abstract Syntax 
Tree (HLAST) from the token stream. The parser is
generated by ocamlyacc, a yacc like system.
The terms produced by the parser represented
by AST and TYP components.
@p()
Currently, some lightweight desugaring occurs in the
parsing stage. Some highlights are described below.
The parser based desugaring never synthesises fresh
names.

@head(2,'Operators')
Most functional operators are replaced by function
applications. The set of operators, and the names
of the functions, is currently hard coded into
the parser and lexer, as is precedence, associativity,
etc.

@head(2,'Error productions')
Productions for some common errors are included
in the grammar.

@head(1,'STAGE 4. Desugaring')
The HLAST is reduced by term rewriting rules
to a Low Level Abstract Syntax Tree (LLAST).
The LLAST consists of a linear sequence
of entries, each of which is either
a declaration Dcl, executable Exe,
or external interface Iface form
which together contitute the asm type.
A DCL may contain a list of asms, reflecting
the scope heirarchy after rewriting.
@p()
The stringent splitting of all AST terms
into declarative and executable code simplifies
subsequent processing.

@head(2,'Lambda lifting')
By far the most important rewriting rule is
known as lambda lifting. Lambda lifting
takes an anonymous inline expression for a higher
order construction such as a procedure or function,
synthesises a fresh name, and inserts a declaration
of that name in an appropriate place. The original
expression is replaced by an access to that 
definition.
@p()
Lifting is applied to blocks, lazy expressions,
and lambda expresssions.

@head(2,'Exceptions')
Exceptions undergo specialised term rewriting,
replacing exception handlers with procedures,
and raise statements with procedure calls.
A goto is inserted into each exception handler
to jump to the resumption point (so that the
procedure call for a raise never returns).

@head(2,'Control Structures')
Other control structures are transformed
into conditional local jumps.

@head(2,'Matching')
Match statements are transformed as follows.
@p()
A fresh name is synthesised and declared
as a value initialised by the match expression.
@()
For each case, a function returning a bool
is created which determines if there is a match.
The interesting case is variant matching,
which works by simply checking that the discriminant
tag of the match variable has a particular value.
@p()
For each user defined handler a procedure 
is generated which does two jobs: first,
it initialises local variables corresponding
to the pattern variables, with the corresponding
component of the match expression, and then it
executes the user code.
@p()
The extraction process involves invoking unsafe
destructors on the match variable. These extractors
are determined by inverting the pattern. For example,
a variable nested several levels deep in a tuple
matching applies several projections to the match
variable to extract the desired component,
the destructor for a union variant casts the
component data to the expected type.

@head(1,'General Expression decomposition')
At present, Felix does not decompose expressions
into three address code, it leaves this job
to the C++ compiler. It may be necessary to
perform such decomposition in the future,
since C++ lacks representations for many
functional constructions. In particular,
replacing high level function calls with
procedures initialising a temporary may
be necessary to permit control inversion
by returning a continuation. 
@p()
At present, this is not possible: all functional
code is evaluated on the machine stack.

@head(1,'STAGE 5. Inversion')
This stage takes the heirarchical asm structure
produced by the desugaring stage
and inverts it. This inversion only
involves the Dcl forms from the desugaring stage,
the Exe forms remain untouched.
It produces a single global
symbol table by assigning a unique integer
to every symbol.  The table is then a map
from integers to symbol definitions, represented
by a hashtable.
@p()
The symbol entry contains four pieces of information:
the identifier for the symbol, the original source
location in the users code for the definition,
the parent of the symbol,
and kind dependent data called a SYMDEF.
@p()
Many names represent scopes, including functions,
procedures, modules, and interfaces. For these
kinds of symbol, there is always a a name map
available. A name map is a mapping from names
to sets of integers, which identifies all
entities of the given name declared in
the scope associated with the symbol.
@p()
The name map is represented by a hashtable
whose entities are either a NonFunctionEntry
with a single integer, or a FunctionEntry with
a list of integers.
@p()
The purpose of this representation is to allow
overloading function and procedures symbols,
whilst still providing early error detection
for duplicate entries of the same name for
other symbols.

@head(1,'STAGE 6. Type Binding')
The next stage of processing is responsible
for type binding. This involves replacing
all names used in type expressions with
the index corresponding to the name.
@p()
Unqualified names are searched in the stack
of enclosing scopes. Note that forward references
work because the search uses the name maps
already constructed during the previous inversion step.
@p()
This stage accepts an unbound symbol table as
input and produces a partially bound symbol
table as output: the data is the same in both
tables except that type names have been replaces
by indexes.
@p()
This stage detects an error if a name used
in a type expression does not refer to a type.
@p()
The type binding is necessary to permit
the next stage to perform overload resolution,
which requires types to be bound so they
can be identified (that is, compared for
equality).
@p()
In this stage, SYMDEFs are replaced by BDCLs.

@head(1,'STAGE 7. Binding')
This stage is responsible for binding
all names, and for fixing the types of
all typed symbols. It takes the partially
bound symbol table from the previous stage
and produces a fully bound symbol table.
@p()
This stage has two aspects: expression binding
and statement binding. Statement binding
drives expression binding. All definitions
in the partially bound symbol table are
bound, not necessarily in linear order.
@p()
Binding involves lookup which may include
overload resolution. The types of functions
are known from the previous stage.
@p()
However, the types of variables are required
to synthesis the type of an expression bottom
up to permit matching the type of an argument
to the type of a function.
@p()
Because Felix supports inference of the type
of declared values and initialised variables,
and the initialisers themselves may involve
function calls requiring overload resolution,
the type of an expression is calculated using
a recursive algorithm with an exclusion list
to detect cyclic dependencies.
@p()
Note that the type of an expression can be
computed multiple times by our algorithm.
The input uses the partially bound symbol
tables for all calculations and generates
fully bound entries, which are not consulted
to avoid recomputation, nor are intermediate
results entered into the fully bound
symbol table. The algorithm could be
improved by such optimisations.
@p()
The terms in the fully bound table
include no names. In particular,
EXE forms are replaced by BEXE forms,
and AST terms using in expresions by
BEXPR forms, and BDCLs from the partially
bound table replaced by BBDCL forms.

@head(1,'STAGE 8. Type regsitration')
This stage scans the fully bound
symbol table, and builds a registry of
all types used in the program, associating
a unique integer with each type.
@p()
The list is generated by recursive analysis
of the types in all declarations: either
the type declared by the declaration,
or the type of the entity being declared.
Note that 'declared' here includes synthesised
entities.
@p()
Note that executable code is not scanned,
even though it may contain expressions
which evalute to anonymous tuple types,
since such types cannot be used except
to initialise a variable form, be it
a value, variable, or function or procedure
parameter, and the types of these are all
subject to exhaustive decomposition.
@p()
The unique integer assigned to each type
has two distinct purposes. The first purpose
is to guarrantee that C++ classes generated
to represent types have unique names.
@p()
The second purpose is more subtle. 
The recursion is organised in such a way
that if a type depends on another directly,
it will always be assigned a higher integer index.
This means the registry can be linearised into
an total order compatible with the partial
order of type dependencies.
@p()
Type registration detects illegal type recursion.
However, not all type recursion is illegal.
@p()
Recursion across unions is permitted, indeed,
it is necessary for the specification of
inductive types like lists. This recursion works,
because a union component is represented
by a universal class consisting of an
integer tag and a void pointer to the 
variants argument tuple (that is, union
variant constructors arguments are boxed).
@p()
Obviously, recursion is also permitted by use
of pointers.
@p()
Recursion is not permitted for structs (records)
since structure components are not boxed:
the client must use pointers explicitly.

@head(1,'Optimisation')
There is no separate back end optimisation at present.

@head(1,'STAGE 9. Code generation')
This stage performs the final code generation,
including some minor optimisations.
@p()
The code generator generates a C++ class for each
user defined type, each tuple type, each function
or procedure type, and a typedef for each union type
and primitive type. A template is used for pointers.
@p()
The class definition is split into two stages:
first, just the names are declared. This is usually
a plain class declaration or typedef for either
a primitive type or union type.
@p()
Then, the classes are defined. Bodies of members
are not generated yet.
@p()
Next, classes are defined for each actual
function or procedure.
@p()
Next, the bodies of all members are generated.
@p()
Finally, external interfaces are defined;
these are functions with extern "C" linkage
which can be used by the driver to execute
the program.
@p()
All generated code is split between two files:
a header file and an implementation file.
All declarations and class definitions go in
the header file. The body consists entirely
of member function defintions.

@head(1,'Representation')
This section describes the representation
of various Felix entities.

@head(2,'Primitive types')
The representation of all primitive types is
defined by the user with binding constructions.

@head(2,'Product types')
Felix structs and tuples are represented by C++ structs.

@head(2,'Union types')
Unions are represented by a single univeral
class consisting of an integer case tag
and a void pointer to the tuple used to
construct the variant, the pointer is NULL
if the variant has no arguments.
@p()
If all the components of a union are constants,
the union is called a plain enumeration,
and the representation changes to an integer.
[NOT IMPLEMENTED YET]

@head(2,'Primitive functions')
Primitive functions are called by inline expansion.

@head(2,'Primitive procedures')
Primitive procedures are called by inline expansion.

@head(2,'Felix functions')
A Felix function is represented by a C++ class
with an apply method. The class is derived
from the function's type class, which has a pure
virtual apply method, so that a pointer to
an object may be passed to a function expecting
a function of a particular type.
@()
The constructor of a function class requires
that the functions display be passed. The display
is a list of pointers to the objects representing
the closures of the functions enclosing the
function's Felix defintion.
@p()
The object resulting from the construction
of an object of the class representing a Felix
function represents the closure of the function
with its environment of definition at the time
of closure formation.
@p()
The protocol for argument passing is: if a function
has a unit argument, no argument is passed,
if it has one argument, that argument is passed,
otherwise a tuple is passed.
@p()
All local variables and parameters are represented
by nonstatic members. None of these members
are explicitly initialised. All initialisations
are converted to assignments.
@p()
A function does not store its callers return address.
Felix function objects are always created on the heap,
and called directly (the pointer is resulting from
calling operator new is never stored anywhere).
@p()
There is room to optimise this: if a function
does not return or store a pointer to itself,
including any of its members, nor to any
function defined within it, then the object
can use automatic storage, since no references
to it will persist when the call terminates.
This can be established for some functions.

@head(1,'Felix procedures and the execution model')
Now we get to the interesting bit!
Felix procedures, like functions, are
derived from a base representing their type.
Felix procedure types are themselves derived
from an abstract class continuation_t representing
procedural continuations. The continuation
class has an integer variable representing
the program counter, and a state flag described
below.
@p()
There are two methods required to execute a procedure.
The first method, the call() method, accepts the
arguments of the procedure, using the same
protocol as a function's apply() method.
It also accepts a pointer to the caller,
NULL if the caller is the driver program.
It returns a pointer to the object when complete.
@p()
The second method is resume(), which
consists of a single switch on the program 
counter variable. The resume method
executes the procedure for a while, then
returns a pointer to the object, with the
program counter set so a subsequent call
to resume() will continue execution where
it left off.
@p()
When a procedure calls another procedure,
it sets the program counter to the 
value of the next case of the switch,
and then constructs a new object for
the procedure to be called. It then calls
the call() method, passing its own this
pointer as the return address, as well
as any argument.
@p()
It then returns the pointer returned by
the call method just invoked, which points
at the newly created object.
@p()
Because the stack is empty at this time,
the pointer is returned to the driver,
which immediately calls resume.
When the resume method detects the procedure
has finished, it returns the pointer
its caller passed to the call method,
and the driver then resumes executing
the caller. The driver knows the original
call is finished when it gets back the
NULL return address it originally passed.
@p()
This technique is known as continuation passing.
It operates so that the machine stack is always
empty when a procedure is called: the same technique
is used in 'Stackless Python'.
@p()
In Felix, the reason for using this technique is as
follows. There is a state variable in the continuation
which usually tells the driver to resume the procedure
immediately. However, when the Felix read primitive
is executed, something different happens.
The read primitive stores the address of the variable
to receive the next message into a special location
in the continuation base, and sets a flag indicating
that this thread of control is blocked until
the required data is stored in the variable.
@p()
It is up to the driver to find data for the
routine and resume it. The effect of this
arrangement is follows: a dispatch loop can be
used to fetch messages from a queue and
send them to the particular thread which 
is waiting on that message. For example
in windowing system with a thread for
each window, the window id is used to determine
which thread should get the message.
@p()
The set of all window threads can be stored
in an STL map or a hashtable,
which maps the window id to
the thread that is managing it.
Although the thread has executed a blocking
read operation, the driver reads a message
from the central queue and calls some thread
with the message, not necessarily the one
that last blocked. 
@p()
That is, while the Felix code
is conceptually thread based and performs
blocking read operations, there is only
a single hardware thread running,
which invokes the thread using the
resume() callback.
@p()
The ability of this mechanism to switch
thread contexts is determined by the data structure
the driver uses to map incoming messages to
Felix threads. By using a hashtable, constant
time switching can be achieved for millions
of threads: much faster than any operating
system switching, and supporting thread populations
only limited by available memory.
@p()
The ability of the Felix translator to
convert blocking reads into callbacks is
known as control inversion, more abstractly,
control inversion turns algorithmic code
inside out to obtain event driven code.

@head(1,'Modules')
A module consists of a name, a parent,
and a name map: from identifiers to integers;
the integers index entity definitions.
@p()
An interface is similar, except that the 
integers denote entity interfaces.
@p()
A module can be constrained by an compatible interface
to produce a new module. Here, compatible means
that every name in the interface has a corresponding
name in the module, and, the specifications of the
interface and module entities are compatible.
@p()
Every type is compatible with an abstract type.
Values, variables, functions, and procedures
are compatible is they have the same type.
Modules are compatible with an interface if
they're compatible with the interface, recursively :-)

